#!/usr/bin/env python3
"""
HarborAI è¿½è¸ªç³»ç»Ÿæ•°æ®åº“è¿ç§»è„šæœ¬

æ­¤è„šæœ¬è´Ÿè´£åˆ›å»ºå’Œæ›´æ–°è¿½è¸ªç³»ç»Ÿæ‰€éœ€çš„æ•°æ®åº“è¡¨ç»“æ„ï¼ŒåŒ…æ‹¬ï¼š
- tracing_info è¡¨ï¼šå­˜å‚¨è¿½è¸ªä¿¡æ¯
- ç›¸å…³ç´¢å¼•å’Œçº¦æŸ
- æ•°æ®è¿ç§»å’ŒéªŒè¯

åŠŸèƒ½ç‰¹æ€§ï¼š
- æ”¯æŒå¢é‡è¿ç§»
- æ•°æ®å®Œæ•´æ€§éªŒè¯
- å›æ»šæœºåˆ¶
- æ€§èƒ½ä¼˜åŒ–ç´¢å¼•
- å…¼å®¹æ€§æ£€æŸ¥

ä½œè€…: HarborAIå›¢é˜Ÿ
åˆ›å»ºæ—¶é—´: 2025-01-15
ç‰ˆæœ¬: v1.0.0
"""

import asyncio
import asyncpg
import argparse
import json
import sys
import os
from datetime import datetime, timezone
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from harborai.utils.exceptions import DatabaseError, MigrationError


@dataclass
class MigrationStep:
    """è¿ç§»æ­¥éª¤å®šä¹‰"""
    version: str
    name: str
    description: str
    sql_up: str
    sql_down: str
    dependencies: List[str] = None
    
    def __post_init__(self):
        if self.dependencies is None:
            self.dependencies = []


@dataclass
class MigrationResult:
    """è¿ç§»ç»“æœ"""
    success: bool
    version: str
    message: str
    execution_time_ms: float
    affected_rows: int = 0
    error: Optional[str] = None


class TracingMigrationManager:
    """è¿½è¸ªç³»ç»Ÿè¿ç§»ç®¡ç†å™¨"""
    
    def __init__(self, db_config: Dict[str, Any]):
        """
        åˆå§‹åŒ–è¿ç§»ç®¡ç†å™¨
        
        Args:
            db_config: æ•°æ®åº“è¿æ¥é…ç½®
        """
        self.db_config = db_config
        self.connection_pool: Optional[asyncpg.Pool] = None
        self.migration_steps = self._define_migration_steps()
        
    async def connect(self) -> None:
        """å»ºç«‹æ•°æ®åº“è¿æ¥"""
        try:
            self.connection_pool = await asyncpg.create_pool(
                host=self.db_config["host"],
                port=self.db_config["port"],
                database=self.db_config["database"],
                user=self.db_config["user"],
                password=self.db_config["password"],
                min_size=1,
                max_size=5,
                command_timeout=30
            )
            print(f"âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ: {self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}")
        except Exception as e:
            raise DatabaseError(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
    
    async def disconnect(self) -> None:
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.connection_pool:
            await self.connection_pool.close()
            print("âœ… æ•°æ®åº“è¿æ¥å·²å…³é—­")
    
    def _define_migration_steps(self) -> List[MigrationStep]:
        """å®šä¹‰è¿ç§»æ­¥éª¤"""
        return [
            MigrationStep(
                version="001",
                name="create_migration_history",
                description="åˆ›å»ºè¿ç§»å†å²è¡¨",
                sql_up="""
                CREATE TABLE IF NOT EXISTS migration_history (
                    id SERIAL PRIMARY KEY,
                    version VARCHAR(50) NOT NULL UNIQUE,
                    name VARCHAR(255) NOT NULL,
                    description TEXT,
                    applied_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
                    execution_time_ms FLOAT,
                    success BOOLEAN DEFAULT TRUE,
                    error_message TEXT,
                    checksum VARCHAR(64)
                );
                
                CREATE INDEX IF NOT EXISTS idx_migration_history_version 
                ON migration_history(version);
                
                CREATE INDEX IF NOT EXISTS idx_migration_history_applied_at 
                ON migration_history(applied_at);
                """,
                sql_down="""
                DROP TABLE IF EXISTS migration_history CASCADE;
                """
            ),
            
            MigrationStep(
                version="002",
                name="create_tracing_info_table",
                description="åˆ›å»ºè¿½è¸ªä¿¡æ¯è¡¨",
                sql_up="""
                CREATE TABLE IF NOT EXISTS tracing_info (
                    id BIGSERIAL PRIMARY KEY,
                    hb_trace_id VARCHAR(255) NOT NULL,
                    otel_trace_id VARCHAR(32) NOT NULL,
                    span_id VARCHAR(16) NOT NULL,
                    operation_name VARCHAR(255) NOT NULL,
                    service_name VARCHAR(100) NOT NULL,
                    service_version VARCHAR(50),
                    environment VARCHAR(50),
                    start_time TIMESTAMP WITH TIME ZONE NOT NULL,
                    end_time TIMESTAMP WITH TIME ZONE,
                    duration_ms FLOAT,
                    status VARCHAR(20) NOT NULL DEFAULT 'pending',
                    success BOOLEAN,
                    error_message TEXT,
                    tags JSONB DEFAULT '{}',
                    logs JSONB DEFAULT '[]',
                    parent_span_id VARCHAR(16),
                    trace_flags INTEGER DEFAULT 0,
                    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
                );
                
                -- æ·»åŠ æ³¨é‡Š
                COMMENT ON TABLE tracing_info IS 'è¿½è¸ªä¿¡æ¯è¡¨ï¼Œå­˜å‚¨HarborAIå’ŒOpenTelemetryçš„è¿½è¸ªæ•°æ®';
                COMMENT ON COLUMN tracing_info.hb_trace_id IS 'HarborAIå†…éƒ¨è¿½è¸ªID';
                COMMENT ON COLUMN tracing_info.otel_trace_id IS 'OpenTelemetryè¿½è¸ªIDï¼ˆ32ä½åå…­è¿›åˆ¶ï¼‰';
                COMMENT ON COLUMN tracing_info.span_id IS 'OpenTelemetry Span IDï¼ˆ16ä½åå…­è¿›åˆ¶ï¼‰';
                COMMENT ON COLUMN tracing_info.operation_name IS 'æ“ä½œåç§°ï¼Œå¦‚ai.chat.completion';
                COMMENT ON COLUMN tracing_info.service_name IS 'æœåŠ¡åç§°';
                COMMENT ON COLUMN tracing_info.status IS 'è¿½è¸ªçŠ¶æ€ï¼špending, active, completed, error';
                COMMENT ON COLUMN tracing_info.tags IS 'è¿½è¸ªæ ‡ç­¾ï¼ŒJSONæ ¼å¼';
                COMMENT ON COLUMN tracing_info.logs IS 'è¿½è¸ªæ—¥å¿—ï¼ŒJSONæ•°ç»„æ ¼å¼';
                """,
                sql_down="""
                DROP TABLE IF EXISTS tracing_info CASCADE;
                """,
                dependencies=["001"]
            ),
            
            MigrationStep(
                version="003",
                name="create_tracing_indexes",
                description="åˆ›å»ºè¿½è¸ªä¿¡æ¯è¡¨ç´¢å¼•",
                sql_up="""
                -- ä¸»è¦æŸ¥è¯¢ç´¢å¼•
                CREATE UNIQUE INDEX IF NOT EXISTS idx_tracing_info_hb_trace_id 
                ON tracing_info(hb_trace_id);
                
                CREATE INDEX IF NOT EXISTS idx_tracing_info_otel_trace_id 
                ON tracing_info(otel_trace_id);
                
                CREATE INDEX IF NOT EXISTS idx_tracing_info_operation_name 
                ON tracing_info(operation_name);
                
                CREATE INDEX IF NOT EXISTS idx_tracing_info_service_name 
                ON tracing_info(service_name);
                
                CREATE INDEX IF NOT EXISTS idx_tracing_info_status 
                ON tracing_info(status);
                
                -- æ—¶é—´èŒƒå›´æŸ¥è¯¢ç´¢å¼•
                CREATE INDEX IF NOT EXISTS idx_tracing_info_start_time 
                ON tracing_info(start_time);
                
                CREATE INDEX IF NOT EXISTS idx_tracing_info_created_at 
                ON tracing_info(created_at);
                
                -- å¤åˆç´¢å¼•ç”¨äºå¸¸è§æŸ¥è¯¢æ¨¡å¼
                CREATE INDEX IF NOT EXISTS idx_tracing_info_service_operation 
                ON tracing_info(service_name, operation_name);
                
                CREATE INDEX IF NOT EXISTS idx_tracing_info_status_start_time 
                ON tracing_info(status, start_time);
                
                CREATE INDEX IF NOT EXISTS idx_tracing_info_success_start_time 
                ON tracing_info(success, start_time) WHERE success IS NOT NULL;
                
                -- JSONBç´¢å¼•ç”¨äºæ ‡ç­¾æŸ¥è¯¢
                CREATE INDEX IF NOT EXISTS idx_tracing_info_tags_gin 
                ON tracing_info USING GIN(tags);
                
                -- éƒ¨åˆ†ç´¢å¼•ç”¨äºæ´»è·ƒè¿½è¸ª
                CREATE INDEX IF NOT EXISTS idx_tracing_info_active_traces 
                ON tracing_info(hb_trace_id, start_time) 
                WHERE status IN ('pending', 'active');
                """,
                sql_down="""
                DROP INDEX IF EXISTS idx_tracing_info_hb_trace_id;
                DROP INDEX IF EXISTS idx_tracing_info_otel_trace_id;
                DROP INDEX IF EXISTS idx_tracing_info_operation_name;
                DROP INDEX IF EXISTS idx_tracing_info_service_name;
                DROP INDEX IF EXISTS idx_tracing_info_status;
                DROP INDEX IF EXISTS idx_tracing_info_start_time;
                DROP INDEX IF EXISTS idx_tracing_info_created_at;
                DROP INDEX IF EXISTS idx_tracing_info_service_operation;
                DROP INDEX IF EXISTS idx_tracing_info_status_start_time;
                DROP INDEX IF EXISTS idx_tracing_info_success_start_time;
                DROP INDEX IF EXISTS idx_tracing_info_tags_gin;
                DROP INDEX IF EXISTS idx_tracing_info_active_traces;
                """,
                dependencies=["002"]
            ),
            
            MigrationStep(
                version="004",
                name="create_tracing_constraints",
                description="åˆ›å»ºè¿½è¸ªä¿¡æ¯è¡¨çº¦æŸ",
                sql_up="""
                -- æ£€æŸ¥çº¦æŸ
                ALTER TABLE tracing_info 
                ADD CONSTRAINT chk_tracing_info_status 
                CHECK (status IN ('pending', 'active', 'completed', 'error'));
                
                ALTER TABLE tracing_info 
                ADD CONSTRAINT chk_tracing_info_duration 
                CHECK (duration_ms IS NULL OR duration_ms >= 0);
                
                ALTER TABLE tracing_info 
                ADD CONSTRAINT chk_tracing_info_times 
                CHECK (end_time IS NULL OR end_time >= start_time);
                
                ALTER TABLE tracing_info 
                ADD CONSTRAINT chk_tracing_info_otel_trace_id_format 
                CHECK (otel_trace_id ~ '^[0-9a-f]{32}$');
                
                ALTER TABLE tracing_info 
                ADD CONSTRAINT chk_tracing_info_span_id_format 
                CHECK (span_id ~ '^[0-9a-f]{16}$');
                
                -- è§¦å‘å™¨ï¼šè‡ªåŠ¨æ›´æ–°updated_atå­—æ®µ
                CREATE OR REPLACE FUNCTION update_tracing_info_updated_at()
                RETURNS TRIGGER AS $$
                BEGIN
                    NEW.updated_at = CURRENT_TIMESTAMP;
                    RETURN NEW;
                END;
                $$ LANGUAGE plpgsql;
                
                CREATE TRIGGER trg_tracing_info_updated_at
                    BEFORE UPDATE ON tracing_info
                    FOR EACH ROW
                    EXECUTE FUNCTION update_tracing_info_updated_at();
                """,
                sql_down="""
                DROP TRIGGER IF EXISTS trg_tracing_info_updated_at ON tracing_info;
                DROP FUNCTION IF EXISTS update_tracing_info_updated_at();
                
                ALTER TABLE tracing_info DROP CONSTRAINT IF EXISTS chk_tracing_info_status;
                ALTER TABLE tracing_info DROP CONSTRAINT IF EXISTS chk_tracing_info_duration;
                ALTER TABLE tracing_info DROP CONSTRAINT IF EXISTS chk_tracing_info_times;
                ALTER TABLE tracing_info DROP CONSTRAINT IF EXISTS chk_tracing_info_otel_trace_id_format;
                ALTER TABLE tracing_info DROP CONSTRAINT IF EXISTS chk_tracing_info_span_id_format;
                """,
                dependencies=["003"]
            ),
            
            MigrationStep(
                version="005",
                name="create_tracing_partitions",
                description="åˆ›å»ºè¿½è¸ªä¿¡æ¯è¡¨åˆ†åŒºï¼ˆæŒ‰æœˆï¼‰",
                sql_up="""
                -- åˆ›å»ºåˆ†åŒºå‡½æ•°
                CREATE OR REPLACE FUNCTION create_tracing_info_partition(
                    partition_date DATE
                ) RETURNS VOID AS $$
                DECLARE
                    partition_name TEXT;
                    start_date DATE;
                    end_date DATE;
                BEGIN
                    -- è®¡ç®—åˆ†åŒºåç§°å’Œæ—¥æœŸèŒƒå›´
                    partition_name := 'tracing_info_' || TO_CHAR(partition_date, 'YYYY_MM');
                    start_date := DATE_TRUNC('month', partition_date);
                    end_date := start_date + INTERVAL '1 month';
                    
                    -- åˆ›å»ºåˆ†åŒºè¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
                    EXECUTE format('
                        CREATE TABLE IF NOT EXISTS %I PARTITION OF tracing_info
                        FOR VALUES FROM (%L) TO (%L)',
                        partition_name, start_date, end_date
                    );
                    
                    -- åˆ›å»ºåˆ†åŒºç‰¹å®šçš„ç´¢å¼•
                    EXECUTE format('
                        CREATE INDEX IF NOT EXISTS %I 
                        ON %I(start_time)',
                        'idx_' || partition_name || '_start_time',
                        partition_name
                    );
                    
                    RAISE NOTICE 'åˆ†åŒº % åˆ›å»ºæˆåŠŸ', partition_name;
                END;
                $$ LANGUAGE plpgsql;
                
                -- å°†ç°æœ‰è¡¨è½¬æ¢ä¸ºåˆ†åŒºè¡¨ï¼ˆå¦‚æœæœ‰æ•°æ®éœ€è¦å…ˆå¤‡ä»½ï¼‰
                -- æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªç ´åæ€§æ“ä½œï¼Œåœ¨ç”Ÿäº§ç¯å¢ƒä¸­éœ€è¦è°¨æ…æ‰§è¡Œ
                
                -- åˆ›å»ºå½“å‰æœˆä»½å’Œä¸‹ä¸ªæœˆçš„åˆ†åŒº
                SELECT create_tracing_info_partition(CURRENT_DATE);
                SELECT create_tracing_info_partition(CURRENT_DATE + INTERVAL '1 month');
                """,
                sql_down="""
                -- åˆ é™¤åˆ†åŒºå‡½æ•°
                DROP FUNCTION IF EXISTS create_tracing_info_partition(DATE);
                
                -- æ³¨æ„ï¼šåˆ é™¤åˆ†åŒºéœ€è¦æ‰‹åŠ¨å¤„ç†ï¼Œå› ä¸ºæ¶‰åŠæ•°æ®è¿ç§»
                -- åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œè¿™ä¸ªå›æ»šæ“ä½œéœ€è¦ç‰¹åˆ«å°å¿ƒ
                """,
                dependencies=["004"]
            ),
            
            MigrationStep(
                version="006",
                name="create_tracing_views",
                description="åˆ›å»ºè¿½è¸ªä¿¡æ¯è§†å›¾",
                sql_up="""
                -- æ´»è·ƒè¿½è¸ªè§†å›¾
                CREATE OR REPLACE VIEW v_active_traces AS
                SELECT 
                    hb_trace_id,
                    otel_trace_id,
                    operation_name,
                    service_name,
                    start_time,
                    EXTRACT(EPOCH FROM (CURRENT_TIMESTAMP - start_time)) * 1000 AS running_time_ms,
                    tags,
                    status
                FROM tracing_info
                WHERE status IN ('pending', 'active')
                ORDER BY start_time DESC;
                
                -- è¿½è¸ªç»Ÿè®¡è§†å›¾
                CREATE OR REPLACE VIEW v_tracing_stats AS
                SELECT 
                    service_name,
                    operation_name,
                    DATE_TRUNC('hour', start_time) AS hour_bucket,
                    COUNT(*) AS total_traces,
                    COUNT(*) FILTER (WHERE success = true) AS successful_traces,
                    COUNT(*) FILTER (WHERE success = false) AS failed_traces,
                    AVG(duration_ms) AS avg_duration_ms,
                    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY duration_ms) AS median_duration_ms,
                    PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY duration_ms) AS p95_duration_ms,
                    PERCENTILE_CONT(0.99) WITHIN GROUP (ORDER BY duration_ms) AS p99_duration_ms
                FROM tracing_info
                WHERE status = 'completed' 
                  AND start_time >= CURRENT_TIMESTAMP - INTERVAL '24 hours'
                GROUP BY service_name, operation_name, hour_bucket
                ORDER BY hour_bucket DESC, service_name, operation_name;
                
                -- é”™è¯¯è¿½è¸ªè§†å›¾
                CREATE OR REPLACE VIEW v_error_traces AS
                SELECT 
                    hb_trace_id,
                    otel_trace_id,
                    operation_name,
                    service_name,
                    start_time,
                    end_time,
                    duration_ms,
                    error_message,
                    tags
                FROM tracing_info
                WHERE status = 'error' OR success = false
                ORDER BY start_time DESC;
                
                -- æ€§èƒ½æ…¢æŸ¥è¯¢è§†å›¾
                CREATE OR REPLACE VIEW v_slow_traces AS
                SELECT 
                    hb_trace_id,
                    otel_trace_id,
                    operation_name,
                    service_name,
                    start_time,
                    duration_ms,
                    tags
                FROM tracing_info
                WHERE status = 'completed' 
                  AND duration_ms > 1000  -- è¶…è¿‡1ç§’çš„è¯·æ±‚
                ORDER BY duration_ms DESC;
                """,
                sql_down="""
                DROP VIEW IF EXISTS v_active_traces;
                DROP VIEW IF EXISTS v_tracing_stats;
                DROP VIEW IF EXISTS v_error_traces;
                DROP VIEW IF EXISTS v_slow_traces;
                """,
                dependencies=["005"]
            )
        ]
    
    async def get_applied_migrations(self) -> List[str]:
        """è·å–å·²åº”ç”¨çš„è¿ç§»ç‰ˆæœ¬"""
        if not self.connection_pool:
            raise DatabaseError("æ•°æ®åº“è¿æ¥æœªå»ºç«‹")
        
        async with self.connection_pool.acquire() as connection:
            try:
                # æ£€æŸ¥è¿ç§»å†å²è¡¨æ˜¯å¦å­˜åœ¨
                exists = await connection.fetchval("""
                    SELECT EXISTS (
                        SELECT FROM information_schema.tables 
                        WHERE table_schema = 'public' 
                        AND table_name = 'migration_history'
                    )
                """)
                
                if not exists:
                    return []
                
                # è·å–å·²åº”ç”¨çš„è¿ç§»
                rows = await connection.fetch("""
                    SELECT version 
                    FROM migration_history 
                    WHERE success = true 
                    ORDER BY applied_at
                """)
                
                return [row['version'] for row in rows]
                
            except Exception as e:
                raise DatabaseError(f"è·å–è¿ç§»å†å²å¤±è´¥: {e}")
    
    async def apply_migration(self, step: MigrationStep) -> MigrationResult:
        """åº”ç”¨å•ä¸ªè¿ç§»æ­¥éª¤"""
        if not self.connection_pool:
            raise DatabaseError("æ•°æ®åº“è¿æ¥æœªå»ºç«‹")
        
        start_time = datetime.now()
        
        async with self.connection_pool.acquire() as connection:
            async with connection.transaction():
                try:
                    print(f"ğŸ”„ åº”ç”¨è¿ç§» {step.version}: {step.name}")
                    print(f"   æè¿°: {step.description}")
                    
                    # æ‰§è¡Œè¿ç§»SQL
                    result = await connection.execute(step.sql_up)
                    
                    # è®¡ç®—æ‰§è¡Œæ—¶é—´
                    end_time = datetime.now()
                    execution_time_ms = (end_time - start_time).total_seconds() * 1000
                    
                    # è®°å½•è¿ç§»å†å²
                    await connection.execute("""
                        INSERT INTO migration_history 
                        (version, name, description, execution_time_ms, success)
                        VALUES ($1, $2, $3, $4, $5)
                        ON CONFLICT (version) DO UPDATE SET
                            applied_at = CURRENT_TIMESTAMP,
                            execution_time_ms = EXCLUDED.execution_time_ms,
                            success = EXCLUDED.success,
                            error_message = NULL
                    """, step.version, step.name, step.description, execution_time_ms, True)
                    
                    print(f"âœ… è¿ç§» {step.version} åº”ç”¨æˆåŠŸ ({execution_time_ms:.2f}ms)")
                    
                    return MigrationResult(
                        success=True,
                        version=step.version,
                        message=f"è¿ç§» {step.version} åº”ç”¨æˆåŠŸ",
                        execution_time_ms=execution_time_ms
                    )
                    
                except Exception as e:
                    # è®°å½•å¤±è´¥çš„è¿ç§»
                    end_time = datetime.now()
                    execution_time_ms = (end_time - start_time).total_seconds() * 1000
                    
                    try:
                        await connection.execute("""
                            INSERT INTO migration_history 
                            (version, name, description, execution_time_ms, success, error_message)
                            VALUES ($1, $2, $3, $4, $5, $6)
                            ON CONFLICT (version) DO UPDATE SET
                                applied_at = CURRENT_TIMESTAMP,
                                execution_time_ms = EXCLUDED.execution_time_ms,
                                success = EXCLUDED.success,
                                error_message = EXCLUDED.error_message
                        """, step.version, step.name, step.description, execution_time_ms, False, str(e))
                    except:
                        pass  # å¦‚æœè¿è¿ç§»å†å²éƒ½æ— æ³•è®°å½•ï¼Œè¯´æ˜æ˜¯ä¸¥é‡é”™è¯¯
                    
                    print(f"âŒ è¿ç§» {step.version} åº”ç”¨å¤±è´¥: {e}")
                    
                    return MigrationResult(
                        success=False,
                        version=step.version,
                        message=f"è¿ç§» {step.version} åº”ç”¨å¤±è´¥",
                        execution_time_ms=execution_time_ms,
                        error=str(e)
                    )
    
    async def rollback_migration(self, step: MigrationStep) -> MigrationResult:
        """å›æ»šå•ä¸ªè¿ç§»æ­¥éª¤"""
        if not self.connection_pool:
            raise DatabaseError("æ•°æ®åº“è¿æ¥æœªå»ºç«‹")
        
        start_time = datetime.now()
        
        async with self.connection_pool.acquire() as connection:
            async with connection.transaction():
                try:
                    print(f"ğŸ”„ å›æ»šè¿ç§» {step.version}: {step.name}")
                    
                    # æ‰§è¡Œå›æ»šSQL
                    await connection.execute(step.sql_down)
                    
                    # åˆ é™¤è¿ç§»å†å²è®°å½•
                    await connection.execute("""
                        DELETE FROM migration_history WHERE version = $1
                    """, step.version)
                    
                    # è®¡ç®—æ‰§è¡Œæ—¶é—´
                    end_time = datetime.now()
                    execution_time_ms = (end_time - start_time).total_seconds() * 1000
                    
                    print(f"âœ… è¿ç§» {step.version} å›æ»šæˆåŠŸ ({execution_time_ms:.2f}ms)")
                    
                    return MigrationResult(
                        success=True,
                        version=step.version,
                        message=f"è¿ç§» {step.version} å›æ»šæˆåŠŸ",
                        execution_time_ms=execution_time_ms
                    )
                    
                except Exception as e:
                    end_time = datetime.now()
                    execution_time_ms = (end_time - start_time).total_seconds() * 1000
                    
                    print(f"âŒ è¿ç§» {step.version} å›æ»šå¤±è´¥: {e}")
                    
                    return MigrationResult(
                        success=False,
                        version=step.version,
                        message=f"è¿ç§» {step.version} å›æ»šå¤±è´¥",
                        execution_time_ms=execution_time_ms,
                        error=str(e)
                    )
    
    async def migrate_up(self, target_version: Optional[str] = None) -> List[MigrationResult]:
        """æ‰§è¡Œå‘ä¸Šè¿ç§»"""
        applied_migrations = await self.get_applied_migrations()
        results = []
        
        print(f"ğŸ“‹ å·²åº”ç”¨çš„è¿ç§»: {applied_migrations}")
        
        for step in self.migration_steps:
            # æ£€æŸ¥æ˜¯å¦å·²åº”ç”¨
            if step.version in applied_migrations:
                print(f"â­ï¸  è·³è¿‡å·²åº”ç”¨çš„è¿ç§» {step.version}")
                continue
            
            # æ£€æŸ¥ä¾èµ–
            for dep in step.dependencies:
                if dep not in applied_migrations:
                    raise MigrationError(f"è¿ç§» {step.version} ä¾èµ– {dep}ï¼Œä½† {dep} å°šæœªåº”ç”¨")
            
            # åº”ç”¨è¿ç§»
            result = await self.apply_migration(step)
            results.append(result)
            
            if not result.success:
                print(f"âŒ è¿ç§»å¤±è´¥ï¼Œåœæ­¢åç»­è¿ç§»")
                break
            
            applied_migrations.append(step.version)
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡ç‰ˆæœ¬
            if target_version and step.version == target_version:
                print(f"ğŸ¯ å·²è¾¾åˆ°ç›®æ ‡ç‰ˆæœ¬ {target_version}")
                break
        
        return results
    
    async def migrate_down(self, target_version: str) -> List[MigrationResult]:
        """æ‰§è¡Œå‘ä¸‹è¿ç§»ï¼ˆå›æ»šï¼‰"""
        applied_migrations = await self.get_applied_migrations()
        results = []
        
        # æ‰¾åˆ°éœ€è¦å›æ»šçš„è¿ç§»ï¼ˆæŒ‰é€†åºï¼‰
        steps_to_rollback = []
        for step in reversed(self.migration_steps):
            if step.version in applied_migrations:
                steps_to_rollback.append(step)
                if step.version == target_version:
                    break
        
        print(f"ğŸ“‹ éœ€è¦å›æ»šçš„è¿ç§»: {[s.version for s in steps_to_rollback]}")
        
        for step in steps_to_rollback:
            if step.version == target_version:
                print(f"ğŸ¯ å·²è¾¾åˆ°ç›®æ ‡ç‰ˆæœ¬ {target_version}ï¼Œåœæ­¢å›æ»š")
                break
            
            result = await self.rollback_migration(step)
            results.append(result)
            
            if not result.success:
                print(f"âŒ å›æ»šå¤±è´¥ï¼Œåœæ­¢åç»­å›æ»š")
                break
        
        return results
    
    async def validate_schema(self) -> Dict[str, Any]:
        """éªŒè¯æ•°æ®åº“æ¨¡å¼"""
        if not self.connection_pool:
            raise DatabaseError("æ•°æ®åº“è¿æ¥æœªå»ºç«‹")
        
        validation_results = {
            "tables": {},
            "indexes": {},
            "constraints": {},
            "views": {},
            "functions": {},
            "overall_status": "unknown"
        }
        
        async with self.connection_pool.acquire() as connection:
            try:
                # éªŒè¯è¡¨
                tables = await connection.fetch("""
                    SELECT table_name, 
                           (SELECT COUNT(*) FROM information_schema.columns 
                            WHERE table_name = t.table_name AND table_schema = 'public') as column_count
                    FROM information_schema.tables t
                    WHERE table_schema = 'public' 
                    AND table_name IN ('migration_history', 'tracing_info')
                """)
                
                for table in tables:
                    validation_results["tables"][table["table_name"]] = {
                        "exists": True,
                        "column_count": table["column_count"]
                    }
                
                # éªŒè¯ç´¢å¼•
                indexes = await connection.fetch("""
                    SELECT indexname, tablename
                    FROM pg_indexes
                    WHERE schemaname = 'public'
                    AND tablename IN ('migration_history', 'tracing_info')
                """)
                
                for index in indexes:
                    table_name = index["tablename"]
                    if table_name not in validation_results["indexes"]:
                        validation_results["indexes"][table_name] = []
                    validation_results["indexes"][table_name].append(index["indexname"])
                
                # éªŒè¯çº¦æŸ
                constraints = await connection.fetch("""
                    SELECT constraint_name, table_name, constraint_type
                    FROM information_schema.table_constraints
                    WHERE table_schema = 'public'
                    AND table_name IN ('migration_history', 'tracing_info')
                """)
                
                for constraint in constraints:
                    table_name = constraint["table_name"]
                    if table_name not in validation_results["constraints"]:
                        validation_results["constraints"][table_name] = []
                    validation_results["constraints"][table_name].append({
                        "name": constraint["constraint_name"],
                        "type": constraint["constraint_type"]
                    })
                
                # éªŒè¯è§†å›¾
                views = await connection.fetch("""
                    SELECT table_name
                    FROM information_schema.views
                    WHERE table_schema = 'public'
                    AND table_name LIKE 'v_%'
                """)
                
                validation_results["views"] = [view["table_name"] for view in views]
                
                # éªŒè¯å‡½æ•°
                functions = await connection.fetch("""
                    SELECT routine_name
                    FROM information_schema.routines
                    WHERE routine_schema = 'public'
                    AND routine_type = 'FUNCTION'
                    AND routine_name LIKE '%tracing%'
                """)
                
                validation_results["functions"] = [func["routine_name"] for func in functions]
                
                # æ€»ä½“çŠ¶æ€è¯„ä¼°
                required_tables = {"migration_history", "tracing_info"}
                existing_tables = set(validation_results["tables"].keys())
                
                if required_tables.issubset(existing_tables):
                    validation_results["overall_status"] = "healthy"
                else:
                    validation_results["overall_status"] = "incomplete"
                
            except Exception as e:
                validation_results["overall_status"] = "error"
                validation_results["error"] = str(e)
        
        return validation_results
    
    async def get_migration_status(self) -> Dict[str, Any]:
        """è·å–è¿ç§»çŠ¶æ€"""
        applied_migrations = await self.get_applied_migrations()
        
        status = {
            "applied_migrations": applied_migrations,
            "pending_migrations": [],
            "total_migrations": len(self.migration_steps),
            "completion_percentage": 0
        }
        
        for step in self.migration_steps:
            if step.version not in applied_migrations:
                status["pending_migrations"].append({
                    "version": step.version,
                    "name": step.name,
                    "description": step.description
                })
        
        if status["total_migrations"] > 0:
            status["completion_percentage"] = (
                len(applied_migrations) / status["total_migrations"] * 100
            )
        
        return status


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="HarborAI è¿½è¸ªç³»ç»Ÿæ•°æ®åº“è¿ç§»å·¥å…·")
    parser.add_argument("--host", default="localhost", help="æ•°æ®åº“ä¸»æœº")
    parser.add_argument("--port", type=int, default=5432, help="æ•°æ®åº“ç«¯å£")
    parser.add_argument("--database", required=True, help="æ•°æ®åº“åç§°")
    parser.add_argument("--user", required=True, help="æ•°æ®åº“ç”¨æˆ·")
    parser.add_argument("--password", required=True, help="æ•°æ®åº“å¯†ç ")
    parser.add_argument("--action", choices=["up", "down", "status", "validate"], 
                       default="up", help="æ‰§è¡Œçš„æ“ä½œ")
    parser.add_argument("--target", help="ç›®æ ‡ç‰ˆæœ¬ï¼ˆç”¨äºup/downæ“ä½œï¼‰")
    parser.add_argument("--dry-run", action="store_true", help="ä»…æ˜¾ç¤ºå°†è¦æ‰§è¡Œçš„æ“ä½œï¼Œä¸å®é™…æ‰§è¡Œ")
    
    args = parser.parse_args()
    
    # æ•°æ®åº“é…ç½®
    db_config = {
        "host": args.host,
        "port": args.port,
        "database": args.database,
        "user": args.user,
        "password": args.password
    }
    
    # åˆ›å»ºè¿ç§»ç®¡ç†å™¨
    migration_manager = TracingMigrationManager(db_config)
    
    try:
        # è¿æ¥æ•°æ®åº“
        await migration_manager.connect()
        
        if args.action == "up":
            print("ğŸš€ å¼€å§‹æ‰§è¡Œå‘ä¸Šè¿ç§»...")
            if args.dry_run:
                print("ğŸ” DRY RUN æ¨¡å¼ - ä»…æ˜¾ç¤ºå°†è¦æ‰§è¡Œçš„æ“ä½œ")
                status = await migration_manager.get_migration_status()
                print(f"ğŸ“Š å¾…æ‰§è¡Œçš„è¿ç§»:")
                for migration in status["pending_migrations"]:
                    print(f"   - {migration['version']}: {migration['name']}")
            else:
                results = await migration_manager.migrate_up(args.target)
                
                success_count = sum(1 for r in results if r.success)
                total_count = len(results)
                
                print(f"\nğŸ“Š è¿ç§»ç»“æœ: {success_count}/{total_count} æˆåŠŸ")
                
                if success_count == total_count and total_count > 0:
                    print("ğŸ‰ æ‰€æœ‰è¿ç§»æ‰§è¡ŒæˆåŠŸï¼")
                elif success_count < total_count:
                    print("âš ï¸  éƒ¨åˆ†è¿ç§»æ‰§è¡Œå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
                    sys.exit(1)
                else:
                    print("â„¹ï¸  æ²¡æœ‰éœ€è¦æ‰§è¡Œçš„è¿ç§»")
        
        elif args.action == "down":
            if not args.target:
                print("âŒ å›æ»šæ“ä½œéœ€è¦æŒ‡å®šç›®æ ‡ç‰ˆæœ¬ (--target)")
                sys.exit(1)
            
            print(f"ğŸ”„ å¼€å§‹å›æ»šåˆ°ç‰ˆæœ¬ {args.target}...")
            if args.dry_run:
                print("ğŸ” DRY RUN æ¨¡å¼ - ä»…æ˜¾ç¤ºå°†è¦æ‰§è¡Œçš„æ“ä½œ")
                # è¿™é‡Œå¯ä»¥æ·»åŠ æ˜¾ç¤ºå°†è¦å›æ»šçš„è¿ç§»
            else:
                results = await migration_manager.migrate_down(args.target)
                
                success_count = sum(1 for r in results if r.success)
                total_count = len(results)
                
                print(f"\nğŸ“Š å›æ»šç»“æœ: {success_count}/{total_count} æˆåŠŸ")
                
                if success_count == total_count:
                    print("ğŸ‰ å›æ»šæ‰§è¡ŒæˆåŠŸï¼")
                else:
                    print("âš ï¸  éƒ¨åˆ†å›æ»šæ‰§è¡Œå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
                    sys.exit(1)
        
        elif args.action == "status":
            print("ğŸ“Š è·å–è¿ç§»çŠ¶æ€...")
            status = await migration_manager.get_migration_status()
            
            print(f"\nè¿ç§»çŠ¶æ€:")
            print(f"  æ€»è¿ç§»æ•°: {status['total_migrations']}")
            print(f"  å·²åº”ç”¨: {len(status['applied_migrations'])}")
            print(f"  å¾…åº”ç”¨: {len(status['pending_migrations'])}")
            print(f"  å®Œæˆåº¦: {status['completion_percentage']:.1f}%")
            
            if status['applied_migrations']:
                print(f"\nå·²åº”ç”¨çš„è¿ç§»:")
                for version in status['applied_migrations']:
                    print(f"  âœ… {version}")
            
            if status['pending_migrations']:
                print(f"\nå¾…åº”ç”¨çš„è¿ç§»:")
                for migration in status['pending_migrations']:
                    print(f"  â³ {migration['version']}: {migration['name']}")
        
        elif args.action == "validate":
            print("ğŸ” éªŒè¯æ•°æ®åº“æ¨¡å¼...")
            validation = await migration_manager.validate_schema()
            
            print(f"\néªŒè¯ç»“æœ:")
            print(f"  æ€»ä½“çŠ¶æ€: {validation['overall_status']}")
            
            print(f"\nè¡¨:")
            for table_name, info in validation["tables"].items():
                print(f"  âœ… {table_name} ({info['column_count']} åˆ—)")
            
            print(f"\nç´¢å¼•:")
            for table_name, indexes in validation["indexes"].items():
                print(f"  {table_name}: {len(indexes)} ä¸ªç´¢å¼•")
            
            print(f"\nè§†å›¾: {len(validation['views'])} ä¸ª")
            print(f"å‡½æ•°: {len(validation['functions'])} ä¸ª")
            
            if validation['overall_status'] == 'healthy':
                print("\nğŸ‰ æ•°æ®åº“æ¨¡å¼éªŒè¯é€šè¿‡ï¼")
            else:
                print("\nâš ï¸  æ•°æ®åº“æ¨¡å¼å­˜åœ¨é—®é¢˜ï¼Œè¯·æ£€æŸ¥è¿ç§»çŠ¶æ€")
                if 'error' in validation:
                    print(f"é”™è¯¯: {validation['error']}")
                sys.exit(1)
    
    except Exception as e:
        print(f"âŒ æ“ä½œå¤±è´¥: {e}")
        sys.exit(1)
    
    finally:
        await migration_manager.disconnect()


if __name__ == "__main__":
    asyncio.run(main())