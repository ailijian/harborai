#!/usr/bin/env python3
"""
HarborAI æµ‹è¯•è¿è¡Œè„šæœ¬

æ­¤è„šæœ¬è´Ÿè´£è¿è¡Œè¿½è¸ªç³»ç»Ÿçš„æ‰€æœ‰æµ‹è¯•ï¼ŒåŒ…æ‹¬ï¼š
- å•å…ƒæµ‹è¯•
- é›†æˆæµ‹è¯•
- æ•°æ®éªŒè¯æµ‹è¯•
- æ€§èƒ½åŸºå‡†æµ‹è¯•

åŠŸèƒ½ç‰¹æ€§ï¼š
- è‡ªåŠ¨å‘ç°æµ‹è¯•
- å¹¶è¡Œæµ‹è¯•æ‰§è¡Œ
- è¯¦ç»†çš„æµ‹è¯•æŠ¥å‘Š
- è¦†ç›–ç‡ç»Ÿè®¡
- å¤±è´¥æµ‹è¯•é‡è¯•

ä½œè€…: HarborAIå›¢é˜Ÿ
åˆ›å»ºæ—¶é—´: 2025-01-15
ç‰ˆæœ¬: v1.0.0
"""

import asyncio
import subprocess
import sys
import os
import argparse
import json
import time
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime, timezone

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


@dataclass
class TestResult:
    """æµ‹è¯•ç»“æœ"""
    name: str
    status: str  # "pass", "fail", "skip", "error"
    duration: float
    output: str = ""
    error: str = ""
    coverage: float = 0.0


@dataclass
class TestSuite:
    """æµ‹è¯•å¥—ä»¶"""
    name: str
    tests: List[TestResult]
    total_duration: float
    pass_count: int = 0
    fail_count: int = 0
    skip_count: int = 0
    error_count: int = 0
    coverage: float = 0.0
    
    def __post_init__(self):
        self.pass_count = len([t for t in self.tests if t.status == "pass"])
        self.fail_count = len([t for t in self.tests if t.status == "fail"])
        self.skip_count = len([t for t in self.tests if t.status == "skip"])
        self.error_count = len([t for t in self.tests if t.status == "error"])


@dataclass
class TestReport:
    """æµ‹è¯•æŠ¥å‘Š"""
    timestamp: datetime
    project_info: Dict[str, str]
    test_suites: List[TestSuite]
    overall_coverage: float = 0.0
    total_duration: float = 0.0
    total_tests: int = 0
    total_pass: int = 0
    total_fail: int = 0
    total_skip: int = 0
    total_error: int = 0
    
    def __post_init__(self):
        self.total_duration = sum(suite.total_duration for suite in self.test_suites)
        self.total_tests = sum(len(suite.tests) for suite in self.test_suites)
        self.total_pass = sum(suite.pass_count for suite in self.test_suites)
        self.total_fail = sum(suite.fail_count for suite in self.test_suites)
        self.total_skip = sum(suite.skip_count for suite in self.test_suites)
        self.total_error = sum(suite.error_count for suite in self.test_suites)


class TestRunner:
    """æµ‹è¯•è¿è¡Œå™¨"""
    
    def __init__(self, project_root: Path):
        """
        åˆå§‹åŒ–æµ‹è¯•è¿è¡Œå™¨
        
        Args:
            project_root: é¡¹ç›®æ ¹ç›®å½•
        """
        self.project_root = project_root
        self.test_suites: List[TestSuite] = []
        
    def discover_tests(self) -> Dict[str, List[Path]]:
        """å‘ç°æµ‹è¯•æ–‡ä»¶"""
        test_categories = {
            "unit": [],
            "integration": [],
            "performance": []
        }
        
        # å•å…ƒæµ‹è¯•
        unit_test_dir = self.project_root / "tests" / "unit"
        if unit_test_dir.exists():
            test_categories["unit"] = list(unit_test_dir.glob("test_*.py"))
        
        # é›†æˆæµ‹è¯•
        integration_test_dir = self.project_root / "tests" / "integration"
        if integration_test_dir.exists():
            test_categories["integration"] = list(integration_test_dir.glob("test_*.py"))
        
        # æ€§èƒ½æµ‹è¯•
        performance_test_dir = self.project_root / "tests" / "performance"
        if performance_test_dir.exists():
            test_categories["performance"] = list(performance_test_dir.glob("test_*.py"))
        
        return test_categories
    
    async def run_pytest_suite(self, name: str, test_files: List[Path], 
                              extra_args: List[str] = None) -> TestSuite:
        """è¿è¡Œpytestæµ‹è¯•å¥—ä»¶"""
        if not test_files:
            return TestSuite(name=name, tests=[], total_duration=0.0)
        
        print(f"ğŸ§ª è¿è¡Œ {name} æµ‹è¯•...")
        
        # æ„å»ºpytestå‘½ä»¤
        cmd = [
            sys.executable, "-m", "pytest",
            "--tb=short",
            "--json-report",
            f"--json-report-file={self.project_root}/test_results_{name}.json",
            "-v"
        ]
        
        if extra_args:
            cmd.extend(extra_args)
        
        # æ·»åŠ æµ‹è¯•æ–‡ä»¶
        cmd.extend(str(f) for f in test_files)
        
        start_time = time.time()
        
        try:
            # è¿è¡Œpytest
            result = subprocess.run(
                cmd,
                cwd=self.project_root,
                capture_output=True,
                text=True,
                timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
            )
            
            end_time = time.time()
            duration = end_time - start_time
            
            # è§£æJSONæŠ¥å‘Š
            json_report_file = self.project_root / f"test_results_{name}.json"
            tests = []
            
            if json_report_file.exists():
                try:
                    with open(json_report_file, 'r', encoding='utf-8') as f:
                        report_data = json.load(f)
                    
                    for test_data in report_data.get("tests", []):
                        test_result = TestResult(
                            name=test_data.get("nodeid", "unknown"),
                            status=self._map_pytest_outcome(test_data.get("outcome", "error")),
                            duration=test_data.get("duration", 0.0),
                            output=test_data.get("call", {}).get("stdout", ""),
                            error=test_data.get("call", {}).get("stderr", "")
                        )
                        tests.append(test_result)
                    
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    json_report_file.unlink()
                    
                except Exception as e:
                    print(f"âš ï¸  è§£ææµ‹è¯•æŠ¥å‘Šå¤±è´¥: {e}")
            
            # å¦‚æœæ²¡æœ‰è§£æåˆ°æµ‹è¯•ç»“æœï¼Œåˆ›å»ºä¸€ä¸ªåŸºäºè¿”å›ç çš„ç»“æœ
            if not tests:
                status = "pass" if result.returncode == 0 else "fail"
                tests.append(TestResult(
                    name=f"{name}_suite",
                    status=status,
                    duration=duration,
                    output=result.stdout,
                    error=result.stderr
                ))
            
            return TestSuite(
                name=name,
                tests=tests,
                total_duration=duration
            )
        
        except subprocess.TimeoutExpired:
            return TestSuite(
                name=name,
                tests=[TestResult(
                    name=f"{name}_timeout",
                    status="error",
                    duration=300.0,
                    error="æµ‹è¯•è¶…æ—¶"
                )],
                total_duration=300.0
            )
        
        except Exception as e:
            return TestSuite(
                name=name,
                tests=[TestResult(
                    name=f"{name}_error",
                    status="error",
                    duration=0.0,
                    error=str(e)
                )],
                total_duration=0.0
            )
    
    def _map_pytest_outcome(self, outcome: str) -> str:
        """æ˜ å°„pytestç»“æœåˆ°æ ‡å‡†çŠ¶æ€"""
        mapping = {
            "passed": "pass",
            "failed": "fail",
            "skipped": "skip",
            "error": "error",
            "xfail": "skip",
            "xpass": "pass"
        }
        return mapping.get(outcome, "error")
    
    async def run_coverage_analysis(self) -> float:
        """è¿è¡Œè¦†ç›–ç‡åˆ†æ"""
        print("ğŸ“Š åˆ†æä»£ç è¦†ç›–ç‡...")
        
        try:
            # è¿è¡Œè¦†ç›–ç‡æµ‹è¯•
            cmd = [
                sys.executable, "-m", "pytest",
                "--cov=harborai",
                "--cov-report=json",
                f"--cov-report-file={self.project_root}/coverage.json",
                "tests/"
            ]
            
            result = subprocess.run(
                cmd,
                cwd=self.project_root,
                capture_output=True,
                text=True,
                timeout=300
            )
            
            # è§£æè¦†ç›–ç‡æŠ¥å‘Š
            coverage_file = self.project_root / "coverage.json"
            if coverage_file.exists():
                try:
                    with open(coverage_file, 'r', encoding='utf-8') as f:
                        coverage_data = json.load(f)
                    
                    total_coverage = coverage_data.get("totals", {}).get("percent_covered", 0.0)
                    
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    coverage_file.unlink()
                    
                    return total_coverage
                
                except Exception as e:
                    print(f"âš ï¸  è§£æè¦†ç›–ç‡æŠ¥å‘Šå¤±è´¥: {e}")
                    return 0.0
            
            return 0.0
        
        except Exception as e:
            print(f"âš ï¸  è¦†ç›–ç‡åˆ†æå¤±è´¥: {e}")
            return 0.0
    
    async def run_all_tests(self, include_coverage: bool = True, 
                           parallel: bool = True) -> TestReport:
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹è¿è¡Œæµ‹è¯•å¥—ä»¶...")
        
        # å‘ç°æµ‹è¯•
        test_categories = self.discover_tests()
        
        print(f"ğŸ“‹ å‘ç°æµ‹è¯•:")
        for category, files in test_categories.items():
            print(f"   {category}: {len(files)} ä¸ªæ–‡ä»¶")
        
        # è¿è¡Œæµ‹è¯•å¥—ä»¶
        test_suites = []
        
        if parallel and len(test_categories) > 1:
            # å¹¶è¡Œè¿è¡Œ
            tasks = []
            for category, files in test_categories.items():
                if files:
                    task = self.run_pytest_suite(category, files)
                    tasks.append(task)
            
            if tasks:
                test_suites = await asyncio.gather(*tasks)
        else:
            # ä¸²è¡Œè¿è¡Œ
            for category, files in test_categories.items():
                if files:
                    suite = await self.run_pytest_suite(category, files)
                    test_suites.append(suite)
        
        # è¿è¡Œè¦†ç›–ç‡åˆ†æ
        overall_coverage = 0.0
        if include_coverage:
            overall_coverage = await self.run_coverage_analysis()
        
        # è·å–é¡¹ç›®ä¿¡æ¯
        project_info = {
            "name": "HarborAI",
            "version": "1.0.0",
            "python_version": f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}",
            "platform": sys.platform
        }
        
        # åˆ›å»ºæµ‹è¯•æŠ¥å‘Š
        report = TestReport(
            timestamp=datetime.now(timezone.utc),
            project_info=project_info,
            test_suites=test_suites,
            overall_coverage=overall_coverage
        )
        
        return report
    
    def print_test_report(self, report: TestReport):
        """æ‰“å°æµ‹è¯•æŠ¥å‘Š"""
        print("\n" + "="*80)
        print("ğŸ§ª HarborAI æµ‹è¯•æŠ¥å‘Š")
        print("="*80)
        
        print(f"\nğŸ“… æµ‹è¯•æ—¶é—´: {report.timestamp.strftime('%Y-%m-%d %H:%M:%S UTC')}")
        print(f"ğŸ Pythonç‰ˆæœ¬: {report.project_info['python_version']}")
        print(f"ğŸ’» å¹³å°: {report.project_info['platform']}")
        
        # æ€»ä½“ç»Ÿè®¡
        print(f"\nğŸ“Š æ€»ä½“ç»Ÿè®¡:")
        print(f"   æ€»æµ‹è¯•æ•°: {report.total_tests}")
        print(f"   âœ… é€šè¿‡: {report.total_pass}")
        print(f"   âŒ å¤±è´¥: {report.total_fail}")
        print(f"   â­ï¸  è·³è¿‡: {report.total_skip}")
        print(f"   ğŸ’¥ é”™è¯¯: {report.total_error}")
        print(f"   â±ï¸  æ€»è€—æ—¶: {report.total_duration:.2f}s")
        print(f"   ğŸ“ˆ è¦†ç›–ç‡: {report.overall_coverage:.1f}%")
        
        # æˆåŠŸç‡
        if report.total_tests > 0:
            success_rate = (report.total_pass / report.total_tests) * 100
            print(f"   ğŸ¯ æˆåŠŸç‡: {success_rate:.1f}%")
            
            if success_rate == 100:
                status_emoji = "ğŸŸ¢"
                status_text = "å…¨éƒ¨é€šè¿‡"
            elif success_rate >= 90:
                status_emoji = "ğŸŸ¡"
                status_text = "åŸºæœ¬é€šè¿‡"
            elif success_rate >= 70:
                status_emoji = "ğŸŸ "
                status_text = "éƒ¨åˆ†å¤±è´¥"
            else:
                status_emoji = "ğŸ”´"
                status_text = "å¤§é‡å¤±è´¥"
            
            print(f"   ğŸ“Š æµ‹è¯•çŠ¶æ€: {status_emoji} {status_text}")
        
        # å„å¥—ä»¶è¯¦æƒ…
        print(f"\nğŸ“‹ æµ‹è¯•å¥—ä»¶è¯¦æƒ…:")
        for suite in report.test_suites:
            print(f"\n   ğŸ“¦ {suite.name}:")
            print(f"      æµ‹è¯•æ•°: {len(suite.tests)}")
            print(f"      é€šè¿‡: {suite.pass_count}")
            print(f"      å¤±è´¥: {suite.fail_count}")
            print(f"      è·³è¿‡: {suite.skip_count}")
            print(f"      é”™è¯¯: {suite.error_count}")
            print(f"      è€—æ—¶: {suite.total_duration:.2f}s")
            
            # æ˜¾ç¤ºå¤±è´¥çš„æµ‹è¯•
            failed_tests = [t for t in suite.tests if t.status in ["fail", "error"]]
            if failed_tests:
                print(f"      âŒ å¤±è´¥æµ‹è¯•:")
                for test in failed_tests[:5]:  # æœ€å¤šæ˜¾ç¤º5ä¸ª
                    print(f"         - {test.name}: {test.error[:100]}...")
                
                if len(failed_tests) > 5:
                    print(f"         ... è¿˜æœ‰ {len(failed_tests) - 5} ä¸ªå¤±è´¥æµ‹è¯•")
        
        # è¦†ç›–ç‡è¯„ä¼°
        if report.overall_coverage > 0:
            print(f"\nğŸ“ˆ è¦†ç›–ç‡è¯„ä¼°:")
            if report.overall_coverage >= 90:
                coverage_status = "ğŸŸ¢ ä¼˜ç§€"
            elif report.overall_coverage >= 80:
                coverage_status = "ğŸŸ¡ è‰¯å¥½"
            elif report.overall_coverage >= 70:
                coverage_status = "ğŸŸ  ä¸€èˆ¬"
            else:
                coverage_status = "ğŸ”´ éœ€è¦æ”¹è¿›"
            
            print(f"   çŠ¶æ€: {coverage_status} ({report.overall_coverage:.1f}%)")
        
        print("\n" + "="*80)
    
    def save_report(self, report: TestReport, output_file: Path):
        """ä¿å­˜æµ‹è¯•æŠ¥å‘Š"""
        report_data = {
            "timestamp": report.timestamp.isoformat(),
            "project_info": report.project_info,
            "overall_coverage": report.overall_coverage,
            "total_duration": report.total_duration,
            "total_tests": report.total_tests,
            "total_pass": report.total_pass,
            "total_fail": report.total_fail,
            "total_skip": report.total_skip,
            "total_error": report.total_error,
            "test_suites": []
        }
        
        for suite in report.test_suites:
            suite_data = {
                "name": suite.name,
                "total_duration": suite.total_duration,
                "pass_count": suite.pass_count,
                "fail_count": suite.fail_count,
                "skip_count": suite.skip_count,
                "error_count": suite.error_count,
                "coverage": suite.coverage,
                "tests": [asdict(test) for test in suite.tests]
            }
            report_data["test_suites"].append(suite_data)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="HarborAI æµ‹è¯•è¿è¡Œå·¥å…·")
    parser.add_argument("--no-coverage", action="store_true", help="è·³è¿‡è¦†ç›–ç‡åˆ†æ")
    parser.add_argument("--no-parallel", action="store_true", help="ä¸²è¡Œè¿è¡Œæµ‹è¯•")
    parser.add_argument("--output", help="è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶è·¯å¾„ï¼ˆJSONæ ¼å¼ï¼‰")
    parser.add_argument("--category", choices=["unit", "integration", "performance"], 
                       help="åªè¿è¡ŒæŒ‡å®šç±»åˆ«çš„æµ‹è¯•")
    parser.add_argument("--verbose", action="store_true", help="è¯¦ç»†è¾“å‡º")
    
    args = parser.parse_args()
    
    # åˆ›å»ºæµ‹è¯•è¿è¡Œå™¨
    runner = TestRunner(project_root)
    
    try:
        # å¦‚æœæŒ‡å®šäº†ç±»åˆ«ï¼Œåªè¿è¡Œè¯¥ç±»åˆ«çš„æµ‹è¯•
        if args.category:
            test_categories = runner.discover_tests()
            if args.category in test_categories:
                files = test_categories[args.category]
                if files:
                    suite = await runner.run_pytest_suite(args.category, files)
                    
                    # åˆ›å»ºç®€åŒ–æŠ¥å‘Š
                    report = TestReport(
                        timestamp=datetime.now(timezone.utc),
                        project_info={
                            "name": "HarborAI",
                            "version": "1.0.0",
                            "python_version": f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}",
                            "platform": sys.platform
                        },
                        test_suites=[suite]
                    )
                else:
                    print(f"âŒ æ²¡æœ‰æ‰¾åˆ° {args.category} ç±»åˆ«çš„æµ‹è¯•")
                    sys.exit(1)
            else:
                print(f"âŒ æœªçŸ¥çš„æµ‹è¯•ç±»åˆ«: {args.category}")
                sys.exit(1)
        else:
            # è¿è¡Œæ‰€æœ‰æµ‹è¯•
            report = await runner.run_all_tests(
                include_coverage=not args.no_coverage,
                parallel=not args.no_parallel
            )
        
        # æ‰“å°æŠ¥å‘Š
        runner.print_test_report(report)
        
        # ä¿å­˜æŠ¥å‘Š
        if args.output:
            runner.save_report(report, Path(args.output))
        
        # æ ¹æ®æµ‹è¯•ç»“æœè®¾ç½®é€€å‡ºç 
        if report.total_fail > 0 or report.total_error > 0:
            sys.exit(1)  # æœ‰å¤±è´¥æˆ–é”™è¯¯
        elif report.total_tests == 0:
            sys.exit(2)  # æ²¡æœ‰æµ‹è¯•
        else:
            sys.exit(0)  # æˆåŠŸ
    
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿è¡Œå¤±è´¥: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        sys.exit(3)


if __name__ == "__main__":
    asyncio.run(main())