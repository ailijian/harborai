#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HarborAI ç»“æ„åŒ–è¾“å‡ºæ€§èƒ½åŸºå‡†æµ‹è¯•
ä¸“é—¨æµ‹è¯•FASTæ¨¡å¼ä¸‹çš„æ€§èƒ½ä¼˜åŒ–æ•ˆæœ

æµ‹è¯•ç›®æ ‡ï¼š
1. éªŒè¯FASTæ¨¡å¼ä¸‹çš„æ€§èƒ½æ¥è¿‘ç›´æ¥Agentlyè°ƒç”¨
2. æµ‹è¯•å®¢æˆ·ç«¯æ± ã€Schemaç¼“å­˜ç­‰ä¼˜åŒ–ç»„ä»¶çš„æ•ˆæœ
3. å»ºç«‹æ€§èƒ½åŸºå‡†æ•°æ®
4. è¯†åˆ«æ€§èƒ½ç“¶é¢ˆå¹¶æä¾›ä¼˜åŒ–å»ºè®®

éµå¾ªTDDåŸåˆ™ï¼š
- å…ˆå†™å¤±è´¥æµ‹è¯•ï¼ˆæ€§èƒ½ç›®æ ‡ï¼‰
- å®ç°ä¼˜åŒ–
- éªŒè¯æ€§èƒ½æå‡
"""

import os
import sys
import time
import json
import statistics
import tracemalloc
import psutil
import threading
from contextlib import contextmanager
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime

# è®¾ç½®æ§åˆ¶å°ç¼–ç 
if sys.platform == "win32":
    import codecs
    sys.stdout = codecs.getwriter("utf-8")(sys.stdout.detach())
    sys.stderr = codecs.getwriter("utf-8")(sys.stderr.detach())

# å¯¼å…¥ä¾èµ–
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# è®¾ç½®FASTæ¨¡å¼ç¯å¢ƒå˜é‡ï¼ˆå¿…é¡»åœ¨å¯¼å…¥HarborAIä¹‹å‰è®¾ç½®ï¼‰
os.environ["HARBORAI_PERFORMANCE_MODE"] = "fast"
os.environ["HARBORAI_ENABLE_FAST_PATH"] = "true"
os.environ["HARBORAI_ENABLE_CLIENT_POOL"] = "true"
os.environ["HARBORAI_ENABLE_SCHEMA_CACHE"] = "true"
os.environ["HARBORAI_ENABLE_CONFIG_CACHE"] = "true"

print(f"ğŸš€ è®¾ç½®æ€§èƒ½æ¨¡å¼: FAST")
print(f"ğŸš€ å¯ç”¨æ‰€æœ‰ä¼˜åŒ–ç»„ä»¶")

# å¯¼å…¥æµ‹è¯•åº“
from agently import Agently
from harborai import HarborAI

# æ¸…é™¤ç¼“å­˜ä»¥ç¡®ä¿ç¯å¢ƒå˜é‡ç”Ÿæ•ˆ
from harborai.config.settings import get_settings
from harborai.config.performance import reset_performance_config, PerformanceMode

get_settings.cache_clear()
reset_performance_config(PerformanceMode.FAST)


@dataclass
class BenchmarkResult:
    """åŸºå‡†æµ‹è¯•ç»“æœ"""
    test_name: str
    avg_duration: float
    min_duration: float
    max_duration: float
    std_deviation: float
    success_rate: float
    memory_usage: float
    cpu_usage: float
    iterations: int
    cache_hit_rate: Optional[float] = None
    client_pool_hit_rate: Optional[float] = None


class PerformanceBenchmark:
    """æ€§èƒ½åŸºå‡†æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.process = psutil.Process()
        self.results: List[BenchmarkResult] = []
        
        # æµ‹è¯•é…ç½®
        self.test_schema = {
            "type": "object",
            "properties": {
                "name": {"type": "string", "description": "ç”¨æˆ·å§“å"},
                "age": {"type": "integer", "description": "ç”¨æˆ·å¹´é¾„"},
                "email": {"type": "string", "description": "ç”¨æˆ·é‚®ç®±"},
                "skills": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "æŠ€èƒ½åˆ—è¡¨"
                }
            },
            "required": ["name", "age", "email"]
        }
        
        self.test_query = "è¯·ç”Ÿæˆä¸€ä¸ªè½¯ä»¶å·¥ç¨‹å¸ˆçš„ä¸ªäººä¿¡æ¯ï¼ŒåŒ…æ‹¬å§“åã€å¹´é¾„ã€é‚®ç®±å’ŒæŠ€èƒ½åˆ—è¡¨"
        
        # æ€§èƒ½ç›®æ ‡ï¼ˆåŸºäºTDDåŸåˆ™çš„å¤±è´¥æµ‹è¯•ï¼‰
        self.performance_targets = {
            "harborai_fast_avg_duration": 2.0,  # ç›®æ ‡ï¼šå¹³å‡2ç§’å†…å®Œæˆ
            "harborai_vs_agently_ratio": 1.2,   # ç›®æ ‡ï¼šä¸è¶…è¿‡ç›´æ¥Agentlyè°ƒç”¨çš„1.2å€
            "cache_hit_rate_after_warmup": 0.8,  # ç›®æ ‡ï¼šé¢„çƒ­å80%ç¼“å­˜å‘½ä¸­ç‡
            "client_pool_hit_rate": 0.9,         # ç›®æ ‡ï¼š90%å®¢æˆ·ç«¯æ± å‘½ä¸­ç‡
        }
    
    def get_memory_usage(self) -> float:
        """è·å–å½“å‰å†…å­˜ä½¿ç”¨é‡(MB)"""
        try:
            return self.process.memory_info().rss / 1024 / 1024
        except:
            return 0.0
    
    def get_cpu_percent(self) -> float:
        """è·å–CPUä½¿ç”¨ç‡"""
        try:
            return self.process.cpu_percent()
        except:
            return 0.0
    
    @contextmanager
    def monitor_performance(self):
        """æ€§èƒ½ç›‘æ§ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        tracemalloc.start()
        start_memory = self.get_memory_usage()
        start_cpu = self.get_cpu_percent()
        start_time = time.time()
        
        try:
            yield
        finally:
            end_time = time.time()
            end_memory = self.get_memory_usage()
            end_cpu = self.get_cpu_percent()
            
            if tracemalloc.is_tracing():
                tracemalloc.stop()
    
    def test_agently_direct(self, iterations: int = 5) -> BenchmarkResult:
        """æµ‹è¯•ç›´æ¥Agentlyè°ƒç”¨æ€§èƒ½ï¼ˆä½œä¸ºåŸºå‡†ï¼‰"""
        print(f"\nğŸ” æµ‹è¯•ç›´æ¥Agentlyè°ƒç”¨æ€§èƒ½ (iterations={iterations})")
        
        durations = []
        success_count = 0
        memory_usage = 0
        cpu_usage = 0
        
        # é…ç½®Agently
        Agently.set_settings(
            "OpenAICompatible",
            {
                "base_url": "https://ark.cn-beijing.volces.com/api/v3",
                "model": "doubao-1-5-pro-32k-character-250715",
                "model_type": "chat",
                "auth": os.getenv("DOUBAO_API_KEY"),
            },
        )
        
        # è½¬æ¢Schemaä¸ºAgentlyæ ¼å¼
        agently_output = {
            "output": {
                "name": ("str", "ç”¨æˆ·å§“å"),
                "age": ("int", "ç”¨æˆ·å¹´é¾„"),
                "email": ("str", "ç”¨æˆ·é‚®ç®±"),
                "skills": ("[str]", "æŠ€èƒ½åˆ—è¡¨")
            }
        }
        
        for i in range(iterations):
            print(f"  æ‰§è¡Œç¬¬ {i+1}/{iterations} æ¬¡æµ‹è¯•...")
            
            with self.monitor_performance():
                start_time = time.time()
                
                try:
                    agent = Agently.create_agent()
                    result = (
                        agent
                        .input(self.test_query)
                        .output(agently_output)
                        .start()
                    )
                    
                    end_time = time.time()
                    duration = end_time - start_time
                    durations.append(duration)
                    success_count += 1
                    
                    memory_usage += self.get_memory_usage()
                    cpu_usage += self.get_cpu_percent()
                    
                    print(f"    âœ… æˆåŠŸï¼Œè€—æ—¶: {duration:.2f}s")
                    
                except Exception as e:
                    print(f"    âŒ å¤±è´¥: {e}")
        
        if not durations:
            raise RuntimeError("æ‰€æœ‰Agentlyæµ‹è¯•éƒ½å¤±è´¥äº†")
        
        return BenchmarkResult(
            test_name="Agentlyç›´æ¥è°ƒç”¨",
            avg_duration=statistics.mean(durations),
            min_duration=min(durations),
            max_duration=max(durations),
            std_deviation=statistics.stdev(durations) if len(durations) > 1 else 0,
            success_rate=success_count / iterations,
            memory_usage=memory_usage / iterations,
            cpu_usage=cpu_usage / iterations,
            iterations=iterations
        )
    
    def test_harborai_fast_mode(self, iterations: int = 5) -> BenchmarkResult:
        """æµ‹è¯•HarborAI FASTæ¨¡å¼æ€§èƒ½"""
        print(f"\nğŸš€ æµ‹è¯•HarborAI FASTæ¨¡å¼æ€§èƒ½ (iterations={iterations})")
        
        durations = []
        success_count = 0
        memory_usage = 0
        cpu_usage = 0
        
        # åˆ›å»ºHarborAIå®¢æˆ·ç«¯
        client = HarborAI(
            api_key=os.getenv("DOUBAO_API_KEY"),
            base_url="https://ark.cn-beijing.volces.com/api/v3"
        )
        
        for i in range(iterations):
            print(f"  æ‰§è¡Œç¬¬ {i+1}/{iterations} æ¬¡æµ‹è¯•...")
            
            with self.monitor_performance():
                start_time = time.time()
                
                try:
                    response = client.chat.completions.create(
                        model="doubao-1-5-pro-32k-character-250715",
                        messages=[
                            {"role": "user", "content": self.test_query}
                        ],
                        response_format={
                            "type": "json_schema",
                            "json_schema": {
                                "name": "user_info",
                                "schema": self.test_schema
                            }
                        },
                        structured_provider="agently",
                        temperature=0.1
                    )
                    
                    end_time = time.time()
                    duration = end_time - start_time
                    durations.append(duration)
                    success_count += 1
                    
                    memory_usage += self.get_memory_usage()
                    cpu_usage += self.get_cpu_percent()
                    
                    print(f"    âœ… æˆåŠŸï¼Œè€—æ—¶: {duration:.2f}s")
                    
                except Exception as e:
                    print(f"    âŒ å¤±è´¥: {e}")
        
        if not durations:
            raise RuntimeError("æ‰€æœ‰HarborAIæµ‹è¯•éƒ½å¤±è´¥äº†")
        
        # å°è¯•è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
        cache_hit_rate = None
        client_pool_hit_rate = None
        
        try:
            from harborai.core.parameter_cache import get_parameter_cache_manager
            from harborai.core.agently_client_pool import get_agently_client_pool
            
            cache_manager = get_parameter_cache_manager()
            if cache_manager:
                schema_stats = cache_manager.schema_cache.get_stats()
                if schema_stats.get('total_requests', 0) > 0:
                    cache_hit_rate = schema_stats.get('cache_hits', 0) / schema_stats.get('total_requests', 1)
            
            client_pool = get_agently_client_pool()
            if client_pool:
                pool_stats = client_pool.get_stats()
                if pool_stats.get('total_requests', 0) > 0:
                    client_pool_hit_rate = pool_stats.get('cache_hits', 0) / pool_stats.get('total_requests', 1)
        except Exception as e:
            print(f"    âš ï¸ æ— æ³•è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯: {e}")
        
        return BenchmarkResult(
            test_name="HarborAI FASTæ¨¡å¼",
            avg_duration=statistics.mean(durations),
            min_duration=min(durations),
            max_duration=max(durations),
            std_deviation=statistics.stdev(durations) if len(durations) > 1 else 0,
            success_rate=success_count / iterations,
            memory_usage=memory_usage / iterations,
            cpu_usage=cpu_usage / iterations,
            iterations=iterations,
            cache_hit_rate=cache_hit_rate,
            client_pool_hit_rate=client_pool_hit_rate
        )
    
    def test_cache_warmup_effect(self, warmup_iterations: int = 3, test_iterations: int = 5) -> Tuple[BenchmarkResult, BenchmarkResult]:
        """æµ‹è¯•ç¼“å­˜é¢„çƒ­æ•ˆæœ"""
        print(f"\nğŸ”¥ æµ‹è¯•ç¼“å­˜é¢„çƒ­æ•ˆæœ")
        print(f"  é¢„çƒ­è½®æ¬¡: {warmup_iterations}, æµ‹è¯•è½®æ¬¡: {test_iterations}")
        
        # å†·å¯åŠ¨æµ‹è¯•
        cold_result = self.test_harborai_fast_mode(iterations=test_iterations)
        cold_result.test_name = "HarborAI FASTæ¨¡å¼ (å†·å¯åŠ¨)"
        
        # é¢„çƒ­
        print(f"\nğŸ”¥ æ‰§è¡Œç¼“å­˜é¢„çƒ­...")
        self.test_harborai_fast_mode(iterations=warmup_iterations)
        
        # é¢„çƒ­åæµ‹è¯•
        warm_result = self.test_harborai_fast_mode(iterations=test_iterations)
        warm_result.test_name = "HarborAI FASTæ¨¡å¼ (é¢„çƒ­å)"
        
        return cold_result, warm_result
    
    def run_full_benchmark(self) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´çš„æ€§èƒ½åŸºå‡†æµ‹è¯•"""
        print("ğŸ¯ å¼€å§‹HarborAIç»“æ„åŒ–è¾“å‡ºæ€§èƒ½åŸºå‡†æµ‹è¯•")
        print("=" * 60)
        
        results = {}
        
        try:
            # 1. æµ‹è¯•ç›´æ¥Agentlyè°ƒç”¨ï¼ˆåŸºå‡†ï¼‰
            agently_result = self.test_agently_direct(iterations=5)
            results['agently_baseline'] = agently_result
            self.results.append(agently_result)
            
            # 2. æµ‹è¯•HarborAI FASTæ¨¡å¼
            harborai_result = self.test_harborai_fast_mode(iterations=5)
            results['harborai_fast'] = harborai_result
            self.results.append(harborai_result)
            
            # 3. æµ‹è¯•ç¼“å­˜é¢„çƒ­æ•ˆæœ
            cold_result, warm_result = self.test_cache_warmup_effect(warmup_iterations=3, test_iterations=5)
            results['harborai_cold'] = cold_result
            results['harborai_warm'] = warm_result
            self.results.extend([cold_result, warm_result])
            
            # 4. æ€§èƒ½åˆ†æ
            analysis = self.analyze_performance(results)
            results['analysis'] = analysis
            
            # 5. TDDéªŒè¯ï¼ˆæ£€æŸ¥æ˜¯å¦è¾¾åˆ°æ€§èƒ½ç›®æ ‡ï¼‰
            tdd_results = self.verify_performance_targets(results)
            results['tdd_verification'] = tdd_results
            
            return results
            
        except Exception as e:
            print(f"âŒ åŸºå‡†æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return {"error": str(e)}
    
    def analyze_performance(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†ææ€§èƒ½ç»“æœ"""
        print(f"\nğŸ“Š æ€§èƒ½åˆ†æ")
        print("-" * 40)
        
        analysis = {}
        
        # åŸºæœ¬æ€§èƒ½å¯¹æ¯”
        agently_baseline = results.get('agently_baseline')
        harborai_fast = results.get('harborai_fast')
        
        if agently_baseline and harborai_fast:
            performance_ratio = harborai_fast.avg_duration / agently_baseline.avg_duration
            analysis['performance_ratio'] = performance_ratio
            
            print(f"ğŸ“ˆ æ€§èƒ½å¯¹æ¯”:")
            print(f"  AgentlyåŸºå‡†: {agently_baseline.avg_duration:.2f}s")
            print(f"  HarborAI FAST: {harborai_fast.avg_duration:.2f}s")
            print(f"  æ€§èƒ½æ¯”ç‡: {performance_ratio:.2f}x")
            
            if performance_ratio <= 1.2:
                print(f"  âœ… æ€§èƒ½ä¼˜ç§€ (â‰¤1.2x)")
            elif performance_ratio <= 1.5:
                print(f"  âš ï¸ æ€§èƒ½å¯æ¥å— (â‰¤1.5x)")
            else:
                print(f"  âŒ æ€§èƒ½éœ€è¦ä¼˜åŒ– (>1.5x)")
        
        # ç¼“å­˜æ•ˆæœåˆ†æ
        harborai_cold = results.get('harborai_cold')
        harborai_warm = results.get('harborai_warm')
        
        if harborai_cold and harborai_warm:
            cache_improvement = (harborai_cold.avg_duration - harborai_warm.avg_duration) / harborai_cold.avg_duration
            analysis['cache_improvement'] = cache_improvement
            
            print(f"\nğŸ”¥ ç¼“å­˜æ•ˆæœ:")
            print(f"  å†·å¯åŠ¨: {harborai_cold.avg_duration:.2f}s")
            print(f"  é¢„çƒ­å: {harborai_warm.avg_duration:.2f}s")
            print(f"  æ€§èƒ½æå‡: {cache_improvement*100:.1f}%")
            
            if harborai_warm.cache_hit_rate:
                print(f"  ç¼“å­˜å‘½ä¸­ç‡: {harborai_warm.cache_hit_rate*100:.1f}%")
            
            if harborai_warm.client_pool_hit_rate:
                print(f"  å®¢æˆ·ç«¯æ± å‘½ä¸­ç‡: {harborai_warm.client_pool_hit_rate*100:.1f}%")
        
        return analysis
    
    def verify_performance_targets(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯æ€§èƒ½ç›®æ ‡ï¼ˆTDDåŸåˆ™ï¼‰"""
        print(f"\nğŸ¯ TDDæ€§èƒ½ç›®æ ‡éªŒè¯")
        print("-" * 40)
        
        verification = {}
        passed_tests = 0
        total_tests = 0
        
        harborai_fast = results.get('harborai_fast')
        harborai_warm = results.get('harborai_warm')
        analysis = results.get('analysis', {})
        
        # æµ‹è¯•1: HarborAI FASTæ¨¡å¼å¹³å‡å“åº”æ—¶é—´
        total_tests += 1
        target = self.performance_targets['harborai_fast_avg_duration']
        actual = harborai_fast.avg_duration if harborai_fast else float('inf')
        passed = actual <= target
        
        verification['avg_duration_test'] = {
            'target': f"â‰¤{target}s",
            'actual': f"{actual:.2f}s",
            'passed': passed
        }
        
        if passed:
            passed_tests += 1
            print(f"  âœ… å¹³å‡å“åº”æ—¶é—´: {actual:.2f}s â‰¤ {target}s")
        else:
            print(f"  âŒ å¹³å‡å“åº”æ—¶é—´: {actual:.2f}s > {target}s")
        
        # æµ‹è¯•2: HarborAI vs Agentlyæ€§èƒ½æ¯”ç‡
        total_tests += 1
        target = self.performance_targets['harborai_vs_agently_ratio']
        actual = analysis.get('performance_ratio', float('inf'))
        passed = actual <= target
        
        verification['performance_ratio_test'] = {
            'target': f"â‰¤{target}x",
            'actual': f"{actual:.2f}x",
            'passed': passed
        }
        
        if passed:
            passed_tests += 1
            print(f"  âœ… æ€§èƒ½æ¯”ç‡: {actual:.2f}x â‰¤ {target}x")
        else:
            print(f"  âŒ æ€§èƒ½æ¯”ç‡: {actual:.2f}x > {target}x")
        
        # æµ‹è¯•3: ç¼“å­˜å‘½ä¸­ç‡
        if harborai_warm and harborai_warm.cache_hit_rate is not None:
            total_tests += 1
            target = self.performance_targets['cache_hit_rate_after_warmup']
            actual = harborai_warm.cache_hit_rate
            passed = actual >= target
            
            verification['cache_hit_rate_test'] = {
                'target': f"â‰¥{target*100:.0f}%",
                'actual': f"{actual*100:.1f}%",
                'passed': passed
            }
            
            if passed:
                passed_tests += 1
                print(f"  âœ… ç¼“å­˜å‘½ä¸­ç‡: {actual*100:.1f}% â‰¥ {target*100:.0f}%")
            else:
                print(f"  âŒ ç¼“å­˜å‘½ä¸­ç‡: {actual*100:.1f}% < {target*100:.0f}%")
        
        # æµ‹è¯•4: å®¢æˆ·ç«¯æ± å‘½ä¸­ç‡
        if harborai_warm and harborai_warm.client_pool_hit_rate is not None:
            total_tests += 1
            target = self.performance_targets['client_pool_hit_rate']
            actual = harborai_warm.client_pool_hit_rate
            passed = actual >= target
            
            verification['client_pool_hit_rate_test'] = {
                'target': f"â‰¥{target*100:.0f}%",
                'actual': f"{actual*100:.1f}%",
                'passed': passed
            }
            
            if passed:
                passed_tests += 1
                print(f"  âœ… å®¢æˆ·ç«¯æ± å‘½ä¸­ç‡: {actual*100:.1f}% â‰¥ {target*100:.0f}%")
            else:
                print(f"  âŒ å®¢æˆ·ç«¯æ± å‘½ä¸­ç‡: {actual*100:.1f}% < {target*100:.0f}%")
        
        # æ€»ä½“ç»“æœ
        verification['summary'] = {
            'passed_tests': passed_tests,
            'total_tests': total_tests,
            'success_rate': passed_tests / total_tests if total_tests > 0 else 0,
            'overall_passed': passed_tests == total_tests
        }
        
        print(f"\nğŸ“Š TDDéªŒè¯ç»“æœ: {passed_tests}/{total_tests} é€šè¿‡")
        if passed_tests == total_tests:
            print(f"  ğŸ‰ æ‰€æœ‰æ€§èƒ½ç›®æ ‡è¾¾æˆï¼")
        else:
            print(f"  âš ï¸ éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
        
        return verification
    
    def generate_report(self, results: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        report = []
        report.append("# HarborAI ç»“æ„åŒ–è¾“å‡ºæ€§èƒ½åŸºå‡†æµ‹è¯•æŠ¥å‘Š")
        report.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")
        
        # æµ‹è¯•æ¦‚è¿°
        report.append("## æµ‹è¯•æ¦‚è¿°")
        report.append("æœ¬æ¬¡æµ‹è¯•éªŒè¯HarborAI FASTæ¨¡å¼ä¸‹ç»“æ„åŒ–è¾“å‡ºçš„æ€§èƒ½ä¼˜åŒ–æ•ˆæœ")
        report.append("")
        
        # æµ‹è¯•ç»“æœ
        report.append("## æµ‹è¯•ç»“æœ")
        for name, result in results.items():
            if isinstance(result, BenchmarkResult):
                report.append(f"### {result.test_name}")
                report.append(f"- å¹³å‡è€—æ—¶: {result.avg_duration:.2f}s")
                report.append(f"- æœ€å°è€—æ—¶: {result.min_duration:.2f}s")
                report.append(f"- æœ€å¤§è€—æ—¶: {result.max_duration:.2f}s")
                report.append(f"- æ ‡å‡†å·®: {result.std_deviation:.2f}s")
                report.append(f"- æˆåŠŸç‡: {result.success_rate*100:.1f}%")
                report.append(f"- å†…å­˜ä½¿ç”¨: {result.memory_usage:.1f}MB")
                if result.cache_hit_rate is not None:
                    report.append(f"- ç¼“å­˜å‘½ä¸­ç‡: {result.cache_hit_rate*100:.1f}%")
                if result.client_pool_hit_rate is not None:
                    report.append(f"- å®¢æˆ·ç«¯æ± å‘½ä¸­ç‡: {result.client_pool_hit_rate*100:.1f}%")
                report.append("")
        
        # æ€§èƒ½åˆ†æ
        if 'analysis' in results:
            analysis = results['analysis']
            report.append("## æ€§èƒ½åˆ†æ")
            if 'performance_ratio' in analysis:
                report.append(f"- HarborAI vs Agentlyæ€§èƒ½æ¯”ç‡: {analysis['performance_ratio']:.2f}x")
            if 'cache_improvement' in analysis:
                report.append(f"- ç¼“å­˜é¢„çƒ­æ€§èƒ½æå‡: {analysis['cache_improvement']*100:.1f}%")
            report.append("")
        
        # TDDéªŒè¯ç»“æœ
        if 'tdd_verification' in results:
            verification = results['tdd_verification']
            report.append("## TDDæ€§èƒ½ç›®æ ‡éªŒè¯")
            summary = verification.get('summary', {})
            report.append(f"- é€šè¿‡æµ‹è¯•: {summary.get('passed_tests', 0)}/{summary.get('total_tests', 0)}")
            report.append(f"- æˆåŠŸç‡: {summary.get('success_rate', 0)*100:.1f}%")
            report.append(f"- æ•´ä½“ç»“æœ: {'âœ… é€šè¿‡' if summary.get('overall_passed', False) else 'âŒ éœ€è¦ä¼˜åŒ–'}")
            report.append("")
        
        return "\n".join(report)


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ HarborAI ç»“æ„åŒ–è¾“å‡ºæ€§èƒ½åŸºå‡†æµ‹è¯•")
    print("=" * 60)
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    if not os.getenv("DOUBAO_API_KEY"):
        print("âŒ é”™è¯¯: æœªè®¾ç½® DOUBAO_API_KEY ç¯å¢ƒå˜é‡")
        return
    
    # åˆ›å»ºåŸºå‡†æµ‹è¯•å™¨
    benchmark = PerformanceBenchmark()
    
    try:
        # è¿è¡ŒåŸºå‡†æµ‹è¯•
        results = benchmark.run_full_benchmark()
        
        # ç”ŸæˆæŠ¥å‘Š
        report = benchmark.generate_report(results)
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = "performance_benchmark_report.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"\nğŸ“„ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        results_file = "performance_benchmark_results.json"
        with open(results_file, 'w', encoding='utf-8') as f:
            # è½¬æ¢BenchmarkResultå¯¹è±¡ä¸ºå­—å…¸
            serializable_results = {}
            for key, value in results.items():
                if isinstance(value, BenchmarkResult):
                    serializable_results[key] = asdict(value)
                else:
                    serializable_results[key] = value
            
            json.dump(serializable_results, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“Š è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
        
        # è¿”å›TDDéªŒè¯ç»“æœ
        tdd_verification = results.get('tdd_verification', {})
        summary = tdd_verification.get('summary', {})
        
        if summary.get('overall_passed', False):
            print(f"\nğŸ‰ æ‰€æœ‰æ€§èƒ½ç›®æ ‡è¾¾æˆï¼")
            return 0
        else:
            print(f"\nâš ï¸ éƒ¨åˆ†æ€§èƒ½ç›®æ ‡æœªè¾¾æˆï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
            return 1
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)