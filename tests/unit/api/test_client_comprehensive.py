"""APIå®¢æˆ·ç«¯ç»¼åˆæµ‹è¯•ã€‚"""

import pytest
import asyncio
from unittest.mock import Mock, patch, MagicMock, AsyncMock
from typing import Dict, List, Any, Optional

from harborai.api.client import HarborAI, ChatCompletions, Chat
from harborai.core.base_plugin import ChatCompletion, ChatCompletionChunk
from harborai.utils.exceptions import HarborAIError, ValidationError


class TestChatCompletions:
    """ChatCompletionsç±»æµ‹è¯•ã€‚"""
    
    def setup_method(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒã€‚"""
        self.mock_client_manager = Mock()
        self.chat_completions = ChatCompletions(self.mock_client_manager)
    
    def test_åˆå§‹åŒ–(self):
        """æµ‹è¯•ChatCompletionsåˆå§‹åŒ–ã€‚"""
        assert self.chat_completions.client_manager == self.mock_client_manager
        assert self.chat_completions.logger is not None
        assert self.chat_completions.api_logger is not None
        assert self.chat_completions.settings is not None
    
    def test_è·å–å¿«é€Ÿå¤„ç†å™¨(self):
        """æµ‹è¯•è·å–å¿«é€Ÿç»“æ„åŒ–è¾“å‡ºå¤„ç†å™¨ã€‚"""
        with patch('harborai.core.fast_structured_output.create_fast_structured_output_processor') as mock_create:
            mock_processor = Mock()
            mock_create.return_value = mock_processor
            
            processor = self.chat_completions._get_fast_processor()
            
            assert processor == mock_processor
            mock_create.assert_called_once_with(client_manager=self.mock_client_manager)
            
            # æµ‹è¯•ç¼“å­˜
            processor2 = self.chat_completions._get_fast_processor()
            assert processor2 == mock_processor
            assert mock_create.call_count == 1  # åªè°ƒç”¨ä¸€æ¬¡
    
    @patch('harborai.api.client.get_performance_config')
    def test_create_åŸºæœ¬è°ƒç”¨(self, mock_get_perf_config):
        """æµ‹è¯•åŸºæœ¬çš„createè°ƒç”¨ã€‚"""
        mock_get_perf_config.return_value = Mock(
            enable_fast_path=False,
            enable_structured_output_optimization=False
        )
        
        with patch.object(self.chat_completions, '_create_core') as mock_create_core:
            mock_response = Mock(spec=ChatCompletion)
            mock_create_core.return_value = mock_response
            
            messages = [{"role": "user", "content": "Hello"}]
            result = self.chat_completions.create(messages=messages, model="gpt-3.5-turbo")
            
            assert result == mock_response
            mock_create_core.assert_called_once()
    
    @patch('harborai.api.client.get_performance_config')
    def test_create_å¿«é€Ÿè·¯å¾„(self, mock_get_perf_config):
        """æµ‹è¯•å¿«é€Ÿè·¯å¾„è°ƒç”¨ã€‚"""
        mock_get_perf_config.return_value = Mock(
            enable_fast_path=True,
            enable_structured_output_optimization=False
        )
        
        with patch.object(self.chat_completions, '_create_core') as mock_create_core:
            mock_response = Mock(spec=ChatCompletion)
            mock_create_core.return_value = mock_response
            
            messages = [{"role": "user", "content": "Hello"}]
            result = self.chat_completions.create(messages=messages, model="gpt-3.5-turbo")
            
            assert result == mock_response
            mock_create_core.assert_called_once()
    
    @patch('harborai.api.client.get_performance_config')
    def test_create_ç»“æ„åŒ–è¾“å‡ºä¼˜åŒ–(self, mock_get_perf_config):
        """æµ‹è¯•ç»“æ„åŒ–è¾“å‡ºä¼˜åŒ–è·¯å¾„ã€‚"""
        mock_get_perf_config.return_value = Mock(
            enable_fast_path=True,
            enable_structured_output_optimization=True
        )
        
        with patch.object(self.chat_completions, '_create_core') as mock_create_core:
            mock_response = Mock(spec=ChatCompletion)
            mock_create_core.return_value = mock_response
            
            messages = [{"role": "user", "content": "Hello"}]
            response_format = {"type": "json_object"}
            result = self.chat_completions.create(
                messages=messages, 
                model="gpt-3.5-turbo",
                response_format=response_format,
                structured_provider="openai"
            )
            
            assert result == mock_response
            mock_create_core.assert_called_once()
    
    def test_validate_messages_æœ‰æ•ˆæ¶ˆæ¯(self):
        """æµ‹è¯•æœ‰æ•ˆæ¶ˆæ¯éªŒè¯ã€‚"""
        valid_messages = [
            {"role": "user", "content": "Hello"},
            {"role": "assistant", "content": "Hi there!"}
        ]
        
        # ä¸åº”è¯¥æŠ›å‡ºå¼‚å¸¸
        self.chat_completions._validate_messages(valid_messages)
    
    def test_validate_messages_ç©ºæ¶ˆæ¯åˆ—è¡¨(self):
        """æµ‹è¯•ç©ºæ¶ˆæ¯åˆ—è¡¨éªŒè¯ã€‚"""
        with pytest.raises(ValidationError, match="Messages cannot be empty"):
            self.chat_completions._validate_messages([])
    
    def test_validate_messages_æ— æ•ˆè§’è‰²(self):
        """æµ‹è¯•æ— æ•ˆè§’è‰²éªŒè¯ã€‚"""
        invalid_messages = [
            {"role": "invalid_role", "content": "Hello"}
        ]
        
        with pytest.raises(ValidationError, match="has invalid role.*invalid_role"):
            self.chat_completions._validate_messages(invalid_messages)
    
    def test_validate_messages_ç¼ºå°‘å†…å®¹(self):
        """æµ‹è¯•ç¼ºå°‘å†…å®¹éªŒè¯ã€‚"""
        invalid_messages = [
            {"role": "user"}  # ç¼ºå°‘content
        ]
        
        with pytest.raises(ValidationError, match="Message at index 0 must have either"):
            self.chat_completions._validate_messages(invalid_messages)
    
    def test_process_messages_for_reasoning_model(self):
        """æµ‹è¯•æ¨ç†æ¨¡å‹æ¶ˆæ¯å¤„ç†ã€‚"""
        messages = [
            {"role": "user", "content": "Solve this problem", "reasoning_content": "Think step by step"}
        ]
        
        processed = self.chat_completions._process_messages_for_reasoning_model(messages)
        
        assert len(processed) == 1
        assert processed[0]["role"] == "user"
        assert "reasoning_content" in processed[0]
    
    @pytest.mark.asyncio
    @patch('harborai.api.client.get_performance_config')
    async def test_acreate_åŸºæœ¬è°ƒç”¨(self, mock_get_perf_config):
        """æµ‹è¯•å¼‚æ­¥åŸºæœ¬è°ƒç”¨ã€‚"""
        mock_get_perf_config.return_value = Mock(
            enable_fast_path=False,
            enable_structured_output_optimization=False
        )
        
        with patch.object(self.chat_completions, '_acreate_core') as mock_acreate_core:
            mock_response = Mock(spec=ChatCompletion)
            mock_acreate_core.return_value = mock_response
            
            messages = [{"role": "user", "content": "Hello"}]
            result = await self.chat_completions.acreate(messages=messages, model="gpt-3.5-turbo")
            
            assert result == mock_response
            mock_acreate_core.assert_called_once()


class TestChat:
    """Chatç±»æµ‹è¯•ã€‚"""
    
    def test_åˆå§‹åŒ–(self):
        """æµ‹è¯•Chatåˆå§‹åŒ–ã€‚"""
        mock_client_manager = Mock()
        chat = Chat(mock_client_manager)
        
        assert isinstance(chat.completions, ChatCompletions)
        assert chat.completions.client_manager == mock_client_manager


class TestHarborAI:
    """HarborAIä¸»å®¢æˆ·ç«¯æµ‹è¯•ã€‚"""
    
    def setup_method(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒã€‚"""
        with patch('harborai.api.client.ClientManager') as mock_cm_class:
            self.mock_client_manager = Mock()
            # è®¾ç½®å¯è¿­ä»£çš„å±æ€§
            self.mock_client_manager.plugins = {"openai": Mock(), "claude": Mock()}
            self.mock_client_manager.model_to_plugin = {"gpt-3.5-turbo": "openai", "claude-3": "claude"}
            # è®¾ç½®å¼‚æ­¥æ–¹æ³•
            self.mock_client_manager.aclose = AsyncMock()
            mock_cm_class.return_value = self.mock_client_manager
            
            self.client = HarborAI(api_key="test-key")
    
    def test_åˆå§‹åŒ–åŸºæœ¬å‚æ•°(self):
        """æµ‹è¯•åŸºæœ¬å‚æ•°åˆå§‹åŒ–ã€‚"""
        with patch('harborai.api.client.ClientManager') as mock_cm_class:
            mock_client_manager = Mock()
            # è®¾ç½®å¯è¿­ä»£çš„å±æ€§
            mock_client_manager.plugins = {"openai": Mock(), "claude": Mock()}
            mock_client_manager.model_to_plugin = {"gpt-3.5-turbo": "openai", "claude-3": "claude"}
            mock_cm_class.return_value = mock_client_manager
            
            client = HarborAI(
                api_key="test-key",
                organization="test-org",
                project="test-project",
                base_url="https://api.test.com",
                timeout=30.0,
                max_retries=5
            )
            
            assert isinstance(client.chat, Chat)
            assert client.chat.completions.client_manager == mock_client_manager
    
    def test_åˆå§‹åŒ–é»˜è®¤å‚æ•°(self):
        """æµ‹è¯•é»˜è®¤å‚æ•°åˆå§‹åŒ–ã€‚"""
        with patch('harborai.api.client.ClientManager') as mock_cm_class:
            mock_client_manager = Mock()
            # è®¾ç½®å¯è¿­ä»£çš„å±æ€§
            mock_client_manager.plugins = {"openai": Mock(), "claude": Mock()}
            mock_client_manager.model_to_plugin = {"gpt-3.5-turbo": "openai", "claude-3": "claude"}
            mock_cm_class.return_value = mock_client_manager
            
            client = HarborAI()
            
            assert isinstance(client.chat, Chat)
    
    def test_get_available_models(self):
        """æµ‹è¯•è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨ã€‚"""
        expected_models = ["gpt-3.5-turbo", "claude-3"]
        
        # Mock get_available_models æ–¹æ³•è¿”å›å­—ç¬¦ä¸²åˆ—è¡¨
        self.mock_client_manager.get_available_models.return_value = expected_models
        
        models = self.client.get_available_models()
        
        assert models == expected_models
    
    def test_get_plugin_info(self):
        """æµ‹è¯•è·å–æ’ä»¶ä¿¡æ¯ã€‚"""
        expected_info = {"openai": {"version": "1.0"}, "claude": {"version": "2.0"}}
        self.mock_client_manager.get_plugin_info.return_value = expected_info
        
        info = self.client.get_plugin_info()
        
        assert info == expected_info
        self.mock_client_manager.get_plugin_info.assert_called_once()
    
    def test_register_plugin(self):
        """æµ‹è¯•æ³¨å†Œæ’ä»¶ã€‚"""
        mock_plugin = Mock()
        
        self.client.register_plugin(mock_plugin)
        
        self.mock_client_manager.register_plugin.assert_called_once_with(mock_plugin)
    
    def test_unregister_plugin(self):
        """æµ‹è¯•æ³¨é”€æ’ä»¶ã€‚"""
        plugin_name = "test_plugin"
        
        self.client.unregister_plugin(plugin_name)
        
        self.mock_client_manager.unregister_plugin.assert_called_once_with(plugin_name)
    
    def test_get_total_cost(self):
        """æµ‹è¯•è·å–æ€»æˆæœ¬ã€‚"""
        # å½“å‰å®ç°è¿”å›0.0ä½œä¸ºå ä½ç¬¦
        cost = self.client.get_total_cost()
        
        assert cost == 0.0
    
    def test_reset_cost(self):
        """æµ‹è¯•é‡ç½®æˆæœ¬ã€‚"""
        # å½“å‰å®ç°æ˜¯ç©ºçš„passï¼Œåªæµ‹è¯•ä¸æŠ›å¼‚å¸¸
        self.client.reset_cost()
        
        # å¦‚æœæ²¡æœ‰å¼‚å¸¸ï¼Œæµ‹è¯•é€šè¿‡
    
    @pytest.mark.asyncio
    async def test_aclose(self):
        """æµ‹è¯•å¼‚æ­¥å…³é—­ã€‚"""
        # è®¾ç½®æ’ä»¶mock
        mock_plugin = Mock()
        mock_plugin.aclose = AsyncMock()
        self.mock_client_manager.plugins = {"test": mock_plugin}
        
        # æ¨¡æ‹Ÿæ€§èƒ½ç®¡ç†å™¨å·²åˆå§‹åŒ–
        mock_perf_manager = Mock()
        mock_perf_manager.is_initialized.return_value = True
        self.client._performance_manager = mock_perf_manager
        
        with patch('harborai.api.client.cleanup_performance_manager') as mock_cleanup:
            await self.client.aclose()
            
            mock_plugin.aclose.assert_called_once()
            mock_cleanup.assert_called_once()
    
    def test_close(self):
        """æµ‹è¯•åŒæ­¥å…³é—­ã€‚"""
        # è®¾ç½®æ’ä»¶mock
        mock_plugin = Mock()
        mock_plugin.close = Mock()
        self.mock_client_manager.plugins = {"test": mock_plugin}
        
        with patch('harborai.api.client.cleanup_performance_manager') as mock_cleanup:
            self.client.close()
            
            mock_plugin.close.assert_called_once()
    
    def test_context_manager_sync(self):
        """æµ‹è¯•åŒæ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨ã€‚"""
        with patch.object(self.client, 'close') as mock_close:
            with self.client as client:
                assert client == self.client
            
            mock_close.assert_called_once()
    
    @pytest.mark.asyncio
    async def test_context_manager_async(self):
        """æµ‹è¯•å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨ã€‚"""
        with patch.object(self.client, 'aclose') as mock_aclose:
            async with self.client as client:
                assert client == self.client
            
            mock_aclose.assert_called_once()


class TestIntegrationScenarios:
    """é›†æˆåœºæ™¯æµ‹è¯•ã€‚"""
    
    def setup_method(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒã€‚"""
        with patch('harborai.api.client.ClientManager') as mock_cm_class:
            self.mock_client_manager = Mock()
            # è®¾ç½®å¯è¿­ä»£çš„å±æ€§
            self.mock_client_manager.plugins = {"openai": Mock(), "claude": Mock()}
            self.mock_client_manager.model_to_plugin = {"gpt-3.5-turbo": "openai", "claude-3": "claude"}
            mock_cm_class.return_value = self.mock_client_manager
            
            self.client = HarborAI(api_key="test-key")
    
    @patch('harborai.api.client.get_performance_config')
    def test_å®Œæ•´èŠå¤©æµç¨‹(self, mock_get_perf_config):
        """æµ‹è¯•å®Œæ•´çš„èŠå¤©æµç¨‹ã€‚"""
        mock_get_perf_config.return_value = Mock(
            enable_fast_path=False,
            enable_structured_output_optimization=False
        )
        
        # æ¨¡æ‹Ÿå“åº”
        mock_response = Mock(spec=ChatCompletion)
        mock_response.choices = [Mock()]
        mock_response.choices[0].message.content = "Hello! How can I help you?"
        
        with patch.object(self.client.chat.completions, '_create_core') as mock_create_core:
            mock_create_core.return_value = mock_response
            
            messages = [{"role": "user", "content": "Hello"}]
            response = self.client.chat.completions.create(
                messages=messages,
                model="gpt-3.5-turbo"
            )
            
            assert response == mock_response
            mock_create_core.assert_called_once()
    
    @pytest.mark.asyncio
    @patch('harborai.api.client.get_performance_config')
    async def test_å¼‚æ­¥èŠå¤©æµç¨‹(self, mock_get_perf_config):
        """æµ‹è¯•å¼‚æ­¥èŠå¤©æµç¨‹ã€‚"""
        mock_get_perf_config.return_value = Mock(
            enable_fast_path=False,
            enable_structured_output_optimization=False
        )
        
        # æ¨¡æ‹Ÿå¼‚æ­¥å“åº”
        mock_response = Mock(spec=ChatCompletion)
        mock_response.choices = [Mock()]
        mock_response.choices[0].message.content = "Hello! How can I help you?"
        
        with patch.object(self.client.chat.completions, '_acreate_core') as mock_acreate_core:
            mock_acreate_core.return_value = mock_response
            
            messages = [{"role": "user", "content": "Hello"}]
            response = await self.client.chat.completions.acreate(
                messages=messages,
                model="gpt-3.5-turbo"
            )
            
            assert response == mock_response
            mock_acreate_core.assert_called_once()


class TestErrorHandling:
    """é”™è¯¯å¤„ç†æµ‹è¯•ã€‚"""
    
    def setup_method(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒã€‚"""
        self.mock_client_manager = Mock()
        self.chat_completions = ChatCompletions(self.mock_client_manager)
    
    def test_å¤„ç†å®¢æˆ·ç«¯ç®¡ç†å™¨é”™è¯¯(self):
        """æµ‹è¯•å¤„ç†å®¢æˆ·ç«¯ç®¡ç†å™¨é”™è¯¯ã€‚"""
        with patch.object(self.chat_completions, '_create_core') as mock_create_core:
            mock_create_core.side_effect = HarborAIError("Client manager error")
            
            with pytest.raises(HarborAIError, match="Client manager error"):
                self.chat_completions.create(
                    messages=[{"role": "user", "content": "Hello"}],
                    model="gpt-3.5-turbo"
                )
    
    @pytest.mark.asyncio
    async def test_å¤„ç†å¼‚æ­¥é”™è¯¯(self):
        """æµ‹è¯•å¤„ç†å¼‚æ­¥é”™è¯¯ã€‚"""
        with patch.object(self.chat_completions, '_acreate_core') as mock_acreate_core:
            mock_acreate_core.side_effect = HarborAIError("Async error")
            
            with pytest.raises(HarborAIError, match="Async error"):
                await self.chat_completions.acreate(
                    messages=[{"role": "user", "content": "Hello"}],
                    model="gpt-3.5-turbo"
                )


class TestEdgeCases:
    """è¾¹ç•Œæƒ…å†µæµ‹è¯•ã€‚"""
    
    def setup_method(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒã€‚"""
        self.mock_client_manager = Mock()
        self.chat_completions = ChatCompletions(self.mock_client_manager)
    
    def test_ç©ºå­—ç¬¦ä¸²å†…å®¹(self):
        """æµ‹è¯•ç©ºå­—ç¬¦ä¸²å†…å®¹ã€‚"""
        messages = [{"role": "user", "content": ""}]
        
        # å½“å‰å®ç°å…è®¸ç©ºå­—ç¬¦ä¸²å†…å®¹ï¼Œåªè¦æœ‰contentå­—æ®µ
        # è¿™ä¸ªæµ‹è¯•åº”è¯¥é€šè¿‡è€Œä¸æŠ›å‡ºå¼‚å¸¸
        try:
            self.chat_completions._validate_messages(messages)
        except ValidationError:
            pytest.fail("ç©ºå­—ç¬¦ä¸²å†…å®¹ä¸åº”è¯¥æŠ›å‡ºValidationError")
    
    def test_Noneå†…å®¹(self):
        """æµ‹è¯•Noneå†…å®¹ã€‚"""
        messages = [{"role": "user", "content": None}]
        
        # å½“å‰å®ç°å…è®¸Noneå†…å®¹ï¼Œåªè¦æœ‰contentå­—æ®µ
        # è¿™ä¸ªæµ‹è¯•åº”è¯¥é€šè¿‡è€Œä¸æŠ›å‡ºå¼‚å¸¸
        try:
            self.chat_completions._validate_messages(messages)
        except ValidationError:
            pytest.fail("Noneå†…å®¹ä¸åº”è¯¥æŠ›å‡ºValidationError")
    
    def test_å¤§é‡æ¶ˆæ¯(self):
        """æµ‹è¯•å¤§é‡æ¶ˆæ¯å¤„ç†ã€‚"""
        messages = [{"role": "user", "content": f"Message {i}"} for i in range(1000)]
        
        # ä¸åº”è¯¥æŠ›å‡ºå¼‚å¸¸
        self.chat_completions._validate_messages(messages)
    
    def test_ç‰¹æ®Šå­—ç¬¦æ¶ˆæ¯(self):
        """æµ‹è¯•åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„æ¶ˆæ¯ã€‚"""
        messages = [
            {"role": "user", "content": "Hello ğŸŒŸ World! ä¸­æ–‡æµ‹è¯• @#$%^&*()"}
        ]
        
        # ä¸åº”è¯¥æŠ›å‡ºå¼‚å¸¸
        self.chat_completions._validate_messages(messages)
    
    def test_æ¨ç†å†…å®¹å¤„ç†(self):
        """æµ‹è¯•æ¨ç†å†…å®¹å¤„ç†ã€‚"""
        messages = [
            {
                "role": "user", 
                "content": "Solve this problem",
                "reasoning_content": "Let me think about this step by step..."
            }
        ]
        
        processed = self.chat_completions._process_messages_for_reasoning_model(messages)
        
        assert len(processed) == 1
        assert "reasoning_content" in processed[0]
        assert processed[0]["reasoning_content"] == "Let me think about this step by step..."


class TestChatCompletionsAdvanced:
    """ChatCompletionsé«˜çº§åŠŸèƒ½æµ‹è¯•ã€‚"""
    
    def setup_method(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒã€‚"""
        self.mock_client_manager = Mock()
        self.chat_completions = ChatCompletions(self.mock_client_manager)
    
    def test_create_core_åŸºæœ¬åŠŸèƒ½(self):
        """æµ‹è¯•_create_coreçš„åŸºæœ¬åŠŸèƒ½ã€‚"""
        # æ¨¡æ‹Ÿä¾èµ–
        mock_response = Mock()
        mock_response.choices = [Mock()]
        mock_response.choices[0].message = Mock()
        mock_response.choices[0].message.content = "æµ‹è¯•å“åº”"
        
        # æ¨¡æ‹Ÿæ‰€æœ‰å¿…è¦çš„ä¾èµ–
        with patch('harborai.api.client.get_or_create_trace_id', return_value='test-trace-id'), \
             patch('harborai.api.client.TraceContext'), \
             patch('harborai.utils.logger.LogContext'), \
             patch('harborai.api.client.retry_with_backoff') as mock_retry, \
             patch.object(self.chat_completions.client_manager, 'chat_completion_sync_with_fallback', return_value=mock_response):
            
            # é…ç½®retryè£…é¥°å™¨è¿”å›åŸå‡½æ•°
            mock_retry.side_effect = lambda config=None: lambda func: func
            
            result = self.chat_completions._create_core(
                messages=[{"role": "user", "content": "æµ‹è¯•"}],
                model="gpt-3.5-turbo"
            )
            
            assert result == mock_response
    
    def test_create_core_å¸¦æ‰€æœ‰å‚æ•°(self):
        """æµ‹è¯•_create_coreå¸¦æ‰€æœ‰å‚æ•°ã€‚"""
        # æ¨¡æ‹Ÿæ‰€æœ‰å¿…è¦çš„ä¾èµ–
        with patch('harborai.api.client.get_or_create_trace_id', return_value='test-trace-id'), \
             patch('harborai.api.client.TraceContext'), \
             patch('harborai.utils.logger.LogContext'), \
             patch('harborai.api.client.retry_with_backoff') as mock_retry, \
             patch.object(self.chat_completions.client_manager, 'chat_completion_sync_with_fallback') as mock_create:
            
            # é…ç½®retryè£…é¥°å™¨è¿”å›åŸå‡½æ•°
            mock_retry.side_effect = lambda config=None: lambda func: func
            
            mock_response = Mock(spec=ChatCompletion)
            mock_create.return_value = mock_response
            
            messages = [{"role": "user", "content": "Hello"}]
            result = self.chat_completions._create_core(
                messages=messages,
                model="gpt-3.5-turbo",
                temperature=0.7,
                max_tokens=100,
                top_p=0.9,
                frequency_penalty=0.1,
                presence_penalty=0.2,
                stop=["END"],
                stream=False,
                response_format={"type": "json_object"},
                tools=[{"type": "function", "function": {"name": "test"}}],
                tool_choice="auto",
                user="test_user",
                seed=42,
                logprobs=True,
                top_logprobs=5,
                n=1,
                timeout=30.0,
                extra_body={"custom": "value"}
            )
            
            assert result == mock_response
            mock_create.assert_called_once()
            
            # éªŒè¯å‚æ•°ä¼ é€’
            call_args = mock_create.call_args[1]
            assert call_args["temperature"] == 0.7
            assert call_args["max_tokens"] == 100
            assert call_args["top_p"] == 0.9
    
    @pytest.mark.asyncio
    async def test_acreate_core_åŸºæœ¬åŠŸèƒ½(self):
        """æµ‹è¯•å¼‚æ­¥_acreate_coreçš„åŸºæœ¬åŠŸèƒ½ã€‚"""
        mock_response = Mock()
        
        # æ¨¡æ‹Ÿæ‰€æœ‰å¿…è¦çš„ä¾èµ–
        with patch('harborai.api.client.get_or_create_trace_id', return_value='test-trace-id'), \
             patch('harborai.api.client.TraceContext'), \
             patch('harborai.utils.logger.LogContext'), \
             patch('harborai.api.client.async_retry_with_backoff') as mock_retry:
            
            # é…ç½®retryè£…é¥°å™¨è¿”å›åŸå‡½æ•°
            mock_retry.side_effect = lambda config=None: lambda func: func
            
            # æ¨¡æ‹Ÿå¼‚æ­¥æ–¹æ³•
            async_mock = AsyncMock(return_value=mock_response)
            with patch.object(self.chat_completions.client_manager, 'chat_completion_with_fallback', async_mock):
                result = await self.chat_completions._acreate_core(
                    messages=[{"role": "user", "content": "æµ‹è¯•"}],
                    model="gpt-3.5-turbo"
                )
                
                assert result == mock_response
                async_mock.assert_called_once()
    
    @patch('harborai.api.client.get_performance_config')
    def test_create_å¿«é€Ÿç»“æ„åŒ–è·¯å¾„(self, mock_get_perf_config):
        """æµ‹è¯•å¿«é€Ÿç»“æ„åŒ–è¾“å‡ºè·¯å¾„ã€‚"""
        mock_perf_config = Mock()
        mock_perf_config.mode.value = "fast"  # å°å†™
        mock_get_perf_config.return_value = mock_perf_config
        
        with patch.object(self.chat_completions, '_create_fast_structured_path') as mock_fast_structured:
            mock_response = Mock(spec=ChatCompletion)
            mock_fast_structured.return_value = mock_response
            
            messages = [{"role": "user", "content": "Hello"}]
            response_format = {"type": "json_schema"}  # éœ€è¦æ˜¯json_schemaæ‰èƒ½è§¦å‘å¿«é€Ÿç»“æ„åŒ–è·¯å¾„
            result = self.chat_completions.create(
                messages=messages,
                model="gpt-3.5-turbo",
                response_format=response_format,
                structured_provider="agently",  # éœ€è¦æ˜¯agentlyæ‰èƒ½è§¦å‘å¿«é€Ÿç»“æ„åŒ–è·¯å¾„
                stream=False
            )
            
            assert result == mock_response
            mock_fast_structured.assert_called_once()
    
    @patch('harborai.api.client.get_performance_config')
    def test_create_å¿«é€Ÿè·¯å¾„_å¯ç”¨(self, mock_get_perf_config):
        """æµ‹è¯•å¯ç”¨å¿«é€Ÿè·¯å¾„ã€‚"""
        mock_perf_config = Mock()
        mock_perf_config.mode.value = "fast"
        mock_perf_config.should_use_fast_path.return_value = True  # æ¨¡æ‹Ÿåº”è¯¥ä½¿ç”¨å¿«é€Ÿè·¯å¾„
        mock_get_perf_config.return_value = mock_perf_config
        
        with patch.object(self.chat_completions, '_create_fast_path') as mock_fast_path:
            mock_response = Mock(spec=ChatCompletion)
            mock_fast_path.return_value = mock_response
            
            messages = [{"role": "user", "content": "Hello"}]
            result = self.chat_completions.create(
                messages=messages,
                model="gpt-3.5-turbo"
            )
            
            assert result == mock_response
            mock_fast_path.assert_called_once()
    
    @patch('harborai.api.client.get_performance_config')
    def test_create_å®Œæ•´è·¯å¾„(self, mock_get_perf_config):
        """æµ‹è¯•å®Œæ•´è·¯å¾„ã€‚"""
        mock_perf_config = Mock()
        mock_perf_config.mode.value = "full"
        mock_perf_config.should_use_fast_path.return_value = False  # æ¨¡æ‹Ÿä¸åº”è¯¥ä½¿ç”¨å¿«é€Ÿè·¯å¾„
        mock_get_perf_config.return_value = mock_perf_config
        
        with patch.object(self.chat_completions, '_create_full_path') as mock_full_path:
            mock_response = Mock(spec=ChatCompletion)
            mock_full_path.return_value = mock_response
            
            messages = [{"role": "user", "content": "Hello"}]
            result = self.chat_completions.create(
                messages=messages,
                model="gpt-3.5-turbo"
            )
            
            assert result == mock_response
            mock_full_path.assert_called_once()
    
    @pytest.mark.asyncio
    @patch('harborai.api.client.get_performance_config')
    async def test_acreate_å¿«é€Ÿç»“æ„åŒ–è·¯å¾„(self, mock_get_perf_config):
        """æµ‹è¯•å¼‚æ­¥å¿«é€Ÿç»“æ„åŒ–è·¯å¾„ã€‚"""
        mock_perf_config = Mock()
        mock_perf_config.mode.value = "fast"
        mock_get_perf_config.return_value = mock_perf_config
        
        with patch.object(self.chat_completions, '_acreate_fast_structured_path') as mock_fast_structured:
            mock_response = Mock(spec=ChatCompletion)
            mock_fast_structured.return_value = mock_response
            
            messages = [{"role": "user", "content": "Hello"}]
            response_format = {"type": "json_schema"}
            result = await self.chat_completions.acreate(
                messages=messages,
                model="gpt-3.5-turbo",
                response_format=response_format,
                structured_provider="agently",
                stream=False
            )
            
            assert result == mock_response
            mock_fast_structured.assert_called_once()
    
    @pytest.mark.asyncio
    @patch('harborai.api.client.get_performance_config')
    async def test_acreate_å¿«é€Ÿè·¯å¾„(self, mock_get_perf_config):
        """æµ‹è¯•å¼‚æ­¥å¿«é€Ÿè·¯å¾„ã€‚"""
        mock_perf_config = Mock()
        mock_perf_config.mode.value = "fast"
        mock_perf_config.should_use_fast_path.return_value = True
        mock_get_perf_config.return_value = mock_perf_config
        
        with patch.object(self.chat_completions, '_acreate_fast_path') as mock_fast_path:
            mock_response = Mock(spec=ChatCompletion)
            mock_fast_path.return_value = mock_response
            
            messages = [{"role": "user", "content": "Hello"}]
            result = await self.chat_completions.acreate(
                messages=messages,
                model="gpt-3.5-turbo"
            )
            
            assert result == mock_response
            mock_fast_path.assert_called_once()
    
    @pytest.mark.asyncio
    @patch('harborai.api.client.get_performance_config')
    async def test_acreate_å®Œæ•´è·¯å¾„(self, mock_get_perf_config):
        """æµ‹è¯•å¼‚æ­¥å®Œæ•´è·¯å¾„ã€‚"""
        mock_perf_config = Mock()
        mock_perf_config.mode.value = "full"
        mock_perf_config.should_use_fast_path.return_value = False
        mock_get_perf_config.return_value = mock_perf_config
        
        with patch.object(self.chat_completions, '_acreate_full_path') as mock_full_path:
            mock_response = Mock(spec=ChatCompletion)
            mock_full_path.return_value = mock_response
            
            messages = [{"role": "user", "content": "Hello"}]
            result = await self.chat_completions.acreate(
                messages=messages,
                model="gpt-3.5-turbo"
            )
            
            assert result == mock_response
            mock_full_path.assert_called_once()
    
    @patch.object(ChatCompletions, '_create_core')
    def test_create_fast_structured_path_åŸºæœ¬åŠŸèƒ½(self, mock_create_core):
        """æµ‹è¯•å¿«é€Ÿç»“æ„åŒ–è¾“å‡ºè·¯å¾„çš„åŸºæœ¬åŠŸèƒ½ - æµ‹è¯•å›é€€åˆ°å¸¸è§„è·¯å¾„"""
        # è®¾ç½®mockè¿”å›å€¼
        mock_response = Mock(spec=ChatCompletion)
        mock_create_core.return_value = mock_response
        
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        messages = [{"role": "user", "content": "æµ‹è¯•æ¶ˆæ¯"}]
        response_format = {"type": "json_schema", "json_schema": {"schema": {"type": "object"}}}
        
        # è°ƒç”¨æ–¹æ³•
        result = self.chat_completions._create_fast_structured_path(
            messages=messages,
            model="gpt-3.5-turbo",
            response_format=response_format,
            structured_provider="agently"
        )
        
        # éªŒè¯ç»“æœ - åº”è¯¥å›é€€åˆ°å¸¸è§„è·¯å¾„
        assert result is not None
        mock_create_core.assert_called_once()
    
    @pytest.mark.asyncio
    @patch.object(ChatCompletions, '_acreate_core')
    async def test_acreate_fast_structured_path_åŸºæœ¬åŠŸèƒ½(self, mock_acreate_core):
        """æµ‹è¯•å¼‚æ­¥å¿«é€Ÿç»“æ„åŒ–è¾“å‡ºè·¯å¾„çš„åŸºæœ¬åŠŸèƒ½ - æµ‹è¯•å›é€€åˆ°å¸¸è§„è·¯å¾„"""
        # è®¾ç½®mockè¿”å›å€¼
        mock_response = Mock(spec=ChatCompletion)
        mock_acreate_core.return_value = mock_response
        
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        messages = [{"role": "user", "content": "æµ‹è¯•æ¶ˆæ¯"}]
        response_format = {"type": "json_schema", "json_schema": {"schema": {"type": "object"}}}
        
        # è°ƒç”¨æ–¹æ³•
        result = await self.chat_completions._acreate_fast_structured_path(
            messages=messages,
            model="gpt-3.5-turbo",
            response_format=response_format,
            structured_provider="agently"
        )
        
        # éªŒè¯ç»“æœ - åº”è¯¥å›é€€åˆ°å¸¸è§„è·¯å¾„
        assert result is not None
        mock_acreate_core.assert_called_once()
    
    def test_validate_messages_å·¥å…·è°ƒç”¨æ¶ˆæ¯(self):
        """æµ‹è¯•å·¥å…·è°ƒç”¨æ¶ˆæ¯éªŒè¯ã€‚"""
        messages = [
            {"role": "assistant", "tool_calls": [{"id": "call_123", "type": "function"}]},
            {"role": "tool", "content": "result", "tool_call_id": "call_123"}
        ]
        # ä¸åº”è¯¥æŠ›å‡ºå¼‚å¸¸
        self.chat_completions._validate_messages(messages)
    
    def test_validate_messages_ç©ºå†…å®¹(self):
        """æµ‹è¯•ç©ºå†…å®¹éªŒè¯ã€‚"""
        messages = [
            {"role": "user", "content": ""}
        ]
        # å½“å‰å®ç°å…è®¸ç©ºå†…å®¹
        self.chat_completions._validate_messages(messages)
    
    def test_process_messages_æ— æ¨ç†å†…å®¹(self):
        """æµ‹è¯•æ— æ¨ç†å†…å®¹çš„æ¶ˆæ¯å¤„ç†ã€‚"""
        messages = [
            {"role": "user", "content": "Hello"}
        ]
        
        processed = self.chat_completions._process_messages_for_reasoning_model(messages)
        
        assert processed == messages  # åº”è¯¥è¿”å›åŸå§‹æ¶ˆæ¯


class TestHarborAIAdvanced:
    """HarborAIé«˜çº§åŠŸèƒ½æµ‹è¯•ã€‚"""
    
    def setup_method(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒã€‚"""
        # Mockæ‰€æœ‰ä¾èµ–
        self.mock_client_manager = Mock()
        self.mock_client_manager.plugins = {}  # ä¿®å¤è¿­ä»£é—®é¢˜
        self.mock_client_manager.model_to_plugin = {}  # ä¿®å¤len()é—®é¢˜
        self.mock_chat = Mock()
        self.mock_completions = Mock()
        
        # è®¾ç½®mocké“¾
        self.mock_chat.completions = self.mock_completions
        
        # åˆ›å»ºpatches
        self.client_manager_patch = patch('harborai.api.client.ClientManager', return_value=self.mock_client_manager)
        self.chat_patch = patch('harborai.api.client.Chat', return_value=self.mock_chat)
        self.auto_init_patch = patch('harborai.api.client.auto_initialize')
        self.perf_manager_patch = patch('harborai.api.client.initialize_performance_manager')
    
    def test_åˆå§‹åŒ–è‡ªå®šä¹‰å‚æ•°(self):
        """æµ‹è¯•è‡ªå®šä¹‰å‚æ•°åˆå§‹åŒ–ã€‚"""
        with self.client_manager_patch, self.chat_patch, self.auto_init_patch, self.perf_manager_patch:
            custom_headers = {"Custom-Header": "value"}
            custom_query = {"param": "value"}
            
            client = HarborAI(
                default_headers=custom_headers,
                default_query=custom_query,
                custom_param="custom_value"
            )
            
            assert client.chat == self.mock_chat
            assert client.chat.completions == self.mock_completions
    
    def test_get_total_cost_with_tracker(self):
        """æµ‹è¯•è·å–æ€»æˆæœ¬ï¼ˆå¸¦è¿½è¸ªå™¨ï¼‰ã€‚"""
        with self.client_manager_patch, self.chat_patch, self.auto_init_patch, self.perf_manager_patch:
            client = HarborAI()
            cost = client.get_total_cost()
            
            # å½“å‰å®ç°è¿”å›0.0
            assert cost == 0.0
    
    def test_reset_cost_with_tracker(self):
        """æµ‹è¯•é‡ç½®æˆæœ¬ï¼ˆå¸¦è¿½è¸ªå™¨ï¼‰ã€‚"""
        with self.client_manager_patch, self.chat_patch, self.auto_init_patch, self.perf_manager_patch:
            client = HarborAI()
            client.reset_cost()
            
            # å½“å‰å®ç°æ˜¯passï¼Œä¸ä¼šè°ƒç”¨è¿½è¸ªå™¨ï¼Œæµ‹è¯•ä¸æŠ›å¼‚å¸¸å³å¯
            assert True
    
    @pytest.mark.asyncio
    async def test_aclose_å¼‚å¸¸å¤„ç†(self):
        """æµ‹è¯•å¼‚æ­¥å…³é—­çš„å¼‚å¸¸å¤„ç†ã€‚"""
        with self.client_manager_patch, self.chat_patch, self.auto_init_patch, self.perf_manager_patch:
            with patch('harborai.api.client.cleanup_performance_manager') as mock_cleanup:
                # ç¡®ä¿mock_client_manageræœ‰pluginså±æ€§
                mock_plugin = Mock()
                mock_plugin.aclose = AsyncMock(side_effect=Exception("å…³é—­å¤±è´¥"))
                mock_plugin.name = "test_plugin"
                self.mock_client_manager.plugins = {"test": mock_plugin}
                
                client = HarborAI()
                
                # è®¾ç½®æ€§èƒ½ç®¡ç†å™¨ä»¥ç¡®ä¿æ¸…ç†å‡½æ•°è¢«è°ƒç”¨
                mock_perf_manager = Mock()
                mock_perf_manager.is_initialized.return_value = True
                client._performance_manager = mock_perf_manager
                
                # å¼‚å¸¸åº”è¯¥è¢«æ•è·ï¼Œä¸ä¼šæŠ›å‡º
                await client.aclose()
                
                # éªŒè¯æ’ä»¶çš„acloseè¢«è°ƒç”¨
                mock_plugin.aclose.assert_called_once()
                mock_cleanup.assert_called_once()
    
    def test_close_å¼‚å¸¸å¤„ç†(self):
        """æµ‹è¯•åŒæ­¥å…³é—­çš„å¼‚å¸¸å¤„ç†ã€‚"""
        with self.client_manager_patch, self.chat_patch, self.auto_init_patch, self.perf_manager_patch:
            with patch('harborai.api.client.cleanup_performance_manager') as mock_cleanup:
                # ç¡®ä¿mock_client_manageræœ‰pluginså±æ€§
                mock_plugin = Mock()
                mock_plugin.close = Mock(side_effect=Exception("å…³é—­å¤±è´¥"))
                mock_plugin.name = "test_plugin"
                self.mock_client_manager.plugins = {"test": mock_plugin}
                
                client = HarborAI()
                
                # è®¾ç½®æ€§èƒ½ç®¡ç†å™¨ä»¥ç¡®ä¿æ¸…ç†å‡½æ•°è¢«è°ƒç”¨
                mock_perf_manager = Mock()
                mock_perf_manager.is_initialized.return_value = True
                client._performance_manager = mock_perf_manager
                
                # å¼‚å¸¸åº”è¯¥è¢«æ•è·ï¼Œä¸ä¼šæŠ›å‡º
                client.close()
                
                # éªŒè¯æ’ä»¶çš„closeè¢«è°ƒç”¨
                mock_plugin.close.assert_called_once()
                mock_cleanup.assert_called_once()
    
    def test_client_åˆ«å(self):
        """æµ‹è¯•Clientåˆ«åã€‚"""
        from harborai.api.client import Client
        assert Client == HarborAI


class TestPerformanceOptimizations:
    """æ€§èƒ½ä¼˜åŒ–æµ‹è¯•ã€‚"""
    
    def setup_method(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒã€‚"""
        self.mock_client_manager = Mock()
        self.chat_completions = ChatCompletions(self.mock_client_manager)
    
    def test_å¿«é€Ÿå¤„ç†å™¨ç¼“å­˜(self):
        """æµ‹è¯•å¿«é€Ÿå¤„ç†å™¨ç¼“å­˜æœºåˆ¶ã€‚"""
        with patch('harborai.core.fast_structured_output.create_fast_structured_output_processor') as mock_create:
            mock_processor = Mock()
            mock_create.return_value = mock_processor
            
            # ç¬¬ä¸€æ¬¡è°ƒç”¨
            processor1 = self.chat_completions._get_fast_processor()
            # ç¬¬äºŒæ¬¡è°ƒç”¨
            processor2 = self.chat_completions._get_fast_processor()
            
            # åº”è¯¥è¿”å›åŒä¸€ä¸ªå®ä¾‹
            assert processor1 == processor2
            # åˆ›å»ºå‡½æ•°åªåº”è¯¥è¢«è°ƒç”¨ä¸€æ¬¡
            assert mock_create.call_count == 1
    
    @patch('harborai.api.client.get_performance_config')
    def test_æ€§èƒ½é…ç½®è·¯ç”±(self, mock_get_perf_config):
        """æµ‹è¯•æ€§èƒ½é…ç½®å¯¹è·¯ç”±çš„å½±å“ã€‚"""
        mock_perf_config = Mock()
        mock_get_perf_config.return_value = mock_perf_config
        
        # æµ‹è¯•å¿«é€Ÿè·¯å¾„
        mock_perf_config.should_use_fast_path.return_value = True
        
        with patch.object(self.chat_completions, '_create_fast_path') as mock_fast:
            mock_fast.return_value = Mock(spec=ChatCompletion)
            
            messages = [{"role": "user", "content": "Hello"}]
            self.chat_completions.create(messages=messages, model="gpt-3.5-turbo")
            
            mock_fast.assert_called_once()
        
        # æµ‹è¯•å®Œæ•´è·¯å¾„
        mock_perf_config.should_use_fast_path.return_value = False
        
        with patch.object(self.chat_completions, '_create_full_path') as mock_full:
            mock_full.return_value = Mock(spec=ChatCompletion)
            
            messages = [{"role": "user", "content": "Hello"}]
            self.chat_completions.create(messages=messages, model="gpt-3.5-turbo")
            
            mock_full.assert_called_once()
    
    def test_æ¶ˆæ¯é¢„å¤„ç†ç¼“å­˜(self):
        """æµ‹è¯•æ¶ˆæ¯é¢„å¤„ç†çš„ç¼“å­˜æ•ˆæœã€‚"""
        messages = [{"role": "user", "content": "Hello"}]
        
        # å¤šæ¬¡è°ƒç”¨ç›¸åŒçš„æ¶ˆæ¯å¤„ç†
        for _ in range(5):
            processed = self.chat_completions._process_messages_for_reasoning_model(messages)
            assert processed == messages
    
    def test_å‚æ•°éªŒè¯ä¼˜åŒ–(self):
        """æµ‹è¯•å‚æ•°éªŒè¯çš„æ€§èƒ½ä¼˜åŒ–ã€‚"""
        import time
        
        messages = [{"role": "user", "content": "Hello"}]
        
        # æµ‹è¯•éªŒè¯æ€§èƒ½
        start_time = time.time()
        for _ in range(100):
            self.chat_completions._validate_messages(messages)
        validation_time = time.time() - start_time
        
        # éªŒè¯åº”è¯¥å¾ˆå¿«å®Œæˆ
        assert validation_time < 1.0  # 100æ¬¡éªŒè¯åº”è¯¥åœ¨1ç§’å†…å®Œæˆ


class TestStreamingAndTools:
    """æµå¼å“åº”å’Œå·¥å…·è°ƒç”¨æµ‹è¯•ã€‚"""
    
    def setup_method(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒã€‚"""
        self.mock_client_manager = Mock()
        self.chat_completions = ChatCompletions(self.mock_client_manager)
    
    def test_æµå¼å“åº”å¤„ç†(self):
        """æµ‹è¯•æµå¼å“åº”å¤„ç†ã€‚"""
        # æ¨¡æ‹Ÿæµå¼å“åº”
        def mock_stream():
            yield Mock(spec=ChatCompletionChunk, choices=[Mock(delta=Mock(content="Hello"))])
            yield Mock(spec=ChatCompletionChunk, choices=[Mock(delta=Mock(content=" world"))])
            yield Mock(spec=ChatCompletionChunk, choices=[Mock(delta=Mock(content="!"))])
        
        with patch('harborai.api.client.get_or_create_trace_id', return_value='test-trace-id'), \
             patch('harborai.api.client.TraceContext'), \
             patch('harborai.utils.logger.LogContext'), \
             patch('harborai.api.client.retry_with_backoff') as mock_retry, \
             patch.object(self.chat_completions.client_manager, 'chat_completion_sync_with_fallback', return_value=mock_stream()):
            
            # é…ç½®retryè£…é¥°å™¨è¿”å›åŸå‡½æ•°
            mock_retry.side_effect = lambda config=None: lambda func: func
            
            messages = [{"role": "user", "content": "Hello"}]
            result = self.chat_completions._create_core(
                messages=messages,
                model="gpt-3.5-turbo",
                stream=True
            )
            
            # éªŒè¯è¿”å›çš„æ˜¯ç”Ÿæˆå™¨
            chunks = list(result)
            assert len(chunks) == 3
            assert all(isinstance(chunk, Mock) for chunk in chunks)
    
    def test_å·¥å…·è°ƒç”¨æµç¨‹(self):
        """æµ‹è¯•å·¥å…·è°ƒç”¨æµç¨‹ã€‚"""
        tools = [
            {
                "type": "function",
                "function": {
                    "name": "get_weather",
                    "description": "Get weather information",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "location": {"type": "string"}
                        }
                    }
                }
            }
        ]
        
        mock_response = Mock(spec=ChatCompletion)
        mock_function = Mock()
        mock_function.name = "get_weather"
        mock_function.arguments = '{"location": "Beijing"}'
        
        mock_response.choices = [
            Mock(message=Mock(
                tool_calls=[
                    Mock(
                        id="call_123",
                        type="function",
                        function=mock_function
                    )
                ]
            ))
        ]
        
        with patch('harborai.api.client.get_or_create_trace_id', return_value='test-trace-id'), \
             patch('harborai.api.client.TraceContext'), \
             patch('harborai.utils.logger.LogContext'), \
             patch('harborai.api.client.retry_with_backoff') as mock_retry, \
             patch.object(self.chat_completions.client_manager, 'chat_completion_sync_with_fallback', return_value=mock_response):
            
            # é…ç½®retryè£…é¥°å™¨è¿”å›åŸå‡½æ•°
            mock_retry.side_effect = lambda config=None: lambda func: func
            
            messages = [{"role": "user", "content": "What's the weather in Beijing?"}]
            result = self.chat_completions._create_core(
                messages=messages,
                model="gpt-3.5-turbo",
                tools=tools,
                tool_choice="auto"
            )
            
            assert result == mock_response
            assert result.choices[0].message.tool_calls[0].function.name == "get_weather"


class TestAdvancedErrorHandling:
    """é«˜çº§é”™è¯¯å¤„ç†æµ‹è¯•ã€‚"""
    
    def setup_method(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒã€‚"""
        self.mock_client_manager = Mock()
        self.chat_completions = ChatCompletions(self.mock_client_manager)
    
    def test_å¤„ç†ç½‘ç»œè¶…æ—¶(self):
        """æµ‹è¯•å¤„ç†ç½‘ç»œè¶…æ—¶ã€‚"""
        import asyncio
        
        with patch('harborai.api.client.get_or_create_trace_id', return_value='test-trace-id'), \
             patch('harborai.api.client.TraceContext'), \
             patch('harborai.utils.logger.LogContext'), \
             patch('harborai.api.client.retry_with_backoff') as mock_retry, \
             patch.object(self.chat_completions.client_manager, 'chat_completion_sync_with_fallback', side_effect=asyncio.TimeoutError("è¯·æ±‚è¶…æ—¶")):
            
            # é…ç½®retryè£…é¥°å™¨è¿”å›åŸå‡½æ•°
            mock_retry.side_effect = lambda config=None: lambda func: func
            
            with pytest.raises(asyncio.TimeoutError):
                messages = [{"role": "user", "content": "Hello"}]
                self.chat_completions._create_core(
                    messages=messages,
                    model="gpt-3.5-turbo",
                    timeout=1.0
                )
    
    def test_å¤„ç†å‚æ•°é”™è¯¯(self):
        """æµ‹è¯•å¤„ç†å‚æ•°é”™è¯¯ã€‚"""
        # æµ‹è¯•æ— æ•ˆçš„temperatureå€¼
        messages = [{"role": "user", "content": "Hello"}]
        
        # å½“å‰å®ç°ä¸éªŒè¯å‚æ•°èŒƒå›´ï¼Œæ‰€ä»¥è¿™ä¸ªæµ‹è¯•éªŒè¯ä¸æŠ›å‡ºå¼‚å¸¸
        try:
            self.chat_completions._create_core(
                messages=messages,
                model="gpt-3.5-turbo",
                temperature=2.0  # è¶…å‡ºæœ‰æ•ˆèŒƒå›´
            )
        except ValidationError:
            pytest.fail("å½“å‰å®ç°ä¸åº”è¯¥éªŒè¯temperatureèŒƒå›´")
    
    def test_å¤„ç†æ¨¡å‹ä¸å­˜åœ¨é”™è¯¯(self):
        """æµ‹è¯•å¤„ç†æ¨¡å‹ä¸å­˜åœ¨é”™è¯¯ã€‚"""
        with patch('harborai.api.client.get_or_create_trace_id', return_value='test-trace-id'), \
             patch('harborai.api.client.TraceContext'), \
             patch('harborai.utils.logger.LogContext'), \
             patch('harborai.api.client.retry_with_backoff') as mock_retry, \
             patch.object(self.chat_completions.client_manager, 'chat_completion_sync_with_fallback', side_effect=HarborAIError("æ¨¡å‹ä¸å­˜åœ¨")):
            
            # é…ç½®retryè£…é¥°å™¨è¿”å›åŸå‡½æ•°
            mock_retry.side_effect = lambda config=None: lambda func: func
            
            with pytest.raises(HarborAIError, match="æ¨¡å‹ä¸å­˜åœ¨"):
                messages = [{"role": "user", "content": "Hello"}]
                self.chat_completions._create_core(
                    messages=messages,
                    model="non-existent-model"
                )


class TestAdvancedEdgeCases:
    """é«˜çº§è¾¹ç•Œæƒ…å†µæµ‹è¯•ã€‚"""
    
    def setup_method(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒã€‚"""
        self.mock_client_manager = Mock()
        self.chat_completions = ChatCompletions(self.mock_client_manager)
    
    def test_è¶…é•¿å†…å®¹(self):
        """æµ‹è¯•è¶…é•¿å†…å®¹ã€‚"""
        # åˆ›å»ºä¸€ä¸ªéå¸¸é•¿çš„æ¶ˆæ¯
        long_content = "x" * 100000
        messages = [{"role": "user", "content": long_content}]
        
        # åº”è¯¥èƒ½æ­£å¸¸éªŒè¯
        self.chat_completions._validate_messages(messages)
    
    def test_æ··åˆæ¶ˆæ¯ç±»å‹(self):
        """æµ‹è¯•æ··åˆæ¶ˆæ¯ç±»å‹ã€‚"""
        messages = [
            {"role": "user", "content": "Hello"},
            {"role": "assistant", "content": "Hi there!"},
            {"role": "user", "content": "How are you?"},
            {"role": "assistant", "tool_calls": [{"id": "call_123", "type": "function"}]},
            {"role": "tool", "content": "Function result", "tool_call_id": "call_123"}
        ]
        
        # åº”è¯¥èƒ½æ­£å¸¸éªŒè¯
        self.chat_completions._validate_messages(messages)
    
    def test_æç«¯å‚æ•°å€¼(self):
        """æµ‹è¯•æç«¯å‚æ•°å€¼ã€‚"""
        messages = [{"role": "user", "content": "Test"}]
        
        # æµ‹è¯•æç«¯çš„temperatureå€¼
        with patch('harborai.api.client.get_or_create_trace_id', return_value='test-trace-id'), \
             patch('harborai.api.client.TraceContext'), \
             patch('harborai.utils.logger.LogContext'), \
             patch('harborai.api.client.retry_with_backoff') as mock_retry, \
             patch.object(self.chat_completions.client_manager, 'chat_completion_sync_with_fallback') as mock_create:
            
            # é…ç½®retryè£…é¥°å™¨è¿”å›åŸå‡½æ•°
            mock_retry.side_effect = lambda config=None: lambda func: func
            mock_create.return_value = Mock(spec=ChatCompletion)
            
            # æœ€å°å€¼
            self.chat_completions._create_core(
                messages=messages,
                model="gpt-3.5-turbo",
                temperature=0.0
            )
            
            # æœ€å¤§å€¼
            self.chat_completions._create_core(
                messages=messages,
                model="gpt-3.5-turbo",
                temperature=2.0
            )
    
    def test_å¹¶å‘è°ƒç”¨(self):
        """æµ‹è¯•å¹¶å‘è°ƒç”¨ã€‚"""
        import threading
        
        results = []
        errors = []
        
        def make_call():
            try:
                with patch('harborai.api.client.get_or_create_trace_id', return_value='test-trace-id'), \
                     patch('harborai.api.client.TraceContext'), \
                     patch('harborai.utils.logger.LogContext'), \
                     patch('harborai.api.client.retry_with_backoff') as mock_retry, \
                     patch.object(self.chat_completions.client_manager, 'chat_completion_sync_with_fallback') as mock_create:
                    
                    # é…ç½®retryè£…é¥°å™¨è¿”å›åŸå‡½æ•°
                    mock_retry.side_effect = lambda config=None: lambda func: func
                    mock_create.return_value = Mock(spec=ChatCompletion)
                    
                    messages = [{"role": "user", "content": f"Hello from thread {threading.current_thread().ident}"}]
                    result = self.chat_completions._create_core(
                        messages=messages,
                        model="gpt-3.5-turbo"
                    )
                    results.append(result)
            except Exception as e:
                errors.append(e)
        
        # åˆ›å»ºå¤šä¸ªçº¿ç¨‹
        threads = []
        for i in range(10):
            thread = threading.Thread(target=make_call)
            threads.append(thread)
            thread.start()
        
        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for thread in threads:
            thread.join()
        
        # éªŒè¯ç»“æœ
        assert len(results) == 10
        assert len(errors) == 0


class TestParameterValidation:
    """å‚æ•°éªŒè¯æµ‹è¯•ç±»ã€‚"""
    
    def setup_method(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒã€‚"""
        self.mock_client_manager = Mock()
        self.chat_completions = ChatCompletions(self.mock_client_manager)
    
    def test_temperature_å‚æ•°éªŒè¯_éæ•°å­—ç±»å‹(self):
        """æµ‹è¯•temperatureå‚æ•°éªŒè¯ - éæ•°å­—ç±»å‹ã€‚"""
        messages = [{"role": "user", "content": "Hello"}]
        
        with pytest.raises(ValueError, match="temperature must be a number"):
            self.chat_completions._create_core(
                messages=messages,
                model="gpt-3.5-turbo",
                temperature="invalid"
            )
    
    def test_temperature_å‚æ•°éªŒè¯_è¶…å‡ºèŒƒå›´_è´Ÿæ•°(self):
        """æµ‹è¯•temperatureå‚æ•°éªŒè¯ - è´Ÿæ•°ã€‚"""
        messages = [{"role": "user", "content": "Hello"}]
        
        with pytest.raises(ValueError, match="temperature must be between 0 and 2"):
            self.chat_completions._create_core(
                messages=messages,
                model="gpt-3.5-turbo",
                temperature=-0.1
            )
    
    def test_temperature_å‚æ•°éªŒè¯_è¶…å‡ºèŒƒå›´_è¿‡å¤§(self):
        """æµ‹è¯•temperatureå‚æ•°éªŒè¯ - è¶…è¿‡2.0ã€‚"""
        messages = [{"role": "user", "content": "Hello"}]
        
        with pytest.raises(ValueError, match="temperature must be between 0 and 2"):
            self.chat_completions._create_core(
                messages=messages,
                model="gpt-3.5-turbo",
                temperature=2.1
            )
    
    def test_temperature_å‚æ•°éªŒè¯_æœ‰æ•ˆå€¼(self):
        """æµ‹è¯•temperatureå‚æ•°éªŒè¯ - æœ‰æ•ˆå€¼ã€‚"""
        messages = [{"role": "user", "content": "Hello"}]
        
        with patch.object(self.chat_completions.client_manager, 'chat_completion_sync_with_fallback') as mock_create:
            mock_response = Mock(spec=ChatCompletion)
            mock_create.return_value = mock_response
            
            # æµ‹è¯•è¾¹ç•Œå€¼
            result = self.chat_completions._create_core(
                messages=messages,
                model="gpt-3.5-turbo",
                temperature=0.0
            )
            assert result == mock_response
            
            result = self.chat_completions._create_core(
                messages=messages,
                model="gpt-3.5-turbo",
                temperature=2.0
            )
            assert result == mock_response
            
            result = self.chat_completions._create_core(
                messages=messages,
                model="gpt-3.5-turbo",
                temperature=1.0
            )
            assert result == mock_response
    
    def test_max_tokens_å‚æ•°éªŒè¯_éæ•´æ•°ç±»å‹(self):
        """æµ‹è¯•max_tokenså‚æ•°éªŒè¯ - éæ•´æ•°ç±»å‹ã€‚"""
        messages = [{"role": "user", "content": "Hello"}]
        
        with pytest.raises(ValueError, match="max_tokens must be an integer"):
            self.chat_completions._create_core(
                messages=messages,
                model="gpt-3.5-turbo",
                max_tokens="invalid"
            )
    
    def test_max_tokens_å‚æ•°éªŒè¯_éæ­£æ•°(self):
        """æµ‹è¯•max_tokenså‚æ•°éªŒè¯ - éæ­£æ•°ã€‚"""
        messages = [{"role": "user", "content": "Hello"}]
        
        with pytest.raises(ValueError, match="max_tokens must be positive"):
            self.chat_completions._create_core(
                messages=messages,
                model="gpt-3.5-turbo",
                max_tokens=0
            )
        
        with pytest.raises(ValueError, match="max_tokens must be positive"):
            self.chat_completions._create_core(
                messages=messages,
                model="gpt-3.5-turbo",
                max_tokens=-1
            )
    
    @patch('harborai.core.models.get_model_capabilities')
    def test_max_tokens_å‚æ•°éªŒè¯_è¶…å‡ºæ¨¡å‹é™åˆ¶(self, mock_get_capabilities):
        """æµ‹è¯•max_tokenså‚æ•°éªŒè¯ - è¶…å‡ºæ¨¡å‹é™åˆ¶ã€‚"""
        from harborai.core.exceptions import ValidationError as CoreValidationError
        
        messages = [{"role": "user", "content": "Hello"}]
        
        # æ¨¡æ‹Ÿæ¨¡å‹èƒ½åŠ›
        mock_capabilities = Mock()
        mock_capabilities.max_tokens_limit = 4096
        mock_get_capabilities.return_value = mock_capabilities
        
        with pytest.raises(CoreValidationError, match="max_tokens \\(5000\\) exceeds limit for model"):
            self.chat_completions._create_core(
                messages=messages,
                model="gpt-3.5-turbo",
                max_tokens=5000
            )
    
    @patch('harborai.core.models.get_model_capabilities')
    def test_max_tokens_å‚æ•°éªŒè¯_æœ‰æ•ˆå€¼(self, mock_get_capabilities):
        """æµ‹è¯•max_tokenså‚æ•°éªŒè¯ - æœ‰æ•ˆå€¼ã€‚"""
        messages = [{"role": "user", "content": "Hello"}]
        
        # æ¨¡æ‹Ÿæ¨¡å‹èƒ½åŠ›
        mock_capabilities = Mock()
        mock_capabilities.max_tokens_limit = 4096
        mock_get_capabilities.return_value = mock_capabilities
        
        with patch.object(self.chat_completions.client_manager, 'chat_completion_sync_with_fallback') as mock_create:
            mock_response = Mock(spec=ChatCompletion)
            mock_create.return_value = mock_response
            
            result = self.chat_completions._create_core(
                messages=messages,
                model="gpt-3.5-turbo",
                max_tokens=1000
            )
            assert result == mock_response
    
    def test_structured_provider_å‚æ•°éªŒè¯_æ— æ•ˆå€¼(self):
        """æµ‹è¯•structured_providerå‚æ•°éªŒè¯ - æ— æ•ˆå€¼ã€‚"""
        messages = [{"role": "user", "content": "Hello"}]
        
        with pytest.raises(ValidationError, match="Invalid structured_provider 'invalid'"):
            self.chat_completions._create_core(
                messages=messages,
                model="gpt-3.5-turbo",
                structured_provider="invalid"
            )
    
    def test_structured_provider_å‚æ•°éªŒè¯_æœ‰æ•ˆå€¼(self):
        """æµ‹è¯•structured_providerå‚æ•°éªŒè¯ - æœ‰æ•ˆå€¼ã€‚"""
        messages = [{"role": "user", "content": "Hello"}]
        
        with patch.object(self.chat_completions.client_manager, 'chat_completion_sync_with_fallback') as mock_create:
            mock_response = Mock(spec=ChatCompletion)
            mock_create.return_value = mock_response
            
            # æµ‹è¯•agently
            result = self.chat_completions._create_core(
                messages=messages,
                model="gpt-3.5-turbo",
                structured_provider="agently"
            )
            assert result == mock_response
            
            # æµ‹è¯•native
            result = self.chat_completions._create_core(
                messages=messages,
                model="gpt-3.5-turbo",
                structured_provider="native"
            )
            assert result == mock_response
    
    def test_fallback_å‚æ•°å¤„ç†_ä¼˜å…ˆçº§(self):
        """æµ‹è¯•fallbackå‚æ•°å¤„ç† - fallback_modelsä¼˜å…ˆçº§é«˜äºfallbackã€‚"""
        messages = [{"role": "user", "content": "Hello"}]
        
        with patch.object(self.chat_completions.client_manager, 'chat_completion_sync_with_fallback') as mock_create:
            mock_response = Mock(spec=ChatCompletion)
            mock_create.return_value = mock_response
            
            result = self.chat_completions._create_core(
                messages=messages,
                model="gpt-3.5-turbo",
                fallback=["gpt-4"],
                fallback_models=["claude-3"]
            )
            
            # éªŒè¯è°ƒç”¨å‚æ•°ä¸­ä½¿ç”¨äº†fallback_models
            call_args = mock_create.call_args[1]
            assert call_args['fallback'] == ["claude-3"]
    
    def test_fallback_å‚æ•°å¤„ç†_é»˜è®¤ç©ºåˆ—è¡¨(self):
        """æµ‹è¯•fallbackå‚æ•°å¤„ç† - é»˜è®¤ä¸ºç©ºåˆ—è¡¨ã€‚"""
        messages = [{"role": "user", "content": "Hello"}]
        
        with patch.object(self.chat_completions.client_manager, 'chat_completion_sync_with_fallback') as mock_create:
            mock_response = Mock(spec=ChatCompletion)
            mock_create.return_value = mock_response
            
            result = self.chat_completions._create_core(
                messages=messages,
                model="gpt-3.5-turbo"
            )
            
            # éªŒè¯è°ƒç”¨å‚æ•°ä¸­fallbackä¸ºç©ºåˆ—è¡¨
            call_args = mock_create.call_args[1]
            assert call_args['fallback'] == []


class TestAsyncParameterValidation:
    """å¼‚æ­¥å‚æ•°éªŒè¯æµ‹è¯•ç±»ã€‚"""
    
    def setup_method(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒã€‚"""
        self.mock_client_manager = Mock()
        self.chat_completions = ChatCompletions(self.mock_client_manager)
    
    @pytest.mark.asyncio
    async def test_async_temperature_å‚æ•°éªŒè¯_éæ•°å­—ç±»å‹(self):
        """æµ‹è¯•å¼‚æ­¥temperatureå‚æ•°éªŒè¯ - éæ•°å­—ç±»å‹ã€‚"""
        messages = [{"role": "user", "content": "Hello"}]
        
        with pytest.raises(ValueError, match="temperature must be a number"):
            await self.chat_completions._acreate_core(
                messages=messages,
                model="gpt-3.5-turbo",
                temperature="invalid"
            )
    
    @pytest.mark.asyncio
    async def test_async_max_tokens_å‚æ•°éªŒè¯_éæ•´æ•°ç±»å‹(self):
        """æµ‹è¯•å¼‚æ­¥max_tokenså‚æ•°éªŒè¯ - éæ•´æ•°ç±»å‹ã€‚"""
        messages = [{"role": "user", "content": "Hello"}]
        
        with pytest.raises(ValueError, match="max_tokens must be an integer"):
            await self.chat_completions._acreate_core(
                messages=messages,
                model="gpt-3.5-turbo",
                max_tokens="invalid"
            )
    
    @pytest.mark.asyncio
    async def test_async_structured_provider_å‚æ•°éªŒè¯_æ— æ•ˆå€¼(self):
        """æµ‹è¯•å¼‚æ­¥structured_providerå‚æ•°éªŒè¯ - æ— æ•ˆå€¼ã€‚"""
        messages = [{"role": "user", "content": "Hello"}]
        
        with pytest.raises(ValidationError, match="Invalid structured_provider 'invalid'. Must be 'agently' or 'native'"):
            await self.chat_completions._acreate_core(
                messages=messages,
                model="gpt-3.5-turbo",
                structured_provider="invalid"
            )


class TestFastStructuredOutputErrorHandling:
    """å¿«é€Ÿç»“æ„åŒ–è¾“å‡ºé”™è¯¯å¤„ç†æµ‹è¯•ç±»ã€‚"""
    
    def setup_method(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒã€‚"""
        self.mock_client_manager = Mock()
        self.chat_completions = ChatCompletions(self.mock_client_manager)
    
    def test_fast_structured_output_å¤„ç†å™¨å¼‚å¸¸(self):
        """æµ‹è¯•å¿«é€Ÿç»“æ„åŒ–è¾“å‡ºå¤„ç†å™¨å¼‚å¸¸æ—¶å›é€€åˆ°å¸¸è§„è·¯å¾„ã€‚"""
        messages = [{"role": "user", "content": "Hello"}]
        response_format = {"type": "json_schema", "json_schema": {"schema": {}}}
        
        with patch.object(self.chat_completions, '_get_fast_processor') as mock_get_processor:
            mock_processor = Mock()
            mock_processor.process_structured_output.side_effect = Exception("å¤„ç†å™¨é”™è¯¯")
            mock_get_processor.return_value = mock_processor
            
            with patch.object(self.chat_completions, '_create_core') as mock_create_core:
                mock_response = Mock(spec=ChatCompletion)
                mock_create_core.return_value = mock_response
                
                result = self.chat_completions._create_fast_structured_path(
                    messages=messages,
                    model="gpt-3.5-turbo",
                    response_format=response_format,
                    structured_provider="agently"
                )
                
                # éªŒè¯å›é€€åˆ°å¸¸è§„è·¯å¾„
                mock_create_core.assert_called_once()
                assert result == mock_response
    
    @pytest.mark.asyncio
    async def test_async_fast_structured_output_å¤„ç†å™¨å¼‚å¸¸(self):
        """æµ‹è¯•å¼‚æ­¥å¿«é€Ÿç»“æ„åŒ–è¾“å‡ºå¤„ç†å™¨å¼‚å¸¸æ—¶å›é€€åˆ°å¸¸è§„è·¯å¾„ã€‚"""
        messages = [{"role": "user", "content": "Hello"}]
        response_format = {"type": "json_schema", "json_schema": {"schema": {}}}
        
        with patch.object(self.chat_completions, '_get_fast_processor') as mock_get_processor:
            mock_processor = Mock()
            mock_processor.aprocess_structured_output = AsyncMock(side_effect=Exception("å¼‚æ­¥å¤„ç†å™¨é”™è¯¯"))
            mock_get_processor.return_value = mock_processor
            
            with patch.object(self.chat_completions, '_acreate_core') as mock_acreate_core:
                mock_response = Mock(spec=ChatCompletion)
                mock_acreate_core.return_value = mock_response
                
                result = await self.chat_completions._acreate_fast_structured_path(
                    messages=messages,
                    model="gpt-3.5-turbo",
                    response_format=response_format,
                    structured_provider="agently"
                )
                
                # éªŒè¯å›é€€åˆ°å¸¸è§„è·¯å¾„
                mock_acreate_core.assert_called_once()
                assert result == mock_response
    
    def test_fast_structured_output_å“åº”æ„å»ºå¼‚å¸¸(self):
        """æµ‹è¯•å¿«é€Ÿç»“æ„åŒ–è¾“å‡ºå“åº”æ„å»ºå¼‚å¸¸æ—¶å›é€€åˆ°å¸¸è§„è·¯å¾„ã€‚"""
        messages = [{"role": "user", "content": "Hello"}]
        response_format = {"type": "json_schema", "json_schema": {"schema": {}}}
        
        with patch.object(self.chat_completions, '_get_fast_processor') as mock_get_processor:
            mock_processor = Mock()
            mock_processor.process_structured_output.return_value = "valid_response"
            mock_get_processor.return_value = mock_processor
            
            # æ¨¡æ‹ŸChatCompletionæ„é€ å¤±è´¥ - éœ€è¦patchåœ¨client.pyä¸­çš„å¯¼å…¥
            with patch('harborai.api.client.ChatCompletion', side_effect=Exception("å“åº”æ„å»ºå¤±è´¥")):
                with patch.object(self.chat_completions, '_create_core') as mock_create_core:
                    mock_response = Mock(spec=ChatCompletion)
                    mock_create_core.return_value = mock_response
                    
                    result = self.chat_completions._create_fast_structured_path(
                        messages=messages,
                        model="gpt-3.5-turbo",
                        response_format=response_format,
                        structured_provider="agently"
                    )
                    
                    # éªŒè¯å›é€€åˆ°å¸¸è§„è·¯å¾„
                    mock_create_core.assert_called_once()
                    assert result == mock_response


class TestStreamingFunctionality:
    """æµå¼å¤„ç†åŠŸèƒ½æµ‹è¯•ç±»ã€‚"""
    
    def setup_method(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒã€‚"""
        self.mock_client_manager = Mock()
        self.chat_completions = ChatCompletions(self.mock_client_manager)
    
    def test_æµå¼å“åº”_åŸºæœ¬åŠŸèƒ½(self):
        """æµ‹è¯•æµå¼å“åº”åŸºæœ¬åŠŸèƒ½ã€‚"""
        messages = [{"role": "user", "content": "Hello"}]
        
        # æ¨¡æ‹Ÿæµå¼å“åº”
        mock_chunk1 = Mock(spec=ChatCompletionChunk)
        mock_chunk2 = Mock(spec=ChatCompletionChunk)
        mock_stream = iter([mock_chunk1, mock_chunk2])
        
        with patch.object(self.chat_completions.client_manager, 'chat_completion_sync_with_fallback') as mock_create:
            mock_create.return_value = mock_stream
            
            result = self.chat_completions._create_core(
                messages=messages,
                model="gpt-3.5-turbo",
                stream=True
            )
            
            # éªŒè¯è¿”å›çš„æ˜¯è¿­ä»£å™¨
            chunks = list(result)
            assert len(chunks) == 2
            assert chunks[0] == mock_chunk1
            assert chunks[1] == mock_chunk2
    
    @pytest.mark.asyncio
    async def test_å¼‚æ­¥æµå¼å“åº”_åŸºæœ¬åŠŸèƒ½(self):
        """æµ‹è¯•å¼‚æ­¥æµå¼å“åº”åŸºæœ¬åŠŸèƒ½ã€‚"""
        messages = [{"role": "user", "content": "Hello"}]
        
        # åˆ›å»ºæ¨¡æ‹Ÿçš„å¼‚æ­¥ç”Ÿæˆå™¨
        async def mock_async_generator():
            mock_chunk1 = Mock(spec=ChatCompletionChunk)
            mock_chunk1.choices = [{"delta": {"content": "Hello"}, "finish_reason": None}]
            mock_chunk2 = Mock(spec=ChatCompletionChunk)
            mock_chunk2.choices = [{"delta": {"content": " World"}, "finish_reason": "stop"}]
            yield mock_chunk1
            yield mock_chunk2
        
        with patch.object(self.chat_completions.client_manager, 'chat_completion_with_fallback', new_callable=AsyncMock) as mock_acreate:
            # ä½¿ç”¨AsyncMockå¹¶è¿”å›å¼‚æ­¥ç”Ÿæˆå™¨
            mock_acreate.return_value = mock_async_generator()
            
            result = await self.chat_completions._acreate_core(
                messages=messages,
                model="gpt-3.5-turbo",
                stream=True
            )
            
            # éªŒè¯è¿”å›çš„æ˜¯å¼‚æ­¥è¿­ä»£å™¨
            chunks = []
            async for chunk in result:
                chunks.append(chunk)
            
            assert len(chunks) == 2
            assert chunks[0].choices[0]["delta"]["content"] == "Hello"
            assert chunks[1].choices[0]["delta"]["content"] == " World"
    
    def test_æµå¼å“åº”_é”™è¯¯å¤„ç†(self):
        """æµ‹è¯•æµå¼å“åº”é”™è¯¯å¤„ç†ã€‚"""
        messages = [{"role": "user", "content": "Hello"}]
        
        with patch.object(self.chat_completions.client_manager, 'chat_completion_sync_with_fallback') as mock_create:
            mock_create.side_effect = Exception("æµå¼å¤„ç†é”™è¯¯")
            
            with pytest.raises(Exception, match="æµå¼å¤„ç†é”™è¯¯"):
                result = self.chat_completions._create_core(
                    messages=messages,
                    model="gpt-3.5-turbo",
                    stream=True
                )
                list(result)  # è§¦å‘å¼‚å¸¸
    
    @pytest.mark.asyncio
    async def test_å¼‚æ­¥æµå¼å“åº”_é”™è¯¯å¤„ç†(self):
        """æµ‹è¯•å¼‚æ­¥æµå¼å“åº”é”™è¯¯å¤„ç†ã€‚"""
        messages = [{"role": "user", "content": "Hello"}]
        
        with patch.object(self.chat_completions.client_manager, 'chat_completion_with_fallback') as mock_acreate:
            mock_acreate.side_effect = Exception("å¼‚æ­¥æµå¼å¤„ç†é”™è¯¯")
            
            with pytest.raises(Exception, match="å¼‚æ­¥æµå¼å¤„ç†é”™è¯¯"):
                await self.chat_completions._acreate_core(
                    messages=messages,
                    model="gpt-3.5-turbo",
                    stream=True
                )


class TestHarborAIAdvancedMethods:
    """HarborAIé«˜çº§æ–¹æ³•æµ‹è¯•ç±»ã€‚"""
    
    def setup_method(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒã€‚"""
        self.harbor_ai = HarborAI()
    
    def test_get_available_models_å®ç°(self):
        """æµ‹è¯•get_available_modelsæ–¹æ³•å®ç°ã€‚"""
        with patch.object(self.harbor_ai.client_manager, 'get_available_models') as mock_get_models:
            mock_models = ["gpt-3.5-turbo", "gpt-4", "claude-3"]
            mock_get_models.return_value = mock_models
            
            result = self.harbor_ai.get_available_models()
            assert result == mock_models
            mock_get_models.assert_called_once()
    
    def test_get_plugin_info_å®ç°(self):
        """æµ‹è¯•get_plugin_infoæ–¹æ³•å®ç°ã€‚"""
        with patch.object(self.harbor_ai.client_manager, 'get_plugin_info') as mock_get_info:
            mock_info = {"plugins": ["plugin1", "plugin2"]}
            mock_get_info.return_value = mock_info
            
            result = self.harbor_ai.get_plugin_info()
            assert result == mock_info
            mock_get_info.assert_called_once()
    
    def test_register_plugin_å®ç°(self):
        """æµ‹è¯•register_pluginæ–¹æ³•å®ç°ã€‚"""
        mock_plugin = Mock()
        
        with patch.object(self.harbor_ai.client_manager, 'register_plugin') as mock_register:
            self.harbor_ai.register_plugin(mock_plugin)
            mock_register.assert_called_once_with(mock_plugin)
    
    def test_unregister_plugin_å®ç°(self):
        """æµ‹è¯•unregister_pluginæ–¹æ³•å®ç°ã€‚"""
        plugin_name = "test_plugin"
        
        with patch.object(self.harbor_ai.client_manager, 'unregister_plugin') as mock_unregister:
            self.harbor_ai.unregister_plugin(plugin_name)
            mock_unregister.assert_called_once_with(plugin_name)
    
    def test_get_total_cost_with_cost_tracker(self):
        """æµ‹è¯•å¸¦æˆæœ¬è·Ÿè¸ªå™¨çš„get_total_costæ–¹æ³•ã€‚"""
        mock_cost_tracker = Mock()
        mock_cost_tracker.get_total_cost.return_value = 15.75
        
        with patch.object(self.harbor_ai, 'cost_tracker', mock_cost_tracker):
            result = self.harbor_ai.get_total_cost()
            assert result == 15.75
            mock_cost_tracker.get_total_cost.assert_called_once()
    
    def test_get_total_cost_without_cost_tracker(self):
        """æµ‹è¯•æ— æˆæœ¬è·Ÿè¸ªå™¨çš„get_total_costæ–¹æ³•ã€‚"""
        with patch.object(self.harbor_ai, 'cost_tracker', None):
            result = self.harbor_ai.get_total_cost()
            assert result == 0.0
    
    def test_reset_cost_with_cost_tracker(self):
        """æµ‹è¯•å¸¦æˆæœ¬è·Ÿè¸ªå™¨çš„reset_costæ–¹æ³•ã€‚"""
        mock_cost_tracker = Mock()
        
        with patch.object(self.harbor_ai, 'cost_tracker', mock_cost_tracker):
            self.harbor_ai.reset_cost()
            mock_cost_tracker.reset.assert_called_once()
    
    def test_reset_cost_without_cost_tracker(self):
        """æµ‹è¯•æ— æˆæœ¬è·Ÿè¸ªå™¨çš„reset_costæ–¹æ³•ã€‚"""
        with patch.object(self.harbor_ai, 'cost_tracker', None):
            # åº”è¯¥ä¸æŠ›å‡ºå¼‚å¸¸
            self.harbor_ai.reset_cost()
    
    @pytest.mark.asyncio
    async def test_aclose_with_plugin_error(self):
        """æµ‹è¯•acloseæ–¹æ³•åœ¨æ’ä»¶é”™è¯¯æ—¶çš„å¤„ç†ã€‚"""
        # åˆ›å»ºä¸€ä¸ªæœ‰acloseæ–¹æ³•çš„mockæ’ä»¶
        mock_plugin = Mock()
        mock_plugin.name = "test_plugin"
        mock_plugin.aclose = AsyncMock(side_effect=Exception("å…³é—­é”™è¯¯"))
        
        # å°†mockæ’ä»¶æ·»åŠ åˆ°client_manager.pluginsä¸­
        self.harbor_ai.client_manager.plugins = {"test_plugin": mock_plugin}
        
        # åº”è¯¥ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œåªè®°å½•æ—¥å¿—
        await self.harbor_ai.aclose()
        
        # éªŒè¯æ’ä»¶çš„acloseæ–¹æ³•è¢«è°ƒç”¨
        mock_plugin.aclose.assert_called_once()
    
    def test_close_with_plugin_error(self):
        """æµ‹è¯•closeæ–¹æ³•åœ¨æ’ä»¶é”™è¯¯æ—¶çš„å¤„ç†ã€‚"""
        # åˆ›å»ºä¸€ä¸ªæœ‰closeæ–¹æ³•çš„mockæ’ä»¶
        mock_plugin = Mock()
        mock_plugin.name = "test_plugin"
        mock_plugin.close = Mock(side_effect=Exception("å…³é—­é”™è¯¯"))
        
        # å°†mockæ’ä»¶æ·»åŠ åˆ°client_manager.pluginsä¸­
        self.harbor_ai.client_manager.plugins = {"test_plugin": mock_plugin}
        
        # åº”è¯¥ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œåªè®°å½•æ—¥å¿—
        self.harbor_ai.close()
        
        # éªŒè¯æ’ä»¶çš„closeæ–¹æ³•è¢«è°ƒç”¨
        mock_plugin.close.assert_called_once()
    
    def test_client_åˆ«åå±æ€§(self):
        """æµ‹è¯•clientåˆ«åå±æ€§ã€‚"""
        assert hasattr(self.harbor_ai, 'client')
        assert self.harbor_ai.client == self.harbor_ai