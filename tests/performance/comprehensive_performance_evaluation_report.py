#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HarborAI SDKç»¼åˆæ€§èƒ½è¯„ä¼°æŠ¥å‘Šç”Ÿæˆå™¨

æ•´åˆæ‰€æœ‰æ€§èƒ½æµ‹è¯•ç»“æœï¼Œç”Ÿæˆå®Œæ•´çš„æ€§èƒ½è¯„ä¼°æŠ¥å‘Š
"""

import json
import os
from typing import Dict, List, Any, Optional
from datetime import datetime
import statistics

class ComprehensivePerformanceReportGenerator:
    """ç»¼åˆæ€§èƒ½æŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.prd_requirements = {
            'call_overhead_ms': 1.0,
            'concurrency_success_rate': 99.9,
            'memory_leak_mb': 1.0,
            'initialization_time_ms': 500.0,
            'concurrent_throughput_ops_per_sec': 1000.0
        }
        
    def load_all_results(self) -> Dict[str, Any]:
        """åŠ è½½æ‰€æœ‰æµ‹è¯•ç»“æœ"""
        results = {}
        
        # åŠ è½½åŸºç¡€æ€§èƒ½æµ‹è¯•ç»“æœ
        try:
            with open('sdk_performance_results.json', 'r', encoding='utf-8') as f:
                results['basic_performance'] = json.load(f)
        except FileNotFoundError:
            results['basic_performance'] = {}
        
        # åŠ è½½å¯¹æ¯”æµ‹è¯•ç»“æœ
        try:
            with open('sdk_comparison_results.json', 'r', encoding='utf-8') as f:
                results['comparison'] = json.load(f)
        except FileNotFoundError:
            results['comparison'] = {}
        
        # åŠ è½½ç‰¹æœ‰åŠŸèƒ½æµ‹è¯•ç»“æœ
        try:
            with open('sdk_features_performance_results.json', 'r', encoding='utf-8') as f:
                results['features'] = json.load(f)
        except FileNotFoundError:
            results['features'] = {}
        
        # åŠ è½½åˆ†ææŠ¥å‘Šæ•°æ®
        try:
            with open('harborai_performance_analysis_report.md', 'r', encoding='utf-8') as f:
                results['analysis_report'] = f.read()
        except FileNotFoundError:
            results['analysis_report'] = ""
        
        # åŠ è½½å¯¹æ¯”æŠ¥å‘Šæ•°æ®
        try:
            with open('harborai_vs_openai_comparison_report.md', 'r', encoding='utf-8') as f:
                results['comparison_report'] = f.read()
        except FileNotFoundError:
            results['comparison_report'] = ""
        
        # åŠ è½½ä¼˜åŒ–è®¡åˆ’æ•°æ®
        try:
            with open('harborai_performance_optimization_plan.md', 'r', encoding='utf-8') as f:
                results['optimization_plan'] = f.read()
        except FileNotFoundError:
            results['optimization_plan'] = ""
        
        return results
    
    def calculate_overall_score(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """è®¡ç®—æ€»ä½“æ€§èƒ½è¯„åˆ†"""
        basic_perf = results.get('basic_performance', {})
        comparison = results.get('comparison', {})
        
        scores = {}
        
        # PRDåˆè§„æ€§è¯„åˆ†
        prd_scores = []
        
        # 1. è°ƒç”¨å¼€é”€è¯„åˆ†
        method_overhead = basic_perf.get('method_call_overhead', {})
        if method_overhead:
            avg_overhead_us = statistics.mean([
                data.get('average_us', 0) for data in method_overhead.values()
            ])
            call_overhead_ms = avg_overhead_us / 1000
            call_score = max(0, 100 - (call_overhead_ms / self.prd_requirements['call_overhead_ms']) * 100)
            prd_scores.append(call_score)
            scores['call_overhead_score'] = call_score
        
        # 2. å¹¶å‘æˆåŠŸç‡è¯„åˆ†
        concurrent_perf = basic_perf.get('concurrent_performance', {})
        if concurrent_perf:
            success_rates = [data.get('success_rate', 0) for data in concurrent_perf.values()]
            avg_success_rate = statistics.mean(success_rates) if success_rates else 0
            concurrency_score = (avg_success_rate / self.prd_requirements['concurrency_success_rate']) * 100
            prd_scores.append(concurrency_score)
            scores['concurrency_score'] = concurrency_score
        
        # 3. å†…å­˜æ³„æ¼è¯„åˆ†
        memory_usage = basic_perf.get('memory_usage', {})
        memory_leak = memory_usage.get('potential_memory_leak_mb', 0)
        memory_score = max(0, 100 - (memory_leak / self.prd_requirements['memory_leak_mb']) * 100)
        prd_scores.append(memory_score)
        scores['memory_score'] = memory_score
        
        # 4. åˆå§‹åŒ–æ—¶é—´è¯„åˆ†
        init_overhead = basic_perf.get('initialization_overhead', {})
        if init_overhead:
            init_times = [data.get('average_ms', 0) for data in init_overhead.values()]
            avg_init_time = statistics.mean(init_times) if init_times else 0
            init_score = max(0, 100 - (avg_init_time / self.prd_requirements['initialization_time_ms']) * 100)
            prd_scores.append(init_score)
            scores['initialization_score'] = init_score
        
        # 5. å¹¶å‘ååé‡è¯„åˆ†
        if concurrent_perf:
            throughputs = [data.get('operations_per_second', 0) for data in concurrent_perf.values()]
            max_throughput = max(throughputs) if throughputs else 0
            throughput_score = min(100, (max_throughput / self.prd_requirements['concurrent_throughput_ops_per_sec']) * 100)
            prd_scores.append(throughput_score)
            scores['throughput_score'] = throughput_score
        
        # PRDæ€»ä½“åˆè§„æ€§è¯„åˆ†
        scores['prd_compliance_score'] = statistics.mean(prd_scores) if prd_scores else 0
        
        # ä¸OpenAI SDKå¯¹æ¯”è¯„åˆ†
        harborai_data = comparison.get('HarborAI', {})
        openai_data = comparison.get('OpenAI', {})
        
        if harborai_data and openai_data:
            comparison_scores = []
            
            # åˆå§‹åŒ–æ—¶é—´å¯¹æ¯”
            harbor_init = harborai_data.get('initialization_time_ms', 0)
            openai_init = openai_data.get('initialization_time_ms', 0)
            if openai_init > 0:
                init_comparison = min(100, (openai_init / harbor_init) * 100)
                comparison_scores.append(init_comparison)
            
            # æ–¹æ³•è°ƒç”¨å¼€é”€å¯¹æ¯”
            harbor_call = harborai_data.get('method_call_overhead_us', 0)
            openai_call = openai_data.get('method_call_overhead_us', 0)
            if openai_call > 0:
                call_comparison = min(100, (openai_call / harbor_call) * 100)
                comparison_scores.append(call_comparison)
            
            # å†…å­˜ä½¿ç”¨å¯¹æ¯”
            harbor_mem = harborai_data.get('memory_usage_mb', 0)
            openai_mem = openai_data.get('memory_usage_mb', 0)
            if openai_mem > 0:
                mem_comparison = min(100, (openai_mem / harbor_mem) * 100)
                comparison_scores.append(mem_comparison)
            
            # å¹¶å‘ååé‡å¯¹æ¯”
            harbor_throughput = harborai_data.get('concurrent_throughput_ops_per_sec', 0)
            openai_throughput = openai_data.get('concurrent_throughput_ops_per_sec', 0)
            if openai_throughput > 0:
                throughput_comparison = min(100, (harbor_throughput / openai_throughput) * 100)
                comparison_scores.append(throughput_comparison)
            
            scores['openai_comparison_score'] = statistics.mean(comparison_scores) if comparison_scores else 0
        
        # ç‰¹æœ‰åŠŸèƒ½æ€§èƒ½è¯„åˆ†
        features = results.get('features', {})
        if features:
            feature_scores = []
            for feature_name, data in features.items():
                # åŸºäºæ“ä½œå¼€é”€å’Œååé‡è®¡ç®—åŠŸèƒ½è¯„åˆ†
                operation_overhead = data.get('operation_overhead_us', 0)
                throughput = data.get('throughput_ops_per_sec', 0)
                success_rate = data.get('success_rate_percent', 0)
                
                # æ“ä½œå¼€é”€è¯„åˆ† (è¶Šä½è¶Šå¥½)
                overhead_score = max(0, 100 - operation_overhead * 2)  # æ¯å¾®ç§’æ‰£2åˆ†
                
                # ååé‡è¯„åˆ† (è¶Šé«˜è¶Šå¥½)
                throughput_score = min(100, throughput / 10)  # æ¯10ops/så¾—1åˆ†
                
                # æˆåŠŸç‡è¯„åˆ†
                success_score = success_rate
                
                feature_score = (overhead_score + throughput_score + success_score) / 3
                feature_scores.append(feature_score)
            
            scores['features_score'] = statistics.mean(feature_scores) if feature_scores else 0
        
        # æ€»ä½“è¯„åˆ†
        all_scores = [
            scores.get('prd_compliance_score', 0),
            scores.get('openai_comparison_score', 0),
            scores.get('features_score', 0)
        ]
        scores['overall_score'] = statistics.mean([s for s in all_scores if s > 0])
        
        return scores
    
    def generate_executive_summary(self, results: Dict[str, Any], scores: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ‰§è¡Œæ‘˜è¦"""
        summary = []
        
        overall_score = scores.get('overall_score', 0)
        prd_score = scores.get('prd_compliance_score', 0)
        comparison_score = scores.get('openai_comparison_score', 0)
        
        # æ€»ä½“è¯„ä»·
        if overall_score >= 80:
            performance_level = "ä¼˜ç§€"
            recommendation = "HarborAI SDKæ€§èƒ½è¡¨ç°ä¼˜å¼‚ï¼Œæ»¡è¶³ç”Ÿäº§ç¯å¢ƒè¦æ±‚"
        elif overall_score >= 60:
            performance_level = "è‰¯å¥½"
            recommendation = "HarborAI SDKæ€§èƒ½è¡¨ç°è‰¯å¥½ï¼Œå»ºè®®è¿›è¡Œéƒ¨åˆ†ä¼˜åŒ–"
        elif overall_score >= 40:
            performance_level = "ä¸€èˆ¬"
            recommendation = "HarborAI SDKæ€§èƒ½æœ‰å¾…æå‡ï¼Œéœ€è¦é‡ç‚¹ä¼˜åŒ–"
        else:
            performance_level = "è¾ƒå·®"
            recommendation = "HarborAI SDKæ€§èƒ½å­˜åœ¨ä¸¥é‡é—®é¢˜ï¼Œéœ€è¦å…¨é¢ä¼˜åŒ–"
        
        summary.append(f"## æ‰§è¡Œæ‘˜è¦")
        summary.append(f"")
        summary.append(f"### æ€»ä½“è¯„ä»·: {performance_level} ({overall_score:.1f}/100)")
        summary.append(f"{recommendation}")
        summary.append(f"")
        summary.append(f"### å…³é”®æŒ‡æ ‡")
        summary.append(f"- **PRDåˆè§„æ€§**: {prd_score:.1f}/100")
        summary.append(f"- **ä¸OpenAI SDKå¯¹æ¯”**: {comparison_score:.1f}/100")
        summary.append(f"- **ç‰¹æœ‰åŠŸèƒ½æ€§èƒ½**: {scores.get('features_score', 0):.1f}/100")
        summary.append(f"")
        
        # ä¸»è¦å‘ç°
        summary.append(f"### ä¸»è¦å‘ç°")
        
        basic_perf = results.get('basic_performance', {})
        comparison = results.get('comparison', {})
        
        # PRDåˆè§„æ€§åˆ†æ
        if prd_score >= 80:
            summary.append(f"âœ… **PRDåˆè§„æ€§ä¼˜ç§€**: æ‰€æœ‰å…³é”®æ€§èƒ½æŒ‡æ ‡å‡æ»¡è¶³è®¾è®¡è¦æ±‚")
        elif prd_score >= 60:
            summary.append(f"âš ï¸ **PRDåˆè§„æ€§è‰¯å¥½**: å¤§éƒ¨åˆ†æ€§èƒ½æŒ‡æ ‡æ»¡è¶³è¦æ±‚ï¼Œå°‘æ•°æŒ‡æ ‡éœ€è¦ä¼˜åŒ–")
        else:
            summary.append(f"âŒ **PRDåˆè§„æ€§ä¸è¶³**: å¤šé¡¹å…³é”®æ€§èƒ½æŒ‡æ ‡æœªè¾¾åˆ°è®¾è®¡è¦æ±‚")
        
        # ä¸OpenAI SDKå¯¹æ¯”åˆ†æ
        if comparison_score >= 80:
            summary.append(f"âœ… **ç«äº‰åŠ›å¼º**: æ€§èƒ½è¡¨ç°æ¥è¿‘æˆ–è¶…è¶ŠOpenAI SDK")
        elif comparison_score >= 50:
            summary.append(f"âš ï¸ **ç«äº‰åŠ›ä¸€èˆ¬**: æ€§èƒ½ç•¥é€ŠäºOpenAI SDKï¼Œæœ‰ä¼˜åŒ–ç©ºé—´")
        else:
            summary.append(f"âŒ **ç«äº‰åŠ›ä¸è¶³**: æ€§èƒ½æ˜æ˜¾è½åäºOpenAI SDKï¼Œéœ€è¦é‡ç‚¹ä¼˜åŒ–")
        
        # ç‰¹æœ‰åŠŸèƒ½åˆ†æ
        features_score = scores.get('features_score', 0)
        if features_score >= 70:
            summary.append(f"âœ… **ç‰¹æœ‰åŠŸèƒ½æ€§èƒ½è‰¯å¥½**: æ’ä»¶æ¶æ„ç­‰ç‰¹æœ‰åŠŸèƒ½è¿è¡Œé«˜æ•ˆ")
        elif features_score >= 50:
            summary.append(f"âš ï¸ **ç‰¹æœ‰åŠŸèƒ½æ€§èƒ½ä¸€èˆ¬**: éƒ¨åˆ†ç‰¹æœ‰åŠŸèƒ½å­˜åœ¨æ€§èƒ½å¼€é”€")
        else:
            summary.append(f"âŒ **ç‰¹æœ‰åŠŸèƒ½æ€§èƒ½ä¸ä½³**: ç‰¹æœ‰åŠŸèƒ½æ˜¾è‘—å½±å“æ•´ä½“æ€§èƒ½")
        
        summary.append(f"")
        
        return "\n".join(summary)
    
    def generate_detailed_analysis(self, results: Dict[str, Any], scores: Dict[str, Any]) -> str:
        """ç”Ÿæˆè¯¦ç»†åˆ†æ"""
        analysis = []
        
        analysis.append("## è¯¦ç»†æ€§èƒ½åˆ†æ")
        analysis.append("")
        
        # åŸºç¡€æ€§èƒ½åˆ†æ
        basic_perf = results.get('basic_performance', {})
        if basic_perf:
            analysis.append("### åŸºç¡€æ€§èƒ½æŒ‡æ ‡")
            
            # åˆå§‹åŒ–æ€§èƒ½
            init_overhead = basic_perf.get('initialization_overhead', {})
            if init_overhead:
                analysis.append("#### åˆå§‹åŒ–æ€§èƒ½")
                for mode, data in init_overhead.items():
                    avg_time = data.get('average_ms', 0)
                    analysis.append(f"- **{mode}æ¨¡å¼**: {avg_time:.2f}ms")
                analysis.append("")
            
            # æ–¹æ³•è°ƒç”¨æ€§èƒ½
            method_overhead = basic_perf.get('method_call_overhead', {})
            if method_overhead:
                analysis.append("#### æ–¹æ³•è°ƒç”¨æ€§èƒ½")
                for method, data in method_overhead.items():
                    avg_overhead = data.get('average_us', 0)
                    analysis.append(f"- **{method}**: {avg_overhead:.2f}Î¼s")
                analysis.append("")
            
            # å†…å­˜ä½¿ç”¨
            memory_usage = basic_perf.get('memory_usage', {})
            if memory_usage:
                analysis.append("#### å†…å­˜ä½¿ç”¨")
                baseline = memory_usage.get('baseline_mb', 0)
                leak = memory_usage.get('potential_memory_leak_mb', 0)
                analysis.append(f"- **åŸºå‡†å†…å­˜**: {baseline:.2f}MB")
                analysis.append(f"- **æ½œåœ¨å†…å­˜æ³„æ¼**: {leak:.2f}MB")
                analysis.append("")
            
            # å¹¶å‘æ€§èƒ½
            concurrent_perf = basic_perf.get('concurrent_performance', {})
            if concurrent_perf:
                analysis.append("#### å¹¶å‘æ€§èƒ½")
                for concurrency, data in concurrent_perf.items():
                    throughput = data.get('operations_per_second', 0)
                    success_rate = data.get('success_rate', 0)
                    analysis.append(f"- **{concurrency}å¹¶å‘**: {throughput:.1f}ops/s, æˆåŠŸç‡{success_rate:.1f}%")
                analysis.append("")
        
        # å¯¹æ¯”åˆ†æ
        comparison = results.get('comparison', {})
        if comparison:
            analysis.append("### ä¸OpenAI SDKå¯¹æ¯”")
            
            harborai_data = comparison.get('HarborAI', {})
            openai_data = comparison.get('OpenAI', {})
            
            if harborai_data and openai_data:
                analysis.append("| æŒ‡æ ‡ | HarborAI | OpenAI | å·®è· |")
                analysis.append("|------|----------|--------|------|")
                
                # åˆå§‹åŒ–æ—¶é—´
                harbor_init = harborai_data.get('initialization_time_ms', 0)
                openai_init = openai_data.get('initialization_time_ms', 0)
                init_diff = harbor_init - openai_init
                init_pct = (init_diff / openai_init * 100) if openai_init > 0 else 0
                analysis.append(f"| åˆå§‹åŒ–æ—¶é—´ | {harbor_init:.2f}ms | {openai_init:.2f}ms | {init_pct:+.1f}% |")
                
                # æ–¹æ³•è°ƒç”¨å¼€é”€
                harbor_call = harborai_data.get('method_call_overhead_us', 0)
                openai_call = openai_data.get('method_call_overhead_us', 0)
                call_diff = harbor_call - openai_call
                call_pct = (call_diff / openai_call * 100) if openai_call > 0 else 0
                analysis.append(f"| æ–¹æ³•è°ƒç”¨å¼€é”€ | {harbor_call:.2f}Î¼s | {openai_call:.2f}Î¼s | {call_pct:+.1f}% |")
                
                # å†…å­˜ä½¿ç”¨
                harbor_mem = harborai_data.get('memory_usage_mb', 0)
                openai_mem = openai_data.get('memory_usage_mb', 0)
                mem_diff = harbor_mem - openai_mem
                mem_pct = (mem_diff / openai_mem * 100) if openai_mem > 0 else 0
                analysis.append(f"| å†…å­˜ä½¿ç”¨ | {harbor_mem:.2f}MB | {openai_mem:.2f}MB | {mem_pct:+.1f}% |")
                
                # å¹¶å‘ååé‡
                harbor_throughput = harborai_data.get('concurrent_throughput_ops_per_sec', 0)
                openai_throughput = openai_data.get('concurrent_throughput_ops_per_sec', 0)
                throughput_diff = harbor_throughput - openai_throughput
                throughput_pct = (throughput_diff / openai_throughput * 100) if openai_throughput > 0 else 0
                analysis.append(f"| å¹¶å‘ååé‡ | {harbor_throughput:.1f}ops/s | {openai_throughput:.1f}ops/s | {throughput_pct:+.1f}% |")
                
                analysis.append("")
        
        # ç‰¹æœ‰åŠŸèƒ½åˆ†æ
        features = results.get('features', {})
        if features:
            analysis.append("### ç‰¹æœ‰åŠŸèƒ½æ€§èƒ½")
            
            analysis.append("| åŠŸèƒ½ | æ“ä½œå¼€é”€ | å†…å­˜å¼€é”€ | ååé‡ | æˆåŠŸç‡ |")
            analysis.append("|------|----------|----------|--------|--------|")
            
            for feature_name, data in features.items():
                operation_overhead = data.get('operation_overhead_us', 0)
                memory_overhead = data.get('memory_overhead_mb', 0)
                throughput = data.get('throughput_ops_per_sec', 0)
                success_rate = data.get('success_rate_percent', 0)
                
                analysis.append(f"| {feature_name} | {operation_overhead:.2f}Î¼s | {memory_overhead:.2f}MB | {throughput:.1f}ops/s | {success_rate:.1f}% |")
            
            analysis.append("")
        
        return "\n".join(analysis)
    
    def generate_recommendations_summary(self, results: Dict[str, Any]) -> str:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®æ‘˜è¦"""
        recommendations = []
        
        recommendations.append("## ä¼˜åŒ–å»ºè®®æ‘˜è¦")
        recommendations.append("")
        
        # åŸºäºåˆ†æç»“æœç”Ÿæˆå»ºè®®
        basic_perf = results.get('basic_performance', {})
        comparison = results.get('comparison', {})
        
        # åˆå§‹åŒ–ä¼˜åŒ–å»ºè®®
        init_overhead = basic_perf.get('initialization_overhead', {})
        if init_overhead:
            avg_init_times = [data.get('average_ms', 0) for data in init_overhead.values()]
            max_init_time = max(avg_init_times) if avg_init_times else 0
            
            if max_init_time > 200:
                recommendations.append("### ğŸ”¥ é«˜ä¼˜å…ˆçº§ä¼˜åŒ–")
                recommendations.append("1. **åˆå§‹åŒ–æ€§èƒ½ä¼˜åŒ–**")
                recommendations.append("   - å®ç°å»¶è¿ŸåŠ è½½æœºåˆ¶")
                recommendations.append("   - ä¼˜åŒ–æ’ä»¶åˆå§‹åŒ–æµç¨‹")
                recommendations.append("   - å¹¶è¡ŒåŒ–åˆå§‹åŒ–æ“ä½œ")
                recommendations.append("")
        
        # æ–¹æ³•è°ƒç”¨ä¼˜åŒ–å»ºè®®
        method_overhead = basic_perf.get('method_call_overhead', {})
        if method_overhead:
            avg_overheads = [data.get('average_us', 0) for data in method_overhead.values()]
            max_overhead = max(avg_overheads) if avg_overheads else 0
            
            if max_overhead > 1:
                recommendations.append("2. **æ–¹æ³•è°ƒç”¨æ€§èƒ½ä¼˜åŒ–**")
                recommendations.append("   - ç®€åŒ–æ–¹æ³•è°ƒç”¨é“¾")
                recommendations.append("   - å‡å°‘å‚æ•°éªŒè¯å¼€é”€")
                recommendations.append("   - ä¼˜åŒ–è£…é¥°å™¨å’Œä¸­é—´ä»¶")
                recommendations.append("")
        
        # å†…å­˜ä¼˜åŒ–å»ºè®®
        memory_usage = basic_perf.get('memory_usage', {})
        memory_leak = memory_usage.get('potential_memory_leak_mb', 0)
        
        if memory_leak > 1:
            recommendations.append("3. **å†…å­˜ç®¡ç†ä¼˜åŒ–**")
            recommendations.append("   - ä¿®å¤å†…å­˜æ³„æ¼é—®é¢˜")
            recommendations.append("   - ä¼˜åŒ–å¯¹è±¡ç”Ÿå‘½å‘¨æœŸç®¡ç†")
            recommendations.append("   - å®ç°å†…å­˜ç›‘æ§æœºåˆ¶")
            recommendations.append("")
        
        # å¹¶å‘ä¼˜åŒ–å»ºè®®
        concurrent_perf = basic_perf.get('concurrent_performance', {})
        if concurrent_perf:
            success_rates = [data.get('success_rate', 0) for data in concurrent_perf.values()]
            min_success_rate = min(success_rates) if success_rates else 100
            
            if min_success_rate < 99:
                recommendations.append("### âš ï¸ ä¸­ä¼˜å…ˆçº§ä¼˜åŒ–")
                recommendations.append("4. **å¹¶å‘ç¨³å®šæ€§ä¼˜åŒ–**")
                recommendations.append("   - æé«˜å¹¶å‘å¤„ç†ç¨³å®šæ€§")
                recommendations.append("   - ä¼˜åŒ–é”™è¯¯å¤„ç†æœºåˆ¶")
                recommendations.append("   - å®ç°æ›´å¥½çš„èµ„æºç®¡ç†")
                recommendations.append("")
        
        # ä¸OpenAI SDKå¯¹æ¯”çš„ä¼˜åŒ–å»ºè®®
        if comparison:
            harborai_data = comparison.get('HarborAI', {})
            openai_data = comparison.get('OpenAI', {})
            
            if harborai_data and openai_data:
                harbor_throughput = harborai_data.get('concurrent_throughput_ops_per_sec', 0)
                openai_throughput = openai_data.get('concurrent_throughput_ops_per_sec', 0)
                
                if harbor_throughput < openai_throughput * 0.8:  # å¦‚æœååé‡ä½äºOpenAIçš„80%
                    recommendations.append("5. **ç«äº‰åŠ›æå‡ä¼˜åŒ–**")
                    recommendations.append("   - å‚è€ƒOpenAI SDKçš„æ€§èƒ½ä¼˜åŒ–ç­–ç•¥")
                    recommendations.append("   - é‡ç‚¹ä¼˜åŒ–å¹¶å‘å¤„ç†èƒ½åŠ›")
                    recommendations.append("   - å‡å°‘ç‰¹æœ‰åŠŸèƒ½çš„æ€§èƒ½å¼€é”€")
                    recommendations.append("")
        
        # ç‰¹æœ‰åŠŸèƒ½ä¼˜åŒ–å»ºè®®
        features = results.get('features', {})
        if features:
            high_overhead_features = [
                name for name, data in features.items()
                if data.get('operation_overhead_us', 0) > 10
            ]
            
            if high_overhead_features:
                recommendations.append("### ğŸ’¡ é•¿æœŸä¼˜åŒ–")
                recommendations.append("6. **ç‰¹æœ‰åŠŸèƒ½æ€§èƒ½ä¼˜åŒ–**")
                for feature in high_overhead_features:
                    recommendations.append(f"   - ä¼˜åŒ–{feature}çš„å®ç°æ•ˆç‡")
                recommendations.append("   - å®ç°åŠŸèƒ½å¼€å…³å’ŒæŒ‰éœ€åŠ è½½")
                recommendations.append("   - ä¼˜åŒ–æ’ä»¶æ¶æ„è®¾è®¡")
                recommendations.append("")
        
        if not any("ä¼˜å…ˆçº§ä¼˜åŒ–" in line for line in recommendations):
            recommendations.append("### âœ… æ€§èƒ½è¡¨ç°è‰¯å¥½")
            recommendations.append("å½“å‰æ€§èƒ½æŒ‡æ ‡åŸºæœ¬æ»¡è¶³è¦æ±‚ï¼Œå»ºè®®ï¼š")
            recommendations.append("- æŒç»­ç›‘æ§æ€§èƒ½æŒ‡æ ‡")
            recommendations.append("- å®šæœŸè¿›è¡Œæ€§èƒ½å›å½’æµ‹è¯•")
            recommendations.append("- å…³æ³¨æ–°åŠŸèƒ½å¯¹æ€§èƒ½çš„å½±å“")
            recommendations.append("")
        
        return "\n".join(recommendations)
    
    def generate_comprehensive_report(self) -> str:
        """ç”Ÿæˆç»¼åˆæ€§èƒ½è¯„ä¼°æŠ¥å‘Š"""
        print("ğŸ“Š ç”Ÿæˆç»¼åˆæ€§èƒ½è¯„ä¼°æŠ¥å‘Š...")
        
        # åŠ è½½æ‰€æœ‰ç»“æœ
        results = self.load_all_results()
        
        # è®¡ç®—è¯„åˆ†
        scores = self.calculate_overall_score(results)
        
        # ç”ŸæˆæŠ¥å‘Š
        report = []
        
        # æŠ¥å‘Šå¤´éƒ¨
        report.append("# HarborAI SDKç»¼åˆæ€§èƒ½è¯„ä¼°æŠ¥å‘Š")
        report.append("=" * 80)
        report.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"**è¯„ä¼°ç‰ˆæœ¬**: HarborAI SDK v1.0")
        report.append(f"**æµ‹è¯•ç¯å¢ƒ**: Windows 11, Python 3.x")
        report.append("")
        
        # æ‰§è¡Œæ‘˜è¦
        report.append(self.generate_executive_summary(results, scores))
        
        # è¯¦ç»†åˆ†æ
        report.append(self.generate_detailed_analysis(results, scores))
        
        # ä¼˜åŒ–å»ºè®®æ‘˜è¦
        report.append(self.generate_recommendations_summary(results))
        
        # æµ‹è¯•æ–¹æ³•è¯´æ˜
        report.append("## æµ‹è¯•æ–¹æ³•è¯´æ˜")
        report.append("")
        report.append("### æµ‹è¯•èŒƒå›´")
        report.append("- **åŸºç¡€æ€§èƒ½æµ‹è¯•**: åˆå§‹åŒ–æ—¶é—´ã€æ–¹æ³•è°ƒç”¨å¼€é”€ã€å†…å­˜ä½¿ç”¨ã€å¹¶å‘æ€§èƒ½")
        report.append("- **å¯¹æ¯”æµ‹è¯•**: ä¸OpenAI SDKçš„æ€§èƒ½å¯¹æ¯”")
        report.append("- **ç‰¹æœ‰åŠŸèƒ½æµ‹è¯•**: æ’ä»¶æ¶æ„ã€ç»“æ„åŒ–è¾“å‡ºã€æ¨ç†æ¨¡å‹æ”¯æŒç­‰")
        report.append("")
        report.append("### æµ‹è¯•ç¯å¢ƒ")
        report.append("- **æ“ä½œç³»ç»Ÿ**: Windows 11")
        report.append("- **Pythonç‰ˆæœ¬**: 3.x")
        report.append("- **æµ‹è¯•å·¥å…·**: è‡ªå®šä¹‰æ€§èƒ½æµ‹è¯•æ¡†æ¶")
        report.append("- **æµ‹è¯•æ•°æ®**: æ¨¡æ‹ŸçœŸå®ä½¿ç”¨åœºæ™¯")
        report.append("")
        
        # ç»“è®º
        report.append("## æ€»ç»“ä¸ç»“è®º")
        report.append("")
        
        overall_score = scores.get('overall_score', 0)
        prd_score = scores.get('prd_compliance_score', 0)
        
        if overall_score >= 80 and prd_score >= 80:
            report.append("âœ… **HarborAI SDKæ€§èƒ½è¡¨ç°ä¼˜ç§€**")
            report.append("- æ‰€æœ‰å…³é”®æ€§èƒ½æŒ‡æ ‡å‡æ»¡è¶³PRDè¦æ±‚")
            report.append("- ä¸ä¸»æµSDKç›¸æ¯”å…·æœ‰ç«äº‰ä¼˜åŠ¿")
            report.append("- ç‰¹æœ‰åŠŸèƒ½è¿è¡Œé«˜æ•ˆï¼Œæ¶æ„è®¾è®¡åˆç†")
            report.append("- å»ºè®®ç»§ç»­ä¿æŒå½“å‰æ€§èƒ½æ°´å¹³ï¼Œå…³æ³¨æ–°åŠŸèƒ½çš„æ€§èƒ½å½±å“")
        elif overall_score >= 60:
            report.append("âš ï¸ **HarborAI SDKæ€§èƒ½è¡¨ç°è‰¯å¥½ï¼Œæœ‰ä¼˜åŒ–ç©ºé—´**")
            report.append("- å¤§éƒ¨åˆ†æ€§èƒ½æŒ‡æ ‡æ»¡è¶³è¦æ±‚")
            report.append("- éƒ¨åˆ†æŒ‡æ ‡éœ€è¦é’ˆå¯¹æ€§ä¼˜åŒ–")
            report.append("- å»ºè®®æŒ‰ç…§ä¼˜åŒ–è®¡åˆ’é€æ­¥æ”¹è¿›")
        else:
            report.append("âŒ **HarborAI SDKæ€§èƒ½éœ€è¦é‡ç‚¹ä¼˜åŒ–**")
            report.append("- å¤šé¡¹å…³é”®æŒ‡æ ‡æœªè¾¾åˆ°é¢„æœŸ")
            report.append("- éœ€è¦åˆ¶å®šå…¨é¢çš„æ€§èƒ½ä¼˜åŒ–è®¡åˆ’")
            report.append("- å»ºè®®ä¼˜å…ˆè§£å†³é«˜å½±å“çš„æ€§èƒ½é—®é¢˜")
        
        report.append("")
        report.append("---")
        report.append("*æœ¬æŠ¥å‘ŠåŸºäºè‡ªåŠ¨åŒ–æ€§èƒ½æµ‹è¯•ç”Ÿæˆï¼Œå»ºè®®ç»“åˆå®é™…ä¸šåŠ¡åœºæ™¯è¿›è¡ŒéªŒè¯*")
        
        return "\n".join(report)

def main():
    """ä¸»å‡½æ•°"""
    generator = ComprehensivePerformanceReportGenerator()
    
    try:
        comprehensive_report = generator.generate_comprehensive_report()
        
        # ä¿å­˜ç»¼åˆæŠ¥å‘Š
        report_file = "harborai_comprehensive_performance_evaluation_report.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(comprehensive_report)
        
        print(f"âœ… ç»¼åˆæ€§èƒ½è¯„ä¼°æŠ¥å‘Šå·²ç”Ÿæˆ")
        print(f"ğŸ“„ æŠ¥å‘Šæ–‡ä»¶: {report_file}")
        
        return 0
        
    except Exception as e:
        print(f"âŒ ç»¼åˆæŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    exit(main())