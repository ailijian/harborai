#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»¼åˆè¦†ç›–ç‡æµ‹è¯•

ä¸“é—¨ç”¨äºæå‡æ•´ä½“æµ‹è¯•è¦†ç›–ç‡çš„æµ‹è¯•æ–‡ä»¶ï¼Œé‡ç‚¹æµ‹è¯•è¾¹ç•Œæ¡ä»¶ã€é”™è¯¯å¤„ç†å’Œæç«¯åœºæ™¯
"""

import pytest
import asyncio
import os
import sys
import tempfile
import json
from unittest.mock import Mock, patch, AsyncMock
from datetime import datetime, timedelta
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from harborai import HarborAI
from harborai.utils.exceptions import (
    HarborAIError, 
    ValidationError,
    APIError,
    RateLimitError,
    AuthenticationError,
    ModelNotFoundError,
    PluginError,
    StructuredOutputError,
    StorageError,
    TimeoutError
)
from harborai.core.exceptions import RetryableError
from harborai.config.settings import Settings
from harborai.core.pricing import PricingCalculator
from harborai.monitoring.token_statistics import TokenStatisticsCollector
from harborai.utils.logger import get_logger
from harborai.core.retry import RetryManager
from harborai.core.observability import TracingManager


class TestExceptionHandling:
    """å¼‚å¸¸å¤„ç†æµ‹è¯•ç±»"""
    
    @pytest.mark.unit
    @pytest.mark.p1
    def test_harborai_error_creation(self):
        """æµ‹è¯•HarborAIé”™è¯¯åˆ›å»º"""
        # åŸºæœ¬é”™è¯¯
        error = HarborAIError("æµ‹è¯•é”™è¯¯")
        assert str(error) == "æµ‹è¯•é”™è¯¯"
        assert error.message == "æµ‹è¯•é”™è¯¯"
        
        # å¸¦é”™è¯¯ä»£ç çš„é”™è¯¯
        error_with_code = HarborAIError("æµ‹è¯•é”™è¯¯", error_code="TEST_001")
        assert error_with_code.error_code == "TEST_001"
        
        # å¸¦è¯¦ç»†ä¿¡æ¯çš„é”™è¯¯
        error_with_details = HarborAIError(
            "æµ‹è¯•é”™è¯¯", 
            error_code="TEST_002",
            details={"key": "value"}
        )
        assert error_with_details.details == {"key": "value"}
    
    @pytest.mark.unit
    @pytest.mark.p1
    def test_model_not_found_error(self):
        """æµ‹è¯•æ¨¡å‹æœªæ‰¾åˆ°é”™è¯¯"""
        error = ModelNotFoundError("test-model")
        assert isinstance(error, HarborAIError)
        assert "test-model" in str(error)
        assert error.model_name == "test-model"
    
    @pytest.mark.unit
    @pytest.mark.p1
    def test_validation_error(self):
        """æµ‹è¯•éªŒè¯é”™è¯¯"""
        error = ValidationError("éªŒè¯å¤±è´¥", field="test_field")
        assert isinstance(error, HarborAIError)
        assert error.field == "test_field"
    
    @pytest.mark.unit
    @pytest.mark.p1
    def test_api_error(self):
        """æµ‹è¯•APIé”™è¯¯"""
        error = APIError("APIè°ƒç”¨å¤±è´¥", status_code=500)
        assert isinstance(error, HarborAIError)
        assert error.status_code == 500
    
    @pytest.mark.unit
    @pytest.mark.p1
    def test_rate_limit_error(self):
        """æµ‹è¯•é€Ÿç‡é™åˆ¶é”™è¯¯"""
        error = RateLimitError("é€Ÿç‡é™åˆ¶", retry_after=60)
        assert isinstance(error, APIError)
        assert error.retry_after == 60
    
    @pytest.mark.unit
    @pytest.mark.p1
    def test_authentication_error(self):
        """æµ‹è¯•è®¤è¯é”™è¯¯"""
        error = AuthenticationError("è®¤è¯å¤±è´¥")
        assert isinstance(error, APIError)
        assert str(error) == "[AUTHENTICATION_ERROR] è®¤è¯å¤±è´¥"


class TestSettingsConfiguration:
    """è®¾ç½®é…ç½®æµ‹è¯•ç±»"""
    
    @pytest.mark.unit
    @pytest.mark.p1
    def test_settings_default_values(self):
        """æµ‹è¯•è®¾ç½®é»˜è®¤å€¼"""
        settings = Settings()
        
        # æ£€æŸ¥é»˜è®¤å€¼
        assert settings.default_timeout > 0
        assert settings.max_retries >= 0
        assert isinstance(settings.plugin_directories, list)
        assert len(settings.plugin_directories) > 0
    
    @pytest.mark.unit
    @pytest.mark.p1
    def test_settings_custom_values(self):
        """æµ‹è¯•è‡ªå®šä¹‰è®¾ç½®å€¼"""
        custom_settings = Settings(
            default_timeout=60,
            max_retries=5,
            plugin_directories=["custom.plugins"]
        )
        
        assert custom_settings.default_timeout == 60
        assert custom_settings.max_retries == 5
        assert custom_settings.plugin_directories == ["custom.plugins"]
    
    @pytest.mark.unit
    @pytest.mark.p1
    def test_settings_environment_variables(self):
        """æµ‹è¯•ç¯å¢ƒå˜é‡è®¾ç½®"""
        with patch.dict(os.environ, {
            "HARBORAI_DEFAULT_TIMEOUT": "120",
            "HARBORAI_MAX_RETRIES": "10"
        }):
            settings = Settings()
            # æ³¨æ„ï¼šå®é™…å®ç°å¯èƒ½éœ€è¦æ”¯æŒç¯å¢ƒå˜é‡
            # è¿™é‡Œåªæ˜¯æµ‹è¯•æ¡†æ¶
    
    @pytest.mark.unit
    @pytest.mark.p1
    def test_settings_validation(self):
        """æµ‹è¯•è®¾ç½®éªŒè¯"""
        import os
        from pydantic import ValidationError as PydanticValidationError
        
        # æµ‹è¯•æ— æ•ˆçš„è¶…æ—¶å€¼ï¼ˆé€šè¿‡ç¯å¢ƒå˜é‡ï¼‰
        os.environ['HARBORAI_TIMEOUT'] = '-1'
        try:
            with pytest.raises((ValueError, ValidationError, PydanticValidationError)):
                Settings()
        finally:
            if 'HARBORAI_TIMEOUT' in os.environ:
                del os.environ['HARBORAI_TIMEOUT']
        
        # æµ‹è¯•æ— æ•ˆçš„é‡è¯•æ¬¡æ•°
        with pytest.raises((ValueError, ValidationError, PydanticValidationError)):
            Settings(max_retries=-1)


class TestPricingCalculator:
    """å®šä»·è®¡ç®—å™¨æµ‹è¯•ç±»"""
    
    @pytest.fixture
    def pricing_calculator(self):
        """åˆ›å»ºå®šä»·è®¡ç®—å™¨å®ä¾‹"""
        return PricingCalculator()
    
    @pytest.mark.unit
    @pytest.mark.p1
    def test_pricing_calculator_creation(self, pricing_calculator):
        """æµ‹è¯•å®šä»·è®¡ç®—å™¨åˆ›å»º"""
        assert pricing_calculator is not None
    
    @pytest.mark.unit
    @pytest.mark.p1
    def test_calculate_cost_basic(self, pricing_calculator):
        """æµ‹è¯•åŸºæœ¬æˆæœ¬è®¡ç®—"""
        # æ¨¡æ‹ŸåŸºæœ¬çš„æˆæœ¬è®¡ç®—
        cost = pricing_calculator.calculate_cost(
            input_tokens=1000,
            output_tokens=500,
            model_name="test-model"
        )
        assert cost is None or cost >= 0
    
    @pytest.mark.unit
    @pytest.mark.p1
    def test_calculate_cost_zero_tokens(self, pricing_calculator):
        """æµ‹è¯•é›¶tokenæˆæœ¬è®¡ç®—"""
        cost = pricing_calculator.calculate_cost(
            input_tokens=0,
            output_tokens=0,
            model_name="test-model"
        )
        assert cost is None or cost == 0
    
    @pytest.mark.unit
    @pytest.mark.p1
    def test_calculate_cost_invalid_model(self, pricing_calculator):
        """æµ‹è¯•æ— æ•ˆæ¨¡å‹æˆæœ¬è®¡ç®—"""
        # åº”è¯¥å¤„ç†æœªçŸ¥æ¨¡å‹
        cost = pricing_calculator.calculate_cost(
            input_tokens=1000,
            output_tokens=500,
            model_name="unknown-model"
        )
        # å¯èƒ½è¿”å›é»˜è®¤ä»·æ ¼æˆ–æŠ›å‡ºå¼‚å¸¸
        assert cost is None or cost >= 0


class TestTokenStatistics:
    """Tokenç»Ÿè®¡æµ‹è¯•ç±»"""
    
    @pytest.fixture
    def token_stats(self):
        """åˆ›å»ºTokenç»Ÿè®¡å®ä¾‹"""
        return TokenStatisticsCollector()
    
    @pytest.mark.unit
    @pytest.mark.p1
    def test_token_statistics_creation(self, token_stats):
        """æµ‹è¯•Tokenç»Ÿè®¡åˆ›å»º"""
        assert token_stats is not None
    
    @pytest.mark.unit
    @pytest.mark.p1
    def test_record_usage(self, token_stats):
        """æµ‹è¯•è®°å½•ä½¿ç”¨æƒ…å†µ"""
        token_stats.record_usage(
            trace_id="test-trace-123",
            model="test-model",
            input_tokens=1000,
            output_tokens=500,
            duration=1.5,
            success=True
        )
        
        # æ£€æŸ¥ç»Ÿè®¡æ•°æ®
        stats = token_stats.get_summary_stats()
        assert stats["total_tokens"] >= 1500
        assert stats["total_requests"] >= 1
        assert stats["total_cost"] >= 0
    
    @pytest.mark.unit
    @pytest.mark.p1
    def test_get_model_statistics(self, token_stats):
        """æµ‹è¯•è·å–æ¨¡å‹ç»Ÿè®¡"""
        token_stats.record_usage("trace1", "model1", 1000, 500, 1.0, True)
        token_stats.record_usage("trace2", "model2", 2000, 1000, 1.5, True)
        
        model1_stats = token_stats.get_model_statistics("model1")
        assert "model1" in model1_stats
        assert model1_stats["model1"].total_input_tokens >= 1000
        assert model1_stats["model1"].total_output_tokens >= 500
    
    @pytest.mark.unit
    @pytest.mark.p1
    def test_clear_old_records(self, token_stats):
        """æµ‹è¯•æ¸…ç†æ—§è®°å½•"""
        token_stats.record_usage("trace1", "test-model", 1000, 500, 1.0, True)
        
        # æ¸…ç†7å¤©å‰çš„è®°å½•ï¼ˆåº”è¯¥ä¸ä¼šæ¸…ç†åˆšæ·»åŠ çš„è®°å½•ï¼‰
        cleared_count = token_stats.clear_old_records(days=7)
        
        stats = token_stats.get_summary_stats()
        assert stats["total_requests"] >= 1
        assert cleared_count >= 0


class TestLogger:
    """æ—¥å¿—è®°å½•å™¨æµ‹è¯•ç±»"""
    
    @pytest.fixture
    def logger(self):
        """åˆ›å»ºæ—¥å¿—è®°å½•å™¨å®ä¾‹"""
        return get_logger("test_logger")
    
    @pytest.mark.unit
    @pytest.mark.p1
    def test_logger_creation(self, logger):
        """æµ‹è¯•æ—¥å¿—è®°å½•å™¨åˆ›å»º"""
        assert logger is not None
        assert logger.name == "test_logger"
    
    @pytest.mark.unit
    @pytest.mark.p1
    def test_log_levels(self, logger):
        """æµ‹è¯•ä¸åŒæ—¥å¿—çº§åˆ«"""
        logger.debug("è°ƒè¯•ä¿¡æ¯")
        logger.info("ä¿¡æ¯")
        logger.warning("è­¦å‘Š")
        logger.error("é”™è¯¯")
        logger.critical("ä¸¥é‡é”™è¯¯")
    
    @pytest.mark.unit
    @pytest.mark.p1
    def test_log_with_extra_data(self, logger):
        """æµ‹è¯•å¸¦é¢å¤–æ•°æ®çš„æ—¥å¿—"""
        logger.info("æµ‹è¯•æ¶ˆæ¯", extra={
            "user_id": "123",
            "request_id": "req_456"
        })
    
    @pytest.mark.unit
    @pytest.mark.p1
    def test_log_exception(self, logger):
        """æµ‹è¯•å¼‚å¸¸æ—¥å¿—"""
        try:
            raise ValueError("æµ‹è¯•å¼‚å¸¸")
        except ValueError as e:
            logger.exception("æ•è·å¼‚å¸¸", exc_info=e)


class TestRetryManager:
    """é‡è¯•ç®¡ç†å™¨æµ‹è¯•ç±»"""
    
    @pytest.fixture
    def retry_manager(self):
        """åˆ›å»ºé‡è¯•ç®¡ç†å™¨å®ä¾‹"""
        from harborai.core.retry import RetryConfig
        config = RetryConfig(max_attempts=3, base_delay=0.1)
        return RetryManager(config)
    
    @pytest.mark.unit
    @pytest.mark.p1
    def test_retry_manager_creation(self, retry_manager):
        """æµ‹è¯•é‡è¯•ç®¡ç†å™¨åˆ›å»º"""
        assert retry_manager is not None
        assert retry_manager.config.max_attempts == 3
        assert retry_manager.config.base_delay == 0.1
    
    @pytest.mark.unit
    @pytest.mark.p1
    def test_successful_operation(self, retry_manager):
        """æµ‹è¯•æˆåŠŸæ“ä½œï¼ˆæ— éœ€é‡è¯•ï¼‰"""
        def successful_operation():
            return "æˆåŠŸ"
        
        result = retry_manager.execute(successful_operation)
        assert result == "æˆåŠŸ"
    
    @pytest.mark.unit
    @pytest.mark.p1
    def test_retry_on_failure(self, retry_manager):
        """æµ‹è¯•å¤±è´¥æ—¶é‡è¯•"""
        call_count = 0
        
        def failing_operation():
            nonlocal call_count
            call_count += 1
            if call_count < 3:
                from harborai.core.exceptions import RetryableError
                raise RetryableError("ä¸´æ—¶å¤±è´¥")
            return "æœ€ç»ˆæˆåŠŸ"
        
        result = retry_manager.execute(failing_operation)
        assert result == "æœ€ç»ˆæˆåŠŸ"
        assert call_count == 3
    
    @pytest.mark.unit
    @pytest.mark.p1
    def test_max_retries_exceeded(self, retry_manager):
        """æµ‹è¯•è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°"""
        def always_failing_operation():
            from harborai.core.exceptions import RetryableError
            raise RetryableError("æ€»æ˜¯å¤±è´¥")
        
        with pytest.raises(RetryableError):
            retry_manager.execute(always_failing_operation)


class TestTracingManager:
    """è¿½è¸ªç®¡ç†å™¨æµ‹è¯•ç±»"""
    
    @pytest.fixture
    def tracing_manager(self):
        """åˆ›å»ºè¿½è¸ªç®¡ç†å™¨å®ä¾‹"""
        return TracingManager()
    
    @pytest.mark.unit
    @pytest.mark.p1
    def test_tracing_manager_creation(self, tracing_manager):
        """æµ‹è¯•è¿½è¸ªç®¡ç†å™¨åˆ›å»º"""
        assert tracing_manager is not None
    
    @pytest.mark.unit
    @pytest.mark.p1
    def test_start_trace(self, tracing_manager):
        """æµ‹è¯•å¼€å§‹è¿½è¸ª"""
        trace_id = tracing_manager.start_trace("test_operation")
        assert trace_id is not None
        assert isinstance(trace_id, str)
    
    @pytest.mark.unit
    @pytest.mark.p1
    def test_span_operations(self, tracing_manager):
        """æµ‹è¯•è·¨åº¦æ“ä½œ"""
        trace_id = tracing_manager.start_trace("test_operation")
        span_id = tracing_manager.get_active_span_id()
        assert span_id is not None
        
        # ç»“æŸè·¨åº¦
        tracing_manager.finish_span(span_id, status="ok")
    
    @pytest.mark.unit
    @pytest.mark.p1
    def test_nested_spans(self, tracing_manager):
        """æµ‹è¯•åµŒå¥—è·¨åº¦"""
        trace_id = tracing_manager.start_trace("parent_operation")
        parent_span_id = tracing_manager.get_active_span_id()
        
        child_span_id = tracing_manager.start_span("child_operation", parent_span_id=parent_span_id)
        assert child_span_id is not None
        
        tracing_manager.finish_span(child_span_id, status="ok")
        tracing_manager.finish_span(parent_span_id, status="ok")


class TestBoundaryConditions:
    """è¾¹ç•Œæ¡ä»¶æµ‹è¯•ç±»"""
    
    @pytest.mark.unit
    @pytest.mark.p2
    def test_empty_string_handling(self):
        """æµ‹è¯•ç©ºå­—ç¬¦ä¸²å¤„ç†"""
        # æµ‹è¯•å„ç§ç»„ä»¶å¯¹ç©ºå­—ç¬¦ä¸²çš„å¤„ç†
        harborai = HarborAI()
        
        # ç©ºæ¶ˆæ¯åº”è¯¥è¢«é€‚å½“å¤„ç†
        with pytest.raises((ValueError, ValidationError, ModelNotFoundError)):
            harborai.chat.completions.create(
                model="test-model",
                messages=[{"role": "user", "content": ""}]
            )
    
    @pytest.mark.unit
    @pytest.mark.p2
    def test_very_long_input(self):
        """æµ‹è¯•è¶…é•¿è¾“å…¥å¤„ç†"""
        harborai = HarborAI()
        
        # åˆ›å»ºä¸€ä¸ªå¾ˆé•¿çš„è¾“å…¥
        long_content = "æµ‹è¯•" * 10000
        
        # åº”è¯¥æœ‰é€‚å½“çš„é•¿åº¦é™åˆ¶æˆ–å¤„ç†
        try:
            result = harborai.chat.completions.create(
                model="test-model",
                messages=[{"role": "user", "content": long_content}]
            )
        except (ValueError, ValidationError, ModelNotFoundError) as e:
            # é¢„æœŸçš„éªŒè¯é”™è¯¯æˆ–æ¨¡å‹æœªæ‰¾åˆ°é”™è¯¯
            assert "é•¿åº¦" in str(e) or "length" in str(e).lower() or "not found" in str(e).lower()
    
    @pytest.mark.unit
    @pytest.mark.p2
    def test_special_characters_handling(self):
        """æµ‹è¯•ç‰¹æ®Šå­—ç¬¦å¤„ç†"""
        harborai = HarborAI()
        
        special_chars = "!@#$%^&*()_+-=[]{}|;':\",./<>?`~"
        unicode_chars = "ä½ å¥½ä¸–ç•ŒğŸŒğŸš€ğŸ’»"
        
        # åº”è¯¥èƒ½å¤„ç†ç‰¹æ®Šå­—ç¬¦å’ŒUnicode
        try:
            harborai.chat.completions.create(
                model="test-model",
                messages=[{"role": "user", "content": special_chars + unicode_chars}]
            )
        except Exception as e:
            # å¦‚æœæŠ›å‡ºå¼‚å¸¸ï¼Œåº”è¯¥æ˜¯åˆç†çš„éªŒè¯é”™è¯¯
            pass
    
    @pytest.mark.unit
    @pytest.mark.p2
    def test_null_and_none_handling(self):
        """æµ‹è¯•NULLå’ŒNoneå€¼å¤„ç†"""
        harborai = HarborAI()
        
        # Noneå€¼åº”è¯¥è¢«é€‚å½“å¤„ç†
        with pytest.raises((ValueError, TypeError, ValidationError, ModelNotFoundError)):
            harborai.chat.completions.create(
                model="test-model",
                messages=None
            )
        
        with pytest.raises((ValueError, TypeError, ValidationError, ModelNotFoundError)):
            harborai.chat.completions.create(
                model=None,
                messages=[{"role": "user", "content": "æµ‹è¯•"}]
            )


class TestErrorRecovery:
    """é”™è¯¯æ¢å¤æµ‹è¯•ç±»"""
    
    @pytest.mark.unit
    @pytest.mark.p2
    def test_network_error_recovery(self):
        """æµ‹è¯•ç½‘ç»œé”™è¯¯æ¢å¤"""
        harborai = HarborAI()
        
        # æ¨¡æ‹Ÿç½‘ç»œé”™è¯¯
        with patch('requests.post') as mock_post:
            mock_post.side_effect = ConnectionError("ç½‘ç»œè¿æ¥å¤±è´¥")
            
            with pytest.raises((ConnectionError, APIError, ModelNotFoundError)):
                harborai.chat.completions.create(
                    model="test-model",
                    messages=[{"role": "user", "content": "æµ‹è¯•"}]
                )
    
    @pytest.mark.unit
    @pytest.mark.p2
    def test_timeout_handling(self):
        """æµ‹è¯•è¶…æ—¶å¤„ç†"""
        harborai = HarborAI()
        
        # æ¨¡æ‹Ÿè¶…æ—¶
        with patch('requests.post') as mock_post:
            mock_post.side_effect = TimeoutError("è¯·æ±‚è¶…æ—¶")
            
            with pytest.raises((TimeoutError, APIError, ModelNotFoundError)):
                harborai.chat.completions.create(
                    model="test-model",
                    messages=[{"role": "user", "content": "æµ‹è¯•"}]
                )
    
    @pytest.mark.unit
    @pytest.mark.p2
    def test_rate_limit_handling(self):
        """æµ‹è¯•é€Ÿç‡é™åˆ¶å¤„ç†"""
        harborai = HarborAI()
        
        # æ¨¡æ‹Ÿé€Ÿç‡é™åˆ¶
        with patch('requests.post') as mock_post:
            mock_response = Mock()
            mock_response.status_code = 429
            mock_response.json.return_value = {"error": "Rate limit exceeded"}
            mock_post.return_value = mock_response
            
            with pytest.raises((RateLimitError, ModelNotFoundError)):
                harborai.chat.completions.create(
                    model="test-model",
                    messages=[{"role": "user", "content": "æµ‹è¯•"}]
                )


class TestPerformanceEdgeCases:
    """æ€§èƒ½è¾¹ç•Œæƒ…å†µæµ‹è¯•ç±»"""
    
    @pytest.mark.performance
    @pytest.mark.p3
    def test_concurrent_requests(self):
        """æµ‹è¯•å¹¶å‘è¯·æ±‚å¤„ç†"""
        harborai = HarborAI()
        
        # ä½¿ç”¨åŒæ­¥æ–¹æ³•è¿›è¡Œå¹¶å‘æµ‹è¯•
        import threading
        import time
        
        results = []
        errors = []
        
        def make_request():
            try:
                # æ¨¡æ‹Ÿè¯·æ±‚ï¼Œé¢„æœŸä¼šæŠ›å‡ºModelNotFoundError
                harborai.chat.completions.create(
                    model="test-model",
                    messages=[{"role": "user", "content": "æµ‹è¯•"}]
                )
            except (ModelNotFoundError, Exception) as e:
                errors.append(e)
        
        # åˆ›å»ºå¤šä¸ªçº¿ç¨‹è¿›è¡Œå¹¶å‘æµ‹è¯•
        threads = []
        for _ in range(5):  # å‡å°‘çº¿ç¨‹æ•°é‡ä»¥é¿å…è¿‡åº¦è´Ÿè½½
            thread = threading.Thread(target=make_request)
            threads.append(thread)
        
        # å¯åŠ¨æ‰€æœ‰çº¿ç¨‹
        start_time = time.time()
        for thread in threads:
            thread.start()
        
        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for thread in threads:
            thread.join()
        
        end_time = time.time()
        
        # éªŒè¯å¹¶å‘å¤„ç†
        assert len(errors) == 5  # æ‰€æœ‰è¯·æ±‚éƒ½åº”è¯¥äº§ç”Ÿé”™è¯¯ï¼ˆå› ä¸ºä½¿ç”¨test-modelï¼‰
        assert end_time - start_time < 5  # å¹¶å‘å¤„ç†åº”è¯¥åœ¨åˆç†æ—¶é—´å†…å®Œæˆ
    
    @pytest.mark.performance
    @pytest.mark.p3
    def test_memory_usage_monitoring(self):
        """æµ‹è¯•å†…å­˜ä½¿ç”¨ç›‘æ§"""
        import psutil
        import gc
        
        try:
            process = psutil.Process()
            initial_memory = process.memory_info().rss
            
            # åˆ›å»ºå°‘é‡å¯¹è±¡è¿›è¡Œæµ‹è¯•
            harborai_instances = []
            for i in range(10):  # å‡å°‘å®ä¾‹æ•°é‡
                harborai_instances.append(HarborAI())
            
            # æ£€æŸ¥å†…å­˜å¢é•¿
            current_memory = process.memory_info().rss
            memory_growth = current_memory - initial_memory
            
            # æ¸…ç†
            del harborai_instances
            gc.collect()
            
            # æ£€æŸ¥å†…å­˜æ˜¯å¦é‡Šæ”¾
            final_memory = process.memory_info().rss
            
            # å†…å­˜å¢é•¿åº”è¯¥åœ¨åˆç†èŒƒå›´å†…ï¼ˆæ›´å®½æ¾çš„é™åˆ¶ï¼‰
            assert memory_growth < 500 * 1024 * 1024  # 500MB
            
            # è®°å½•å†…å­˜ä½¿ç”¨æƒ…å†µï¼ˆä¸å¼ºåˆ¶è¦æ±‚é‡Šæ”¾ï¼Œå› ä¸ºPythonçš„GCè¡Œä¸ºå¯èƒ½ä¸å¯é¢„æµ‹ï¼‰
            print(f"åˆå§‹å†…å­˜: {initial_memory / 1024 / 1024:.2f}MB")
            print(f"å½“å‰å†…å­˜: {current_memory / 1024 / 1024:.2f}MB")
            print(f"æœ€ç»ˆå†…å­˜: {final_memory / 1024 / 1024:.2f}MB")
            print(f"å†…å­˜å¢é•¿: {memory_growth / 1024 / 1024:.2f}MB")
            
        except Exception as e:
            # å¦‚æœå†…å­˜ç›‘æ§å¤±è´¥ï¼Œè·³è¿‡æµ‹è¯•è€Œä¸æ˜¯å¤±è´¥
            pytest.skip(f"å†…å­˜ç›‘æ§æµ‹è¯•è·³è¿‡: {e}")


if __name__ == "__main__":
    pytest.main([__file__, "-v", "--tb=short"])