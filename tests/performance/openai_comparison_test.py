#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HarborAI SDK vs OpenAI SDK æ€§èƒ½å¯¹æ¯”æµ‹è¯•

å¯¹æ¯”HarborAI SDKå’ŒOpenAI SDKåœ¨ç›¸åŒæ¡ä»¶ä¸‹çš„æ€§èƒ½è¡¨ç°
"""

import asyncio
import time
import statistics
import psutil
import gc
import sys
import os
from typing import Dict, List, Any, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
from dataclasses import dataclass
from datetime import datetime
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..'))

try:
    from harborai import HarborAI
    from harborai.config.performance import PerformanceMode
    from harborai.utils.exceptions import HarborAIError
except ImportError as e:
    print(f"âŒ å¯¼å…¥HarborAIå¤±è´¥: {e}")
    HarborAI = None

try:
    import openai
    from openai import OpenAI
except ImportError as e:
    print(f"âŒ å¯¼å…¥OpenAIå¤±è´¥: {e}")
    OpenAI = None

@dataclass
class ComparisonMetrics:
    """å¯¹æ¯”æŒ‡æ ‡æ•°æ®ç±»"""
    sdk_name: str
    initialization_time_ms: float
    method_call_overhead_us: float
    memory_usage_mb: float
    concurrent_throughput_ops_per_sec: float
    success_rate_percent: float
    error_count: int

class SDKComparator:
    """SDKå¯¹æ¯”æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.process = psutil.Process()
        self.test_api_key = "test-key-for-comparison"
        
    def create_mock_harborai_client(self) -> Optional[HarborAI]:
        """åˆ›å»ºæ¨¡æ‹ŸHarborAIå®¢æˆ·ç«¯"""
        if HarborAI is None:
            return None
        
        try:
            return HarborAI(
                api_key=self.test_api_key,
                performance_mode=PerformanceMode.FAST,
                enable_cache=True,
                enable_fallback=False,
                enable_cost_tracking=False
            )
        except Exception as e:
            print(f"âŒ åˆ›å»ºHarborAIå®¢æˆ·ç«¯å¤±è´¥: {e}")
            return None
    
    def create_mock_openai_client(self) -> Optional[OpenAI]:
        """åˆ›å»ºæ¨¡æ‹ŸOpenAIå®¢æˆ·ç«¯"""
        if OpenAI is None:
            return None
        
        try:
            return OpenAI(
                api_key=self.test_api_key,
                timeout=30.0
            )
        except Exception as e:
            print(f"âŒ åˆ›å»ºOpenAIå®¢æˆ·ç«¯å¤±è´¥: {e}")
            return None
    
    def measure_initialization_time(self, sdk_name: str, create_func) -> float:
        """æµ‹é‡åˆå§‹åŒ–æ—¶é—´"""
        times = []
        
        for _ in range(10):
            gc.collect()
            start_time = time.perf_counter()
            
            try:
                client = create_func()
                end_time = time.perf_counter()
                
                if client:
                    times.append((end_time - start_time) * 1000)  # è½¬æ¢ä¸ºæ¯«ç§’
                    del client
            except Exception:
                pass
            
            gc.collect()
        
        return statistics.mean(times) if times else 0
    
    def measure_method_call_overhead(self, sdk_name: str, client) -> float:
        """æµ‹é‡æ–¹æ³•è°ƒç”¨å¼€é”€"""
        if client is None:
            return 0
        
        times = []
        
        for _ in range(100):
            try:
                start_time = time.perf_counter()
                
                # æ¨¡æ‹Ÿæ–¹æ³•è°ƒç”¨ï¼ˆä¸å®é™…å‘é€è¯·æ±‚ï¼‰
                if sdk_name == "HarborAI":
                    self._mock_harborai_call(client)
                elif sdk_name == "OpenAI":
                    self._mock_openai_call(client)
                
                end_time = time.perf_counter()
                times.append((end_time - start_time) * 1000000)  # è½¬æ¢ä¸ºå¾®ç§’
                
            except Exception:
                pass
        
        return statistics.mean(times) if times else 0
    
    def _mock_harborai_call(self, client):
        """æ¨¡æ‹ŸHarborAIè°ƒç”¨"""
        try:
            # åªæµ‹è¯•å‚æ•°å¤„ç†ï¼Œä¸å®é™…å‘é€è¯·æ±‚
            messages = [{"role": "user", "content": "Hello"}]
            params = {
                "model": "gpt-3.5-turbo",
                "messages": messages,
                "temperature": 0.7,
                "max_tokens": 100
            }
            
            # æ¨¡æ‹Ÿå‚æ•°éªŒè¯
            if hasattr(client.chat.completions, '_validate_parameters'):
                client.chat.completions._validate_parameters(params)
        except Exception:
            pass
    
    def _mock_openai_call(self, client):
        """æ¨¡æ‹ŸOpenAIè°ƒç”¨"""
        try:
            # åªæµ‹è¯•å‚æ•°å¤„ç†ï¼Œä¸å®é™…å‘é€è¯·æ±‚
            messages = [{"role": "user", "content": "Hello"}]
            
            # æ¨¡æ‹Ÿå‚æ•°æ„å»ºï¼ˆOpenAI SDKçš„å†…éƒ¨å¤„ç†ï¼‰
            params = {
                "model": "gpt-3.5-turbo",
                "messages": messages,
                "temperature": 0.7,
                "max_tokens": 100
            }
            
            # è¿™é‡Œåªæ˜¯æ„å»ºå‚æ•°ï¼Œä¸å®é™…è°ƒç”¨API
            # å› ä¸ºæˆ‘ä»¬æ²¡æœ‰çœŸå®çš„APIå¯†é’¥
            
        except Exception:
            pass
    
    def measure_memory_usage(self, sdk_name: str, create_func) -> float:
        """æµ‹é‡å†…å­˜ä½¿ç”¨"""
        gc.collect()
        baseline_memory = self.process.memory_info().rss / 1024 / 1024
        
        clients = []
        try:
            # åˆ›å»ºå¤šä¸ªå®¢æˆ·ç«¯å®ä¾‹
            for _ in range(10):
                client = create_func()
                if client:
                    clients.append(client)
            
            peak_memory = self.process.memory_info().rss / 1024 / 1024
            memory_overhead = peak_memory - baseline_memory
            
        except Exception:
            memory_overhead = 0
        finally:
            # æ¸…ç†
            for client in clients:
                del client
            clients.clear()
            gc.collect()
        
        return memory_overhead
    
    def measure_concurrent_performance(self, sdk_name: str, create_func) -> Dict[str, float]:
        """æµ‹é‡å¹¶å‘æ€§èƒ½"""
        def worker_task(worker_id: int, num_operations: int) -> Dict[str, Any]:
            """å·¥ä½œçº¿ç¨‹ä»»åŠ¡"""
            client = create_func()
            if not client:
                return {'success': 0, 'errors': num_operations, 'times': []}
            
            times = []
            errors = 0
            
            for _ in range(num_operations):
                try:
                    start_time = time.perf_counter()
                    
                    if sdk_name == "HarborAI":
                        self._mock_harborai_call(client)
                    elif sdk_name == "OpenAI":
                        self._mock_openai_call(client)
                    
                    end_time = time.perf_counter()
                    times.append((end_time - start_time) * 1000)
                except Exception:
                    errors += 1
            
            return {
                'success': num_operations - errors,
                'errors': errors,
                'times': times
            }
        
        # æµ‹è¯•å¹¶å‘æ€§èƒ½
        concurrency = 10
        operations_per_worker = 50
        
        start_time = time.perf_counter()
        
        with ThreadPoolExecutor(max_workers=concurrency) as executor:
            futures = [
                executor.submit(worker_task, i, operations_per_worker)
                for i in range(concurrency)
            ]
            
            worker_results = []
            for future in as_completed(futures):
                try:
                    result = future.result()
                    worker_results.append(result)
                except Exception:
                    pass
        
        end_time = time.perf_counter()
        
        # æ±‡æ€»ç»“æœ
        total_success = sum(r['success'] for r in worker_results)
        total_errors = sum(r['errors'] for r in worker_results)
        total_operations = concurrency * operations_per_worker
        
        return {
            'throughput_ops_per_sec': total_success / (end_time - start_time) if (end_time - start_time) > 0 else 0,
            'success_rate': (total_success / total_operations * 100) if total_operations > 0 else 0,
            'error_count': total_errors
        }
    
    def run_comparison_test(self) -> Dict[str, ComparisonMetrics]:
        """è¿è¡Œå¯¹æ¯”æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹HarborAI vs OpenAI SDKæ€§èƒ½å¯¹æ¯”æµ‹è¯•")
        print("=" * 60)
        
        results = {}
        
        # æµ‹è¯•HarborAI SDK
        if HarborAI is not None:
            print("ğŸ“Š æµ‹è¯•HarborAI SDK...")
            
            init_time = self.measure_initialization_time("HarborAI", self.create_mock_harborai_client)
            
            harborai_client = self.create_mock_harborai_client()
            call_overhead = self.measure_method_call_overhead("HarborAI", harborai_client)
            
            memory_usage = self.measure_memory_usage("HarborAI", self.create_mock_harborai_client)
            
            concurrent_metrics = self.measure_concurrent_performance("HarborAI", self.create_mock_harborai_client)
            
            results["HarborAI"] = ComparisonMetrics(
                sdk_name="HarborAI",
                initialization_time_ms=init_time,
                method_call_overhead_us=call_overhead,
                memory_usage_mb=memory_usage,
                concurrent_throughput_ops_per_sec=concurrent_metrics['throughput_ops_per_sec'],
                success_rate_percent=concurrent_metrics['success_rate'],
                error_count=concurrent_metrics['error_count']
            )
            
            print(f"  âœ… HarborAIæµ‹è¯•å®Œæˆ")
        else:
            print("  âŒ HarborAI SDKä¸å¯ç”¨")
        
        # æµ‹è¯•OpenAI SDK
        if OpenAI is not None:
            print("ğŸ“Š æµ‹è¯•OpenAI SDK...")
            
            init_time = self.measure_initialization_time("OpenAI", self.create_mock_openai_client)
            
            openai_client = self.create_mock_openai_client()
            call_overhead = self.measure_method_call_overhead("OpenAI", openai_client)
            
            memory_usage = self.measure_memory_usage("OpenAI", self.create_mock_openai_client)
            
            concurrent_metrics = self.measure_concurrent_performance("OpenAI", self.create_mock_openai_client)
            
            results["OpenAI"] = ComparisonMetrics(
                sdk_name="OpenAI",
                initialization_time_ms=init_time,
                method_call_overhead_us=call_overhead,
                memory_usage_mb=memory_usage,
                concurrent_throughput_ops_per_sec=concurrent_metrics['throughput_ops_per_sec'],
                success_rate_percent=concurrent_metrics['success_rate'],
                error_count=concurrent_metrics['error_count']
            )
            
            print(f"  âœ… OpenAIæµ‹è¯•å®Œæˆ")
        else:
            print("  âŒ OpenAI SDKä¸å¯ç”¨")
        
        return results
    
    def generate_comparison_report(self, results: Dict[str, ComparisonMetrics]) -> str:
        """ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š"""
        report = []
        
        report.append("# HarborAI vs OpenAI SDK æ€§èƒ½å¯¹æ¯”æŠ¥å‘Š")
        report.append("=" * 60)
        report.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")
        
        if len(results) < 2:
            report.append("âš ï¸ æ— æ³•è¿›è¡Œå®Œæ•´å¯¹æ¯”ï¼Œç¼ºå°‘SDKå®ä¾‹")
            return "\n".join(report)
        
        harborai_metrics = results.get("HarborAI")
        openai_metrics = results.get("OpenAI")
        
        if not harborai_metrics or not openai_metrics:
            report.append("âš ï¸ æ— æ³•è¿›è¡Œå®Œæ•´å¯¹æ¯”ï¼Œç¼ºå°‘æµ‹è¯•æ•°æ®")
            return "\n".join(report)
        
        # æ€§èƒ½å¯¹æ¯”è¡¨æ ¼
        report.append("## æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”")
        report.append("")
        report.append("| æŒ‡æ ‡ | HarborAI | OpenAI | ä¼˜åŠ¿ |")
        report.append("|------|----------|--------|------|")
        
        # åˆå§‹åŒ–æ—¶é—´
        harbor_init = harborai_metrics.initialization_time_ms
        openai_init = openai_metrics.initialization_time_ms
        init_winner = "HarborAI" if harbor_init < openai_init else "OpenAI"
        init_improvement = abs(harbor_init - openai_init) / max(harbor_init, openai_init) * 100
        
        report.append(f"| åˆå§‹åŒ–æ—¶é—´ | {harbor_init:.2f}ms | {openai_init:.2f}ms | {init_winner} ({init_improvement:.1f}%æ›´å¿«) |")
        
        # æ–¹æ³•è°ƒç”¨å¼€é”€
        harbor_call = harborai_metrics.method_call_overhead_us
        openai_call = openai_metrics.method_call_overhead_us
        call_winner = "HarborAI" if harbor_call < openai_call else "OpenAI"
        call_improvement = abs(harbor_call - openai_call) / max(harbor_call, openai_call) * 100
        
        report.append(f"| æ–¹æ³•è°ƒç”¨å¼€é”€ | {harbor_call:.2f}Î¼s | {openai_call:.2f}Î¼s | {call_winner} ({call_improvement:.1f}%æ›´å¿«) |")
        
        # å†…å­˜ä½¿ç”¨
        harbor_mem = harborai_metrics.memory_usage_mb
        openai_mem = openai_metrics.memory_usage_mb
        mem_winner = "HarborAI" if harbor_mem < openai_mem else "OpenAI"
        mem_improvement = abs(harbor_mem - openai_mem) / max(harbor_mem, openai_mem) * 100
        
        report.append(f"| å†…å­˜ä½¿ç”¨ | {harbor_mem:.2f}MB | {openai_mem:.2f}MB | {mem_winner} ({mem_improvement:.1f}%æ›´å°‘) |")
        
        # å¹¶å‘ååé‡
        harbor_throughput = harborai_metrics.concurrent_throughput_ops_per_sec
        openai_throughput = openai_metrics.concurrent_throughput_ops_per_sec
        throughput_winner = "HarborAI" if harbor_throughput > openai_throughput else "OpenAI"
        throughput_improvement = abs(harbor_throughput - openai_throughput) / max(harbor_throughput, openai_throughput) * 100
        
        report.append(f"| å¹¶å‘ååé‡ | {harbor_throughput:.1f}ops/s | {openai_throughput:.1f}ops/s | {throughput_winner} ({throughput_improvement:.1f}%æ›´é«˜) |")
        
        # æˆåŠŸç‡
        harbor_success = harborai_metrics.success_rate_percent
        openai_success = openai_metrics.success_rate_percent
        success_winner = "HarborAI" if harbor_success > openai_success else "OpenAI"
        
        report.append(f"| æˆåŠŸç‡ | {harbor_success:.1f}% | {openai_success:.1f}% | {success_winner} |")
        
        report.append("")
        
        # ç»¼åˆè¯„åˆ†
        report.append("## ç»¼åˆè¯„åˆ†")
        
        # è®¡ç®—å„é¡¹å¾—åˆ†ï¼ˆ0-100åˆ†ï¼‰
        harbor_scores = {
            'initialization': 100 if harbor_init <= openai_init else max(0, 100 - (harbor_init - openai_init) / openai_init * 100),
            'call_overhead': 100 if harbor_call <= openai_call else max(0, 100 - (harbor_call - openai_call) / openai_call * 100),
            'memory': 100 if harbor_mem <= openai_mem else max(0, 100 - (harbor_mem - openai_mem) / openai_mem * 100),
            'throughput': 100 if harbor_throughput >= openai_throughput else max(0, harbor_throughput / openai_throughput * 100),
            'success_rate': harbor_success
        }
        
        openai_scores = {
            'initialization': 100 if openai_init <= harbor_init else max(0, 100 - (openai_init - harbor_init) / harbor_init * 100),
            'call_overhead': 100 if openai_call <= harbor_call else max(0, 100 - (openai_call - harbor_call) / harbor_call * 100),
            'memory': 100 if openai_mem <= harbor_mem else max(0, 100 - (openai_mem - harbor_mem) / harbor_mem * 100),
            'throughput': 100 if openai_throughput >= harbor_throughput else max(0, openai_throughput / harbor_throughput * 100),
            'success_rate': openai_success
        }
        
        harbor_total = sum(harbor_scores.values()) / len(harbor_scores)
        openai_total = sum(openai_scores.values()) / len(openai_scores)
        
        report.append(f"- **HarborAI ç»¼åˆå¾—åˆ†**: {harbor_total:.1f}/100")
        report.append(f"- **OpenAI ç»¼åˆå¾—åˆ†**: {openai_total:.1f}/100")
        report.append("")
        
        # ä¼˜åŠ¿åˆ†æ
        report.append("## ä¼˜åŠ¿åˆ†æ")
        
        if harbor_total > openai_total:
            report.append("### ğŸ† HarborAI æ•´ä½“è¡¨ç°æ›´ä¼˜")
            report.append("**HarborAIçš„ä¼˜åŠ¿ï¼š**")
            if harbor_init < openai_init:
                report.append(f"- åˆå§‹åŒ–é€Ÿåº¦æ›´å¿« ({init_improvement:.1f}%)")
            if harbor_call < openai_call:
                report.append(f"- æ–¹æ³•è°ƒç”¨å¼€é”€æ›´ä½ ({call_improvement:.1f}%)")
            if harbor_mem < openai_mem:
                report.append(f"- å†…å­˜ä½¿ç”¨æ›´å°‘ ({mem_improvement:.1f}%)")
            if harbor_throughput > openai_throughput:
                report.append(f"- å¹¶å‘å¤„ç†èƒ½åŠ›æ›´å¼º ({throughput_improvement:.1f}%)")
        else:
            report.append("### ğŸ† OpenAI æ•´ä½“è¡¨ç°æ›´ä¼˜")
            report.append("**OpenAIçš„ä¼˜åŠ¿ï¼š**")
            if openai_init < harbor_init:
                report.append(f"- åˆå§‹åŒ–é€Ÿåº¦æ›´å¿« ({init_improvement:.1f}%)")
            if openai_call < harbor_call:
                report.append(f"- æ–¹æ³•è°ƒç”¨å¼€é”€æ›´ä½ ({call_improvement:.1f}%)")
            if openai_mem < harbor_mem:
                report.append(f"- å†…å­˜ä½¿ç”¨æ›´å°‘ ({mem_improvement:.1f}%)")
            if openai_throughput > harbor_throughput:
                report.append(f"- å¹¶å‘å¤„ç†èƒ½åŠ›æ›´å¼º ({throughput_improvement:.1f}%)")
        
        report.append("")
        
        # ç»“è®º
        report.append("## ç»“è®º")
        if harbor_total > openai_total:
            report.append("HarborAI SDKåœ¨æ€§èƒ½æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œåœ¨å¤šä¸ªå…³é”®æŒ‡æ ‡ä¸Šè¶…è¶Šäº†OpenAI SDKã€‚")
            report.append("è¿™è¯æ˜äº†HarborAIçš„æ¶æ„ä¼˜åŒ–å’Œæ€§èƒ½è°ƒä¼˜æ˜¯æœ‰æ•ˆçš„ã€‚")
        else:
            report.append("OpenAI SDKåœ¨æ€§èƒ½æµ‹è¯•ä¸­è¡¨ç°æ›´å¥½ï¼ŒHarborAIä»æœ‰ä¼˜åŒ–ç©ºé—´ã€‚")
            report.append("å»ºè®®é‡ç‚¹å…³æ³¨æ€§èƒ½ç“¶é¢ˆçš„ä¼˜åŒ–ã€‚")
        
        return "\n".join(report)
    
    def print_summary(self, results: Dict[str, ComparisonMetrics]):
        """æ‰“å°å¯¹æ¯”æ‘˜è¦"""
        print("\n" + "=" * 60)
        print("ğŸ“Š HarborAI vs OpenAI SDK æ€§èƒ½å¯¹æ¯”æ‘˜è¦")
        print("=" * 60)
        
        for sdk_name, metrics in results.items():
            print(f"\nğŸ”§ {sdk_name} SDK:")
            print(f"  åˆå§‹åŒ–æ—¶é—´: {metrics.initialization_time_ms:.2f}ms")
            print(f"  æ–¹æ³•è°ƒç”¨å¼€é”€: {metrics.method_call_overhead_us:.2f}Î¼s")
            print(f"  å†…å­˜ä½¿ç”¨: {metrics.memory_usage_mb:.2f}MB")
            print(f"  å¹¶å‘ååé‡: {metrics.concurrent_throughput_ops_per_sec:.1f}ops/s")
            print(f"  æˆåŠŸç‡: {metrics.success_rate_percent:.1f}%")
        
        print("\n" + "=" * 60)

def main():
    """ä¸»å‡½æ•°"""
    comparator = SDKComparator()
    
    try:
        results = comparator.run_comparison_test()
        
        if not results:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„SDKè¿›è¡Œæµ‹è¯•")
            return 1
        
        comparator.print_summary(results)
        
        # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        report = comparator.generate_comparison_report(results)
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = "harborai_vs_openai_comparison_report.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        # ä¿å­˜JSONæ•°æ®
        json_data = {
            sdk_name: {
                'initialization_time_ms': metrics.initialization_time_ms,
                'method_call_overhead_us': metrics.method_call_overhead_us,
                'memory_usage_mb': metrics.memory_usage_mb,
                'concurrent_throughput_ops_per_sec': metrics.concurrent_throughput_ops_per_sec,
                'success_rate_percent': metrics.success_rate_percent,
                'error_count': metrics.error_count
            }
            for sdk_name, metrics in results.items()
        }
        
        json_file = "sdk_comparison_results.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        print(f"ğŸ“„ JSONæ•°æ®å·²ä¿å­˜åˆ°: {json_file}")
        
        return 0
        
    except Exception as e:
        print(f"âŒ å¯¹æ¯”æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    exit(main())