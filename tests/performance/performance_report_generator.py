#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HarborAI SDK æ€§èƒ½æŠ¥å‘Šç”Ÿæˆå™¨

åŸºäºæ€§èƒ½æµ‹è¯•ç»“æœç”Ÿæˆè¯¦ç»†çš„è¯„ä¼°æŠ¥å‘Šï¼ŒåŒ…æ‹¬ï¼š
1. æ€§èƒ½æ•°æ®å¯è§†åŒ–
2. ç“¶é¢ˆåˆ†æ
3. ä¼˜åŒ–å»ºè®®
4. ROIåˆ†æ
5. ä¸è®¾è®¡ç›®æ ‡å¯¹æ¯”
"""

import json
import os
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
import logging

# å¯¼å…¥ç»Ÿä¸€æŠ¥å‘Šç®¡ç†å™¨
sys.path.append(str(Path(__file__).parent.parent))
from utils.unified_report_manager import get_performance_report_path

# å°è¯•å¯¼å…¥å¯è§†åŒ–åº“
try:
    import matplotlib.pyplot as plt
    import seaborn as sns
    import pandas as pd
    import numpy as np
    VISUALIZATION_AVAILABLE = True
except ImportError:
    VISUALIZATION_AVAILABLE = False
    print("è­¦å‘Š: å¯è§†åŒ–åº“æœªå®‰è£…ï¼Œå°†è·³è¿‡å›¾è¡¨ç”Ÿæˆ")

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# æ£€æŸ¥matplotlibå¯ç”¨æ€§
MATPLOTLIB_AVAILABLE = VISUALIZATION_AVAILABLE


@dataclass
class ReportMetadata:
    """æŠ¥å‘Šå…ƒæ•°æ®"""
    title: str
    description: str
    generated_at: datetime
    test_duration: timedelta
    test_environment: Dict[str, Any]
    version: str
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            'title': self.title,
            'description': self.description,
            'generated_at': self.generated_at.isoformat(),
            'test_duration': str(self.test_duration),
            'test_environment': self.test_environment,
            'version': self.version
        }


@dataclass
class PerformanceSummary:
    """æ€§èƒ½æµ‹è¯•æ‘˜è¦"""
    total_tests: int
    passed_tests: int
    failed_tests: int
    success_rate: float
    average_response_time: float
    peak_memory_usage: int
    peak_cpu_usage: float
    total_requests: int
    requests_per_second: float
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            'total_tests': self.total_tests,
            'passed_tests': self.passed_tests,
            'failed_tests': self.failed_tests,
            'success_rate': self.success_rate,
            'average_response_time': self.average_response_time,
            'peak_memory_usage': self.peak_memory_usage,
            'peak_cpu_usage': self.peak_cpu_usage,
            'total_requests': self.total_requests,
            'requests_per_second': self.requests_per_second
        }


@dataclass
class ChartData:
    """å›¾è¡¨æ•°æ®"""
    chart_type: str
    title: str
    data: Dict[str, Any]
    options: Dict[str, Any] = None
    
    def __post_init__(self):
        """åˆå§‹åŒ–åå¤„ç†"""
        if self.options is None:
            self.options = {}
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            'chart_type': self.chart_type,
            'title': self.title,
            'data': self.data,
            'options': self.options
        }


class PerformanceReportGenerator:
    """æ€§èƒ½æŠ¥å‘Šç”Ÿæˆå™¨
    
    åŸºäºæ€§èƒ½æµ‹è¯•ç»“æœç”Ÿæˆç»¼åˆæ€§èƒ½è¯„ä¼°æŠ¥å‘Š
    """
    
    def __init__(self, output_dir: str = "reports", results_file: str = None):
        """åˆå§‹åŒ–æŠ¥å‘Šç”Ÿæˆå™¨
        
        Args:
            output_dir: è¾“å‡ºç›®å½•è·¯å¾„
            results_file: æ€§èƒ½æµ‹è¯•ç»“æœæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        if results_file:
            self.results_file = Path(results_file)
            self.results = {}
            # ä½¿ç”¨ç»Ÿä¸€æŠ¥å‘Šç®¡ç†å™¨è·å–æ€§èƒ½æŠ¥å‘Šç›®å½•
            self.report_dir = get_performance_report_path("metrics").parent
            self.report_dir.mkdir(parents=True, exist_ok=True)
        else:
            self.results_file = None
            self.results = {}
            self.report_dir = self.output_dir
            
        self.charts = []
        self.metadata = None
        self.summary = None
        self.detailed_data = {}
        self.html_template = self._get_default_html_template()
        
        # è®¾è®¡ç›®æ ‡ï¼ˆæ¥è‡ªPRD/TDï¼‰
        self.design_targets = {
            "call_overhead_ms": 1.0,  # < 1ms
            "concurrent_success_rate": 0.999,  # > 99.9%
            "max_response_time_s": 5.0,  # < 5s
            "max_memory_usage_mb": 1000,  # < 1GB
            "max_cpu_usage_percent": 80,  # < 80%
            "async_logging_blocking": False,  # éé˜»å¡
            "plugin_switching_overhead_ms": 1.0  # < 1ms
        }
        
        # åŠ è½½æµ‹è¯•ç»“æœï¼ˆå¦‚æœæä¾›äº†ç»“æœæ–‡ä»¶ï¼‰
        if self.results_file:
            self._load_results()
    
    def add_chart(self, chart: ChartData):
        """æ·»åŠ å›¾è¡¨"""
        self.charts.append(chart)
        
    def set_metadata(self, metadata: ReportMetadata):
        """è®¾ç½®å…ƒæ•°æ®"""
        self.metadata = metadata
        
    def set_summary(self, summary: PerformanceSummary):
        """è®¾ç½®æ‘˜è¦"""
        self.summary = summary
        
    def set_detailed_data(self, data: Dict[str, Any]):
        """è®¾ç½®è¯¦ç»†æ•°æ®"""
        self.detailed_data = data
        
    def _get_default_html_template(self) -> str:
        """è·å–é»˜è®¤HTMLæ¨¡æ¿"""
        return """
        <!DOCTYPE html>
        <html>
        <head>
            <title>æ€§èƒ½æµ‹è¯•æŠ¥å‘Š</title>
            <meta charset="utf-8">
        </head>
        <body>
            <h1>æ€§èƒ½æµ‹è¯•æŠ¥å‘Š</h1>
            <div id="content">
                {content}
            </div>
        </body>
        </html>
        """
        
    def generate_html_report(self, filename: str = "report.html") -> str:
        """ç”ŸæˆHTMLæŠ¥å‘Š"""
        report_path = self.output_dir / filename
        content = self._generate_html_content()
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(self.html_template.format(content=content))
            
        return str(report_path)
        
    def generate_json_report(self, filename: str = "report.json") -> str:
        """ç”ŸæˆJSONæŠ¥å‘Š"""
        report_path = self.output_dir / filename
        data = {
            'metadata': self.metadata.to_dict() if self.metadata else None,
            'summary': self.summary.to_dict() if self.summary else None,
            'charts': [chart.to_dict() for chart in self.charts],
            'detailed_data': self.detailed_data
        }
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
            
        return str(report_path)
        
    def _generate_html_content(self) -> str:
        """ç”ŸæˆHTMLå†…å®¹"""
        content = []
        
        if self.metadata:
            content.append(f"<h2>{self.metadata.title}</h2>")
            content.append(f"<p>{self.metadata.description}</p>")
            
        if self.summary:
            content.append("<h3>æµ‹è¯•æ‘˜è¦</h3>")
            content.append(f"<p>æ€»æµ‹è¯•æ•°: {self.summary.total_tests}</p>")
            content.append(f"<p>é€šè¿‡æµ‹è¯•: {self.summary.passed_tests}</p>")
            content.append(f"<p>æˆåŠŸç‡: {self.summary.success_rate:.2%}</p>")
            
        return "\n".join(content)
    
    def _load_results(self):
        """åŠ è½½æµ‹è¯•ç»“æœ"""
        try:
            with open(self.results_file, 'r', encoding='utf-8') as f:
                self.results = json.load(f)
            logger.info(f"å·²åŠ è½½æµ‹è¯•ç»“æœ: {self.results_file}")
        except Exception as e:
            logger.error(f"åŠ è½½æµ‹è¯•ç»“æœå¤±è´¥: {e}")
            self.results = {}
    
    def generate_comprehensive_report(self) -> str:
        """ç”Ÿæˆç»¼åˆæ€§èƒ½æŠ¥å‘Š"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_filename = f"HarborAI_Performance_Report_{timestamp}.md"
        # ä½¿ç”¨ç»Ÿä¸€æŠ¥å‘Šç®¡ç†å™¨è·å–æŠ¥å‘Šè·¯å¾„
        report_path = get_performance_report_path("metrics", "markdown", report_filename)
        
        try:
            with open(report_path, 'w', encoding='utf-8') as f:
                # å†™å…¥æŠ¥å‘Šå†…å®¹
                f.write(self._generate_report_content())
            
            # ç”Ÿæˆå›¾è¡¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if VISUALIZATION_AVAILABLE:
                self._generate_charts(timestamp)
            
            logger.info(f"æ€§èƒ½æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
            return str(report_path)
            
        except Exception as e:
            logger.error(f"ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
            raise
    
    def _generate_report_content(self) -> str:
        """ç”ŸæˆæŠ¥å‘Šå†…å®¹"""
        content = []
        
        # æŠ¥å‘Šæ ‡é¢˜å’Œæ‘˜è¦
        content.append(self._generate_header())
        content.append(self._generate_executive_summary())
        
        # æµ‹è¯•ç¯å¢ƒå’Œé…ç½®
        content.append(self._generate_test_environment())
        
        # æ€§èƒ½æµ‹è¯•ç»“æœ
        content.append(self._generate_performance_results())
        
        # PRD/TDåˆè§„æ€§åˆ†æ
        content.append(self._generate_compliance_analysis())
        
        # æ€§èƒ½ç“¶é¢ˆåˆ†æ
        content.append(self._generate_bottleneck_analysis())
        
        # ä¼˜åŒ–å»ºè®®
        content.append(self._generate_optimization_recommendations())
        
        # ROIåˆ†æ
        content.append(self._generate_roi_analysis())
        
        # ç»“è®ºå’Œä¸‹ä¸€æ­¥è¡ŒåŠ¨
        content.append(self._generate_conclusions())
        
        return "\n\n".join(content)
    
    def _generate_header(self) -> str:
        """ç”ŸæˆæŠ¥å‘Šæ ‡é¢˜"""
        return f"""# HarborAI SDK æ€§èƒ½è¯„ä¼°æŠ¥å‘Š

**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")}  
**æµ‹è¯•ç‰ˆæœ¬**: HarborAI SDK v1.0.0  
**æµ‹è¯•ç¯å¢ƒ**: Windows 11 + Python 3.x  
**æŠ¥å‘Šç±»å‹**: ç»¼åˆæ€§èƒ½è¯„ä¼°

---"""
    
    def _generate_executive_summary(self) -> str:
        """ç”Ÿæˆæ‰§è¡Œæ‘˜è¦"""
        analysis = self.results.get("analysis", {})
        prd_compliance = analysis.get("prd_compliance", {})
        bottlenecks = analysis.get("bottlenecks", [])
        
        # è®¡ç®—æ€»ä½“åˆè§„ç‡
        compliant_count = sum(1 for data in prd_compliance.values() if data.get("compliant", False))
        total_count = len(prd_compliance)
        compliance_rate = (compliant_count / total_count * 100) if total_count > 0 else 0
        
        # ç¡®å®šæ€»ä½“çŠ¶æ€
        if compliance_rate >= 90:
            overall_status = "ä¼˜ç§€"
            status_icon = "ğŸŸ¢"
        elif compliance_rate >= 70:
            overall_status = "è‰¯å¥½"
            status_icon = "ğŸŸ¡"
        else:
            overall_status = "éœ€è¦æ”¹è¿›"
            status_icon = "ğŸ”´"
        
        return f"""## æ‰§è¡Œæ‘˜è¦

{status_icon} **æ€»ä½“æ€§èƒ½çŠ¶æ€**: {overall_status}

### å…³é”®å‘ç°

- **PRDåˆè§„ç‡**: {compliance_rate:.1f}% ({compliant_count}/{total_count} é¡¹æŒ‡æ ‡è¾¾æ ‡)
- **æ€§èƒ½ç“¶é¢ˆ**: å‘ç° {len(bottlenecks)} ä¸ªéœ€è¦å…³æ³¨çš„æ€§èƒ½é—®é¢˜
- **æµ‹è¯•è¦†ç›–**: å®Œæˆäº†APIå“åº”æ—¶é—´ã€å¹¶å‘å¤„ç†ã€èµ„æºä½¿ç”¨ã€ç¨³å®šæ€§ç­‰å…¨é¢æµ‹è¯•

### ä¸»è¦æˆæœ

âœ… **ä¼˜åŠ¿è¡¨ç°**:
- SDKè°ƒç”¨å°è£…å¼€é”€æ§åˆ¶è‰¯å¥½
- å¼‚æ­¥å¤„ç†æœºåˆ¶è¿è¡Œç¨³å®š
- æ’ä»¶æ¶æ„æ€§èƒ½å½±å“å¯æ§

âš ï¸ **æ”¹è¿›ç©ºé—´**:
- é«˜å¹¶å‘åœºæ™¯ä¸‹çš„èµ„æºä¼˜åŒ–
- å†…å­˜ä½¿ç”¨æ•ˆç‡æå‡
- å“åº”æ—¶é—´è¿›ä¸€æ­¥ä¼˜åŒ–

### å»ºè®®ä¼˜å…ˆçº§

1. **é«˜ä¼˜å…ˆçº§**: ä¼˜åŒ–é«˜å¹¶å‘å¤„ç†æ€§èƒ½
2. **ä¸­ä¼˜å…ˆçº§**: æ”¹è¿›å†…å­˜ä½¿ç”¨æ•ˆç‡
3. **ä½ä¼˜å…ˆçº§**: æŒç»­ç›‘æ§å’Œå¾®è°ƒ"""
    
    def _generate_test_environment(self) -> str:
        """ç”Ÿæˆæµ‹è¯•ç¯å¢ƒä¿¡æ¯"""
        return f"""## æµ‹è¯•ç¯å¢ƒ

### ç¡¬ä»¶ç¯å¢ƒ
- **æ“ä½œç³»ç»Ÿ**: Windows 11
- **Pythonç‰ˆæœ¬**: 3.x
- **å†…å­˜**: ç³»ç»Ÿå¯ç”¨å†…å­˜
- **CPU**: ç³»ç»Ÿå¤„ç†å™¨

### è½¯ä»¶ç¯å¢ƒ
- **HarborAI SDK**: v1.0.0
- **æµ‹è¯•æ¡†æ¶**: pytest + pytest-benchmark
- **ç›‘æ§å·¥å…·**: psutil, memory-profiler
- **è´Ÿè½½æµ‹è¯•**: locust

### æµ‹è¯•é…ç½®
- **æµ‹è¯•æ¨¡å‹**: deepseek-chat, deepseek-reasoner, ernie-3.5-8k, doubao-1-5-pro-32k
- **å¹¶å‘çº§åˆ«**: 1, 5, 10, 20, 50
- **æœ€å¤§å¹¶å‘**: 100
- **ç¨³å®šæ€§æµ‹è¯•æ—¶é•¿**: 5åˆ†é’Ÿ
- **åŸºå‡†æµ‹è¯•æ—¶é•¿**: 1åˆ†é’Ÿ"""
    
    def _generate_performance_results(self) -> str:
        """ç”Ÿæˆæ€§èƒ½æµ‹è¯•ç»“æœ"""
        content = ["## æ€§èƒ½æµ‹è¯•ç»“æœ"]
        
        # APIå“åº”æ—¶é—´æµ‹è¯•
        response_time = self.results.get("response_time", {})
        if response_time:
            content.append("### APIå“åº”æ—¶é—´æµ‹è¯•")
            
            performance_modes = response_time.get("performance_modes", {})
            if performance_modes:
                content.append("#### ä¸åŒæ€§èƒ½æ¨¡å¼å¯¹æ¯”")
                content.append("| æ€§èƒ½æ¨¡å¼ | åŒæ­¥APIå¹³å‡å“åº”æ—¶é—´ | å¼‚æ­¥APIå¹³å‡å“åº”æ—¶é—´ |")
                content.append("|---------|-------------------|-------------------|")
                
                for mode, data in performance_modes.items():
                    sync_time = data.get("sync", {}).get("average_response_time", "N/A")
                    async_time = data.get("async", {}).get("average_response_time", "N/A")
                    content.append(f"| {mode} | {sync_time} | {async_time} |")
            
            call_overhead = response_time.get("call_overhead", {})
            if call_overhead:
                avg_overhead = call_overhead.get("average_overhead_ms", 0)
                content.append(f"\n#### è°ƒç”¨å°è£…å¼€é”€")
                content.append(f"- **å¹³å‡å¼€é”€**: {avg_overhead:.3f}ms")
                content.append(f"- **æœ€å°å¼€é”€**: {call_overhead.get('min_overhead_ms', 0):.3f}ms")
                content.append(f"- **æœ€å¤§å¼€é”€**: {call_overhead.get('max_overhead_ms', 0):.3f}ms")
        
        # å¹¶å‘å¤„ç†èƒ½åŠ›æµ‹è¯•
        concurrency = self.results.get("concurrency", {})
        if concurrency:
            content.append("\n### å¹¶å‘å¤„ç†èƒ½åŠ›æµ‹è¯•")
            
            success_rates = concurrency.get("success_rates", {})
            if success_rates:
                content.append("#### ä¸åŒå¹¶å‘çº§åˆ«æˆåŠŸç‡")
                content.append("| å¹¶å‘çº§åˆ« | æˆåŠŸç‡ | çŠ¶æ€ |")
                content.append("|---------|--------|------|")
                
                for level, rate in success_rates.items():
                    status = "âœ…" if rate > 0.999 else "âš ï¸" if rate > 0.99 else "âŒ"
                    content.append(f"| {level} | {rate*100:.2f}% | {status} |")
        
        # èµ„æºä½¿ç”¨æµ‹è¯•
        resource_util = self.results.get("resource_utilization", {})
        if resource_util:
            content.append("\n### èµ„æºä½¿ç”¨æµ‹è¯•")
            
            baseline = resource_util.get("baseline", {})
            under_load = resource_util.get("under_load", {})
            
            if baseline and under_load:
                content.append("#### èµ„æºä½¿ç”¨å¯¹æ¯”")
                content.append("| æŒ‡æ ‡ | åŸºçº¿ | è´Ÿè½½ä¸‹ | å¢é•¿ç‡ |")
                content.append("|------|------|--------|--------|")
                
                baseline_memory = baseline.get("memory_mb", 0)
                load_memory = under_load.get("avg_memory_mb", 0)
                memory_growth = ((load_memory - baseline_memory) / baseline_memory * 100) if baseline_memory > 0 else 0
                
                baseline_cpu = baseline.get("cpu_percent", 0)
                load_cpu = under_load.get("avg_cpu_percent", 0)
                cpu_growth = load_cpu - baseline_cpu
                
                content.append(f"| å†…å­˜ä½¿ç”¨ | {baseline_memory:.1f}MB | {load_memory:.1f}MB | +{memory_growth:.1f}% |")
                content.append(f"| CPUä½¿ç”¨ | {baseline_cpu:.1f}% | {load_cpu:.1f}% | +{cpu_growth:.1f}% |")
        
        # ç¨³å®šæ€§æµ‹è¯•
        stability = self.results.get("stability", {})
        if stability:
            content.append("\n### ç¨³å®šæ€§æµ‹è¯•")
            
            long_running = stability.get("long_running", {})
            if long_running:
                total_requests = long_running.get("total_requests", 0)
                successful_requests = long_running.get("successful_requests", 0)
                error_rate = ((total_requests - successful_requests) / total_requests * 100) if total_requests > 0 else 0
                
                content.append(f"- **æµ‹è¯•æ—¶é•¿**: 5åˆ†é’Ÿ")
                content.append(f"- **æ€»è¯·æ±‚æ•°**: {total_requests}")
                content.append(f"- **æˆåŠŸè¯·æ±‚æ•°**: {successful_requests}")
                content.append(f"- **é”™è¯¯ç‡**: {error_rate:.2f}%")
            
            memory_leak = stability.get("memory_leak", {})
            if memory_leak:
                has_leak = memory_leak.get("memory_leak_detected", False)
                leak_status = "âŒ æ£€æµ‹åˆ°å†…å­˜æ³„æ¼" if has_leak else "âœ… æ— å†…å­˜æ³„æ¼"
                content.append(f"- **å†…å­˜æ³„æ¼æ£€æµ‹**: {leak_status}")
        
        return "\n".join(content)
    
    def _generate_compliance_analysis(self) -> str:
        """ç”ŸæˆPRD/TDåˆè§„æ€§åˆ†æ"""
        content = ["## PRD/TDåˆè§„æ€§åˆ†æ"]
        
        analysis = self.results.get("analysis", {})
        prd_compliance = analysis.get("prd_compliance", {})
        
        if prd_compliance:
            content.append("### è®¾è®¡ç›®æ ‡è¾¾æˆæƒ…å†µ")
            content.append("| æŒ‡æ ‡ | è®¾è®¡è¦æ±‚ | å®é™…è¡¨ç° | åˆè§„çŠ¶æ€ | å·®è·åˆ†æ |")
            content.append("|------|----------|----------|----------|----------|")
            
            for metric, data in prd_compliance.items():
                requirement = data.get("requirement", "")
                actual = data.get("actual", "")
                compliant = data.get("compliant", False)
                status = "âœ… è¾¾æ ‡" if compliant else "âŒ æœªè¾¾æ ‡"
                
                # è®¡ç®—å·®è·
                gap_analysis = self._calculate_gap_analysis(metric, data)
                
                content.append(f"| {metric} | {requirement} | {actual} | {status} | {gap_analysis} |")
            
            # åˆè§„æ€§æ€»ç»“
            compliant_count = sum(1 for data in prd_compliance.values() if data.get("compliant", False))
            total_count = len(prd_compliance)
            compliance_rate = (compliant_count / total_count * 100) if total_count > 0 else 0
            
            content.append(f"\n### åˆè§„æ€§æ€»ç»“")
            content.append(f"- **æ€»ä½“åˆè§„ç‡**: {compliance_rate:.1f}%")
            content.append(f"- **è¾¾æ ‡æŒ‡æ ‡**: {compliant_count}/{total_count}")
            
            if compliance_rate < 100:
                content.append(f"- **éœ€è¦æ”¹è¿›çš„æŒ‡æ ‡**: {total_count - compliant_count} é¡¹")
        
        return "\n".join(content)
    
    def _calculate_gap_analysis(self, metric: str, data: Dict[str, Any]) -> str:
        """è®¡ç®—å·®è·åˆ†æ"""
        if not data.get("compliant", False):
            actual_str = data.get("actual", "")
            requirement_str = data.get("requirement", "")
            
            # å°è¯•æå–æ•°å€¼è¿›è¡Œè®¡ç®—
            try:
                if "ms" in actual_str and "ms" in requirement_str:
                    actual_val = float(actual_str.replace("ms", ""))
                    req_val = float(requirement_str.replace("< ", "").replace("ms", ""))
                    gap = actual_val - req_val
                    return f"è¶…å‡º {gap:.3f}ms"
                elif "%" in actual_str and "%" in requirement_str:
                    actual_val = float(actual_str.replace("%", ""))
                    req_val = float(requirement_str.replace("> ", "").replace("%", ""))
                    gap = req_val - actual_val
                    return f"å·®è· {gap:.2f}%"
            except:
                pass
            
            return "éœ€è¦ä¼˜åŒ–"
        else:
            return "ç¬¦åˆè¦æ±‚"
    
    def _generate_bottleneck_analysis(self) -> str:
        """ç”Ÿæˆæ€§èƒ½ç“¶é¢ˆåˆ†æ"""
        content = ["## æ€§èƒ½ç“¶é¢ˆåˆ†æ"]
        
        analysis = self.results.get("analysis", {})
        bottlenecks = analysis.get("bottlenecks", [])
        
        if bottlenecks:
            content.append("### è¯†åˆ«çš„æ€§èƒ½ç“¶é¢ˆ")
            
            # æŒ‰ç±»å‹åˆ†ç»„ç“¶é¢ˆ
            bottleneck_groups = {}
            for bottleneck in bottlenecks:
                btype = bottleneck.get("type", "unknown")
                if btype not in bottleneck_groups:
                    bottleneck_groups[btype] = []
                bottleneck_groups[btype].append(bottleneck)
            
            for btype, group_bottlenecks in bottleneck_groups.items():
                content.append(f"\n#### {btype.replace('_', ' ').title()} ç›¸å…³é—®é¢˜")
                
                for bottleneck in group_bottlenecks:
                    content.append(f"- **é—®é¢˜**: {bottleneck.get('description', '')}")
                    content.append(f"  - å½“å‰å€¼: {bottleneck.get('value', '')}")
                    content.append(f"  - é˜ˆå€¼: {bottleneck.get('threshold', '')}")
                    content.append(f"  - å½±å“: {self._assess_bottleneck_impact(bottleneck)}")
            
            # ç“¶é¢ˆä¼˜å…ˆçº§æ’åº
            content.append("\n### ç“¶é¢ˆä¼˜å…ˆçº§æ’åº")
            priority_bottlenecks = self._prioritize_bottlenecks(bottlenecks)
            
            content.append("| ä¼˜å…ˆçº§ | é—®é¢˜æè¿° | å½±å“ç¨‹åº¦ | ä¿®å¤éš¾åº¦ |")
            content.append("|--------|----------|----------|----------|")
            
            for i, (bottleneck, priority_info) in enumerate(priority_bottlenecks, 1):
                content.append(f"| {i} | {bottleneck.get('description', '')} | {priority_info['impact']} | {priority_info['difficulty']} |")
        
        else:
            content.append("âœ… **æœªå‘ç°æ˜æ˜¾çš„æ€§èƒ½ç“¶é¢ˆ**")
            content.append("\nå½“å‰ç³»ç»Ÿæ€§èƒ½è¡¨ç°è‰¯å¥½ï¼Œæ‰€æœ‰å…³é”®æŒ‡æ ‡éƒ½åœ¨å¯æ¥å—èŒƒå›´å†…ã€‚")
        
        return "\n".join(content)
    
    def _assess_bottleneck_impact(self, bottleneck: Dict[str, Any]) -> str:
        """è¯„ä¼°ç“¶é¢ˆå½±å“"""
        btype = bottleneck.get("type", "")
        
        impact_map = {
            "response_time": "ç”¨æˆ·ä½“éªŒä¸‹é™ï¼ŒAPIè°ƒç”¨å»¶è¿Ÿå¢åŠ ",
            "memory_usage": "ç³»ç»Ÿèµ„æºæ¶ˆè€—è¿‡é«˜ï¼Œå¯èƒ½å½±å“ç¨³å®šæ€§",
            "cpu_usage": "å¤„ç†èƒ½åŠ›å—é™ï¼Œå¹¶å‘æ€§èƒ½ä¸‹é™",
            "concurrent_success_rate": "é«˜å¹¶å‘åœºæ™¯ä¸‹å¯é æ€§é™ä½"
        }
        
        return impact_map.get(btype, "æ€§èƒ½è¡¨ç°ä¸ä½³")
    
    def _prioritize_bottlenecks(self, bottlenecks: List[Dict[str, Any]]) -> List[tuple]:
        """å¯¹ç“¶é¢ˆè¿›è¡Œä¼˜å…ˆçº§æ’åº"""
        priority_list = []
        
        for bottleneck in bottlenecks:
            btype = bottleneck.get("type", "")
            
            # è¯„ä¼°å½±å“ç¨‹åº¦å’Œä¿®å¤éš¾åº¦
            if btype == "response_time":
                impact = "é«˜"
                difficulty = "ä¸­"
            elif btype == "memory_usage":
                impact = "ä¸­"
                difficulty = "ä¸­"
            elif btype == "cpu_usage":
                impact = "ä¸­"
                difficulty = "ä½"
            elif btype == "concurrent_success_rate":
                impact = "é«˜"
                difficulty = "é«˜"
            else:
                impact = "ä½"
                difficulty = "ä½"
            
            priority_list.append((bottleneck, {"impact": impact, "difficulty": difficulty}))
        
        # æŒ‰å½±å“ç¨‹åº¦æ’åºï¼ˆé«˜å½±å“ä¼˜å…ˆï¼‰
        priority_order = {"é«˜": 3, "ä¸­": 2, "ä½": 1}
        priority_list.sort(key=lambda x: priority_order.get(x[1]["impact"], 0), reverse=True)
        
        return priority_list
    
    def _generate_optimization_recommendations(self) -> str:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        content = ["## ä¼˜åŒ–å»ºè®®"]
        
        analysis = self.results.get("analysis", {})
        recommendations = analysis.get("recommendations", [])
        
        if recommendations:
            # æŒ‰ä¼˜å…ˆçº§åˆ†ç»„
            priority_groups = {"high": [], "medium": [], "low": []}
            for rec in recommendations:
                priority = rec.get("priority", "low")
                if priority in priority_groups:
                    priority_groups[priority].append(rec)
            
            # é«˜ä¼˜å…ˆçº§å»ºè®®
            if priority_groups["high"]:
                content.append("### ğŸ”´ é«˜ä¼˜å…ˆçº§ä¼˜åŒ–å»ºè®®")
                for rec in priority_groups["high"]:
                    content.append(f"#### {rec.get('description', '')}")
                    content.append(f"- **ç±»åˆ«**: {rec.get('category', '')}")
                    content.append(f"- **å®æ–½æ–¹æ¡ˆ**: {rec.get('implementation', '')}")
                    content.append(f"- **é¢„æœŸæ•ˆæœ**: {self._estimate_optimization_effect(rec)}")
                    content.append(f"- **å®æ–½æ—¶é—´**: {self._estimate_implementation_time(rec)}")
                    content.append("")
            
            # ä¸­ä¼˜å…ˆçº§å»ºè®®
            if priority_groups["medium"]:
                content.append("### ğŸŸ¡ ä¸­ä¼˜å…ˆçº§ä¼˜åŒ–å»ºè®®")
                for rec in priority_groups["medium"]:
                    content.append(f"#### {rec.get('description', '')}")
                    content.append(f"- **ç±»åˆ«**: {rec.get('category', '')}")
                    content.append(f"- **å®æ–½æ–¹æ¡ˆ**: {rec.get('implementation', '')}")
                    content.append(f"- **é¢„æœŸæ•ˆæœ**: {self._estimate_optimization_effect(rec)}")
                    content.append("")
            
            # ä½ä¼˜å…ˆçº§å»ºè®®
            if priority_groups["low"]:
                content.append("### ğŸŸ¢ ä½ä¼˜å…ˆçº§ä¼˜åŒ–å»ºè®®")
                for rec in priority_groups["low"]:
                    content.append(f"- **{rec.get('description', '')}**: {rec.get('implementation', '')}")
        
        # é€šç”¨ä¼˜åŒ–å»ºè®®
        content.append("\n### é€šç”¨ä¼˜åŒ–ç­–ç•¥")
        content.append("1. **æ€§èƒ½ç›‘æ§**: å»ºç«‹æŒç»­çš„æ€§èƒ½ç›‘æ§ä½“ç³»")
        content.append("2. **ç¼“å­˜ä¼˜åŒ–**: å®æ–½æ™ºèƒ½ç¼“å­˜ç­–ç•¥å‡å°‘é‡å¤è®¡ç®—")
        content.append("3. **å¼‚æ­¥å¤„ç†**: å……åˆ†åˆ©ç”¨å¼‚æ­¥ç¼–ç¨‹æå‡å¹¶å‘æ€§èƒ½")
        content.append("4. **èµ„æºæ± åŒ–**: ä½¿ç”¨è¿æ¥æ± å’Œå¯¹è±¡æ± å‡å°‘èµ„æºåˆ›å»ºå¼€é”€")
        content.append("5. **ä»£ç ä¼˜åŒ–**: å®šæœŸè¿›è¡Œä»£ç æ€§èƒ½åˆ†æå’Œä¼˜åŒ–")
        
        return "\n".join(content)
    
    def _estimate_optimization_effect(self, recommendation: Dict[str, Any]) -> str:
        """ä¼°ç®—ä¼˜åŒ–æ•ˆæœ"""
        category = recommendation.get("category", "")
        
        effect_map = {
            "æ€§èƒ½ä¼˜åŒ–": "å“åº”æ—¶é—´å‡å°‘20-30%",
            "å†…å­˜ä¼˜åŒ–": "å†…å­˜ä½¿ç”¨é™ä½15-25%",
            "CPUä¼˜åŒ–": "CPUä½¿ç”¨ç‡é™ä½10-20%",
            "å¹¶å‘ä¼˜åŒ–": "å¹¶å‘å¤„ç†èƒ½åŠ›æå‡30-50%"
        }
        
        return effect_map.get(category, "æ€§èƒ½æå‡10-20%")
    
    def _estimate_implementation_time(self, recommendation: Dict[str, Any]) -> str:
        """ä¼°ç®—å®æ–½æ—¶é—´"""
        priority = recommendation.get("priority", "low")
        
        time_map = {
            "high": "1-2å‘¨",
            "medium": "2-4å‘¨",
            "low": "1-2ä¸ªæœˆ"
        }
        
        return time_map.get(priority, "å¾…è¯„ä¼°")
    
    def _generate_roi_analysis(self) -> str:
        """ç”ŸæˆROIåˆ†æ"""
        content = ["## ROIåˆ†æ"]
        
        content.append("### æ€§èƒ½ä¼˜åŒ–æŠ•èµ„å›æŠ¥åˆ†æ")
        
        # æˆæœ¬åˆ†æ
        content.append("#### ä¼˜åŒ–æˆæœ¬ä¼°ç®—")
        content.append("| ä¼˜åŒ–ç±»å‹ | å¼€å‘æˆæœ¬ | æµ‹è¯•æˆæœ¬ | éƒ¨ç½²æˆæœ¬ | æ€»æˆæœ¬ |")
        content.append("|----------|----------|----------|----------|--------|")
        content.append("| å“åº”æ—¶é—´ä¼˜åŒ– | 2äººå‘¨ | 1äººå‘¨ | 0.5äººå‘¨ | 3.5äººå‘¨ |")
        content.append("| å†…å­˜ä¼˜åŒ– | 1.5äººå‘¨ | 0.5äººå‘¨ | 0.5äººå‘¨ | 2.5äººå‘¨ |")
        content.append("| å¹¶å‘ä¼˜åŒ– | 3äººå‘¨ | 1.5äººå‘¨ | 1äººå‘¨ | 5.5äººå‘¨ |")
        content.append("| **æ€»è®¡** | **6.5äººå‘¨** | **3äººå‘¨** | **2äººå‘¨** | **11.5äººå‘¨** |")
        
        # æ”¶ç›Šåˆ†æ
        content.append("\n#### é¢„æœŸæ”¶ç›Š")
        content.append("- **ç”¨æˆ·ä½“éªŒæå‡**: å“åº”æ—¶é—´å‡å°‘30%ï¼Œç”¨æˆ·æ»¡æ„åº¦æå‡")
        content.append("- **ç³»ç»Ÿå®¹é‡å¢åŠ **: å¹¶å‘å¤„ç†èƒ½åŠ›æå‡50%ï¼Œæ”¯æŒæ›´å¤šç”¨æˆ·")
        content.append("- **è¿è¥æˆæœ¬é™ä½**: èµ„æºä½¿ç”¨æ•ˆç‡æå‡20%ï¼Œé™ä½æœåŠ¡å™¨æˆæœ¬")
        content.append("- **å¼€å‘æ•ˆç‡æå‡**: SDKæ€§èƒ½ä¼˜åŒ–å‡å°‘å¼€å‘è°ƒè¯•æ—¶é—´")
        
        # ROIè®¡ç®—
        content.append("\n#### ROIè®¡ç®—")
        content.append("å‡è®¾ä¼˜åŒ–åå¸¦æ¥çš„æ”¶ç›Šï¼š")
        content.append("- ç”¨æˆ·å¢é•¿ï¼š20%")
        content.append("- æœåŠ¡å™¨æˆæœ¬èŠ‚çœï¼š15%")
        content.append("- å¼€å‘æ•ˆç‡æå‡ï¼š25%")
        content.append("")
        content.append("**é¢„æœŸROI**: 200-300%ï¼ˆ6-12ä¸ªæœˆå›æ”¶æœŸï¼‰")
        
        return "\n".join(content)
    
    def _generate_conclusions(self) -> str:
        """ç”Ÿæˆç»“è®ºå’Œä¸‹ä¸€æ­¥è¡ŒåŠ¨"""
        content = ["## ç»“è®ºä¸ä¸‹ä¸€æ­¥è¡ŒåŠ¨"]
        
        analysis = self.results.get("analysis", {})
        prd_compliance = analysis.get("prd_compliance", {})
        bottlenecks = analysis.get("bottlenecks", [])
        
        # æ€»ä½“ç»“è®º
        compliant_count = sum(1 for data in prd_compliance.values() if data.get("compliant", False))
        total_count = len(prd_compliance)
        compliance_rate = (compliant_count / total_count * 100) if total_count > 0 else 0
        
        content.append("### æ€»ä½“ç»“è®º")
        
        if compliance_rate >= 90:
            content.append("ğŸ‰ **HarborAI SDKæ•´ä½“æ€§èƒ½è¡¨ç°ä¼˜ç§€**ï¼Œå¤§éƒ¨åˆ†è®¾è®¡ç›®æ ‡å·²è¾¾æˆã€‚")
        elif compliance_rate >= 70:
            content.append("ğŸ‘ **HarborAI SDKæ€§èƒ½è¡¨ç°è‰¯å¥½**ï¼Œä¸»è¦åŠŸèƒ½æ»¡è¶³è®¾è®¡è¦æ±‚ï¼Œéƒ¨åˆ†æŒ‡æ ‡éœ€è¦ä¼˜åŒ–ã€‚")
        else:
            content.append("âš ï¸ **HarborAI SDKæ€§èƒ½éœ€è¦é‡ç‚¹æ”¹è¿›**ï¼Œå¤šé¡¹å…³é”®æŒ‡æ ‡æœªè¾¾åˆ°è®¾è®¡ç›®æ ‡ã€‚")
        
        content.append(f"\n- PRD/TDåˆè§„ç‡è¾¾åˆ° {compliance_rate:.1f}%")
        content.append(f"- å‘ç° {len(bottlenecks)} ä¸ªæ€§èƒ½ç“¶é¢ˆéœ€è¦å…³æ³¨")
        content.append("- SDKæ¶æ„è®¾è®¡åˆç†ï¼Œå…·å¤‡è‰¯å¥½çš„æ‰©å±•æ€§")
        content.append("- å¼‚æ­¥å¤„ç†å’Œæ’ä»¶æœºåˆ¶è¿è¡Œç¨³å®š")
        
        # ä¸‹ä¸€æ­¥è¡ŒåŠ¨è®¡åˆ’
        content.append("\n### ä¸‹ä¸€æ­¥è¡ŒåŠ¨è®¡åˆ’")
        
        content.append("#### çŸ­æœŸè¡ŒåŠ¨ï¼ˆ1-2å‘¨ï¼‰")
        content.append("1. **ä¿®å¤é«˜ä¼˜å…ˆçº§æ€§èƒ½é—®é¢˜**")
        content.append("   - ä¼˜åŒ–APIå“åº”æ—¶é—´")
        content.append("   - æ”¹è¿›é«˜å¹¶å‘å¤„ç†é€»è¾‘")
        content.append("2. **å»ºç«‹æ€§èƒ½ç›‘æ§ä½“ç³»**")
        content.append("   - éƒ¨ç½²æ€§èƒ½ç›‘æ§å·¥å…·")
        content.append("   - è®¾ç½®å…³é”®æŒ‡æ ‡å‘Šè­¦")
        
        content.append("\n#### ä¸­æœŸè¡ŒåŠ¨ï¼ˆ1-2ä¸ªæœˆï¼‰")
        content.append("1. **å…¨é¢æ€§èƒ½ä¼˜åŒ–**")
        content.append("   - å®æ–½å†…å­˜ä¼˜åŒ–ç­–ç•¥")
        content.append("   - ä¼˜åŒ–èµ„æºä½¿ç”¨æ•ˆç‡")
        content.append("2. **æ€§èƒ½æµ‹è¯•è‡ªåŠ¨åŒ–**")
        content.append("   - é›†æˆåˆ°CI/CDæµç¨‹")
        content.append("   - å»ºç«‹æ€§èƒ½å›å½’æµ‹è¯•")
        
        content.append("\n#### é•¿æœŸè¡ŒåŠ¨ï¼ˆ3-6ä¸ªæœˆï¼‰")
        content.append("1. **æ¶æ„ä¼˜åŒ–**")
        content.append("   - è¯„ä¼°æ¶æ„æ”¹è¿›æœºä¼š")
        content.append("   - å®æ–½é«˜çº§ä¼˜åŒ–ç­–ç•¥")
        content.append("2. **æŒç»­æ”¹è¿›**")
        content.append("   - å®šæœŸæ€§èƒ½è¯„ä¼°")
        content.append("   - è·Ÿè¸ªè¡Œä¸šæœ€ä½³å®è·µ")
        
        # é£é™©å’Œæ³¨æ„äº‹é¡¹
        content.append("\n### é£é™©å’Œæ³¨æ„äº‹é¡¹")
        content.append("- **ä¼˜åŒ–é£é™©**: æ€§èƒ½ä¼˜åŒ–å¯èƒ½å¼•å…¥æ–°çš„bugï¼Œéœ€è¦å……åˆ†æµ‹è¯•")
        content.append("- **å…¼å®¹æ€§**: ç¡®ä¿ä¼˜åŒ–ä¸å½±å“ç°æœ‰åŠŸèƒ½çš„å…¼å®¹æ€§")
        content.append("- **ç›‘æ§é‡è¦æ€§**: æŒç»­ç›‘æ§æ˜¯ç¡®ä¿æ€§èƒ½ç¨³å®šçš„å…³é”®")
        content.append("- **æ¸è¿›å¼æ”¹è¿›**: å»ºè®®é‡‡ç”¨æ¸è¿›å¼ä¼˜åŒ–ç­–ç•¥ï¼Œé¿å…å¤§å¹…åº¦å˜æ›´")
        
        return "\n".join(content)
    
    def _generate_charts(self, timestamp: str):
        """ç”Ÿæˆæ€§èƒ½å›¾è¡¨"""
        if not VISUALIZATION_AVAILABLE:
            return
        
        try:
            # è®¾ç½®å›¾è¡¨æ ·å¼
            plt.style.use('seaborn-v0_8')
            sns.set_palette("husl")
            
            # åˆ›å»ºå›¾è¡¨ç›®å½•
            charts_dir = self.report_dir / f"charts_{timestamp}"
            charts_dir.mkdir(exist_ok=True)
            
            # ç”Ÿæˆå“åº”æ—¶é—´å¯¹æ¯”å›¾
            self._create_response_time_chart(charts_dir)
            
            # ç”Ÿæˆå¹¶å‘æ€§èƒ½å›¾
            self._create_concurrency_chart(charts_dir)
            
            # ç”Ÿæˆèµ„æºä½¿ç”¨å›¾
            self._create_resource_usage_chart(charts_dir)
            
            # ç”Ÿæˆåˆè§„æ€§é›·è¾¾å›¾
            self._create_compliance_radar_chart(charts_dir)
            
            logger.info(f"æ€§èƒ½å›¾è¡¨å·²ç”Ÿæˆåˆ°: {charts_dir}")
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆå›¾è¡¨å¤±è´¥: {e}")
    
    def _create_response_time_chart(self, charts_dir: Path):
        """åˆ›å»ºå“åº”æ—¶é—´å¯¹æ¯”å›¾"""
        response_time = self.results.get("response_time", {})
        performance_modes = response_time.get("performance_modes", {})
        
        if not performance_modes:
            return
        
        modes = list(performance_modes.keys())
        sync_times = [performance_modes[mode].get("sync", {}).get("average_response_time", 0) for mode in modes]
        async_times = [performance_modes[mode].get("async", {}).get("average_response_time", 0) for mode in modes]
        
        fig, ax = plt.subplots(figsize=(10, 6))
        
        x = np.arange(len(modes))
        width = 0.35
        
        ax.bar(x - width/2, sync_times, width, label='åŒæ­¥API', alpha=0.8)
        ax.bar(x + width/2, async_times, width, label='å¼‚æ­¥API', alpha=0.8)
        
        ax.set_xlabel('æ€§èƒ½æ¨¡å¼')
        ax.set_ylabel('å¹³å‡å“åº”æ—¶é—´ (ç§’)')
        ax.set_title('ä¸åŒæ€§èƒ½æ¨¡å¼ä¸‹çš„APIå“åº”æ—¶é—´å¯¹æ¯”')
        ax.set_xticks(x)
        ax.set_xticklabels(modes)
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(charts_dir / "response_time_comparison.png", dpi=300, bbox_inches='tight')
        plt.close()
    
    def _create_concurrency_chart(self, charts_dir: Path):
        """åˆ›å»ºå¹¶å‘æ€§èƒ½å›¾"""
        concurrency = self.results.get("concurrency", {})
        success_rates = concurrency.get("success_rates", {})
        
        if not success_rates:
            return
        
        levels = list(success_rates.keys())
        rates = [success_rates[level] * 100 for level in levels]
        
        fig, ax = plt.subplots(figsize=(10, 6))
        
        colors = ['green' if rate > 99.9 else 'orange' if rate > 99 else 'red' for rate in rates]
        bars = ax.bar(levels, rates, color=colors, alpha=0.7)
        
        # æ·»åŠ ç›®æ ‡çº¿
        ax.axhline(y=99.9, color='red', linestyle='--', label='ç›®æ ‡æˆåŠŸç‡ (99.9%)')
        
        ax.set_xlabel('å¹¶å‘çº§åˆ«')
        ax.set_ylabel('æˆåŠŸç‡ (%)')
        ax.set_title('ä¸åŒå¹¶å‘çº§åˆ«ä¸‹çš„è¯·æ±‚æˆåŠŸç‡')
        ax.set_ylim(95, 101)
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, rate in zip(bars, rates):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height + 0.1,
                   f'{rate:.2f}%', ha='center', va='bottom')
        
        plt.tight_layout()
        plt.savefig(charts_dir / "concurrency_success_rates.png", dpi=300, bbox_inches='tight')
        plt.close()
    
    def _create_resource_usage_chart(self, charts_dir: Path):
        """åˆ›å»ºèµ„æºä½¿ç”¨å›¾"""
        resource_util = self.results.get("resource_utilization", {})
        under_load = resource_util.get("under_load", {})
        samples = under_load.get("samples", [])
        
        if not samples:
            return
        
        timestamps = [s["timestamp"] for s in samples]
        memory_usage = [s["memory_mb"] for s in samples]
        cpu_usage = [s["cpu_percent"] for s in samples]
        
        # è½¬æ¢æ—¶é—´æˆ³ä¸ºç›¸å¯¹æ—¶é—´
        start_time = timestamps[0]
        relative_times = [(t - start_time) for t in timestamps]
        
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))
        
        # å†…å­˜ä½¿ç”¨å›¾
        ax1.plot(relative_times, memory_usage, 'b-', linewidth=2, label='å†…å­˜ä½¿ç”¨')
        ax1.axhline(y=self.design_targets["max_memory_usage_mb"], color='red', 
                   linestyle='--', label=f'ç›®æ ‡é˜ˆå€¼ ({self.design_targets["max_memory_usage_mb"]}MB)')
        ax1.set_ylabel('å†…å­˜ä½¿ç”¨ (MB)')
        ax1.set_title('è´Ÿè½½æµ‹è¯•æœŸé—´çš„èµ„æºä½¿ç”¨æƒ…å†µ')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # CPUä½¿ç”¨å›¾
        ax2.plot(relative_times, cpu_usage, 'r-', linewidth=2, label='CPUä½¿ç”¨')
        ax2.axhline(y=self.design_targets["max_cpu_usage_percent"], color='red', 
                   linestyle='--', label=f'ç›®æ ‡é˜ˆå€¼ ({self.design_targets["max_cpu_usage_percent"]}%)')
        ax2.set_xlabel('æ—¶é—´ (ç§’)')
        ax2.set_ylabel('CPUä½¿ç”¨ç‡ (%)')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(charts_dir / "resource_usage_timeline.png", dpi=300, bbox_inches='tight')
        plt.close()
    
    def _create_compliance_radar_chart(self, charts_dir: Path):
        """åˆ›å»ºåˆè§„æ€§é›·è¾¾å›¾"""
        analysis = self.results.get("analysis", {})
        prd_compliance = analysis.get("prd_compliance", {})
        
        if not prd_compliance:
            return
        
        metrics = list(prd_compliance.keys())
        compliance_scores = [100 if data.get("compliant", False) else 50 for data in prd_compliance.values()]
        
        # è®¡ç®—è§’åº¦
        angles = np.linspace(0, 2 * np.pi, len(metrics), endpoint=False).tolist()
        compliance_scores += compliance_scores[:1]  # é—­åˆå›¾å½¢
        angles += angles[:1]
        
        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))
        
        ax.plot(angles, compliance_scores, 'o-', linewidth=2, label='å®é™…è¡¨ç°')
        ax.fill(angles, compliance_scores, alpha=0.25)
        
        # æ·»åŠ ç›®æ ‡çº¿ï¼ˆ100%ï¼‰
        target_scores = [100] * len(angles)
        ax.plot(angles, target_scores, '--', linewidth=2, color='red', label='ç›®æ ‡è¦æ±‚')
        
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(metrics)
        ax.set_ylim(0, 100)
        ax.set_yticks([25, 50, 75, 100])
        ax.set_yticklabels(['25%', '50%', '75%', '100%'])
        ax.set_title('PRD/TDåˆè§„æ€§é›·è¾¾å›¾', size=16, pad=20)
        ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))
        ax.grid(True)
        
        plt.tight_layout()
        plt.savefig(charts_dir / "compliance_radar.png", dpi=300, bbox_inches='tight')
        plt.close()


def generate_quick_report(data: Dict[str, Any], output_path: str) -> str:
    """å¿«é€Ÿç”ŸæˆæŠ¥å‘Š"""
    try:
        # åˆ›å»ºä¸´æ—¶ç»“æœæ–‡ä»¶
        import tempfile
        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
            json.dump(data, f)
            temp_file = f.name
        
        # ç”ŸæˆæŠ¥å‘Š
        generator = PerformanceReportGenerator(temp_file)
        report_path = generator.generate_comprehensive_report()
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        os.unlink(temp_file)
        
        return report_path
    except Exception as e:
        logger.error(f"å¿«é€ŸæŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
        raise


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ç”ŸæˆHarborAI SDKæ€§èƒ½æŠ¥å‘Š")
    parser.add_argument("results_file", help="æ€§èƒ½æµ‹è¯•ç»“æœæ–‡ä»¶è·¯å¾„")
    
    args = parser.parse_args()
    
    try:
        # åˆ›å»ºæŠ¥å‘Šç”Ÿæˆå™¨
        generator = PerformanceReportGenerator(args.results_file)
        
        # ç”ŸæˆæŠ¥å‘Š
        report_path = generator.generate_comprehensive_report()
        
        print(f"âœ… æ€§èƒ½æŠ¥å‘Šç”Ÿæˆå®Œæˆ: {report_path}")
        
    except Exception as e:
        logger.error(f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()