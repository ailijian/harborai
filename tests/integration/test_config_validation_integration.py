#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å‘Šè­¦é…ç½®éªŒè¯é›†æˆæµ‹è¯•

æµ‹è¯•é…ç½®éªŒè¯å™¨ä¸å…¶ä»–ç»„ä»¶çš„é›†æˆï¼ŒåŒ…æ‹¬å®é™…é…ç½®æ–‡ä»¶çš„éªŒè¯ã€
é…ç½®çƒ­é‡è½½ã€é…ç½®å†²çªæ£€æµ‹ç­‰å®Œæ•´æµç¨‹ã€‚
"""

import pytest
import json
import yaml
import tempfile
import asyncio
from pathlib import Path
from unittest.mock import patch, MagicMock, AsyncMock

from harborai.core.alerts.config_validator import (
    ConfigValidator, ValidationLevel, ValidationResult,
    validate_config_file, validate_default_config
)
from harborai.core.alerts.alert_manager import AlertManager
from harborai.core.alerts.notification_service import NotificationService
from harborai.core.alerts.suppression_manager import SuppressionManager


class TestConfigValidationIntegration:
    """é…ç½®éªŒè¯é›†æˆæµ‹è¯•"""
    
    @pytest.fixture
    def production_like_config(self):
        """ç”Ÿäº§ç¯å¢ƒç±»ä¼¼çš„é…ç½®"""
        return {
            "alert_rules": [
                {
                    "id": "cpu_high",
                    "name": "CPUä½¿ç”¨ç‡è¿‡é«˜",
                    "description": "ç³»ç»ŸCPUä½¿ç”¨ç‡è¶…è¿‡é˜ˆå€¼",
                    "severity": "high",
                    "condition": "threshold",
                    "metric": "system.cpu.usage",
                    "threshold": 85.0,
                    "duration": 300,
                    "labels": {
                        "component": "system",
                        "team": "infrastructure",
                        "environment": "production"
                    },
                    "annotations": {
                        "summary": "CPUä½¿ç”¨ç‡è¿‡é«˜: {{ $value }}%",
                        "description": "ä¸»æœº {{ $labels.instance }} çš„CPUä½¿ç”¨ç‡å·²è¾¾åˆ° {{ $value }}%ï¼Œè¶…è¿‡é˜ˆå€¼ {{ $threshold }}%",
                        "runbook": "https://wiki.company.com/runbooks/high-cpu",
                        "dashboard": "https://grafana.company.com/d/system-overview"
                    }
                },
                {
                    "id": "memory_high",
                    "name": "å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜",
                    "description": "ç³»ç»Ÿå†…å­˜ä½¿ç”¨ç‡è¶…è¿‡é˜ˆå€¼",
                    "severity": "high",
                    "condition": "threshold",
                    "metric": "system.memory.usage",
                    "threshold": 90.0,
                    "duration": 180,
                    "labels": {
                        "component": "system",
                        "team": "infrastructure",
                        "environment": "production"
                    },
                    "annotations": {
                        "summary": "å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {{ $value }}%",
                        "description": "ä¸»æœº {{ $labels.instance }} çš„å†…å­˜ä½¿ç”¨ç‡å·²è¾¾åˆ° {{ $value }}%",
                        "runbook": "https://wiki.company.com/runbooks/high-memory"
                    }
                },
                {
                    "id": "disk_space_low",
                    "name": "ç£ç›˜ç©ºé—´ä¸è¶³",
                    "description": "ç£ç›˜å¯ç”¨ç©ºé—´ä½äºé˜ˆå€¼",
                    "severity": "critical",
                    "condition": "threshold",
                    "metric": "system.disk.free_percent",
                    "threshold": 10.0,
                    "duration": 60,
                    "labels": {
                        "component": "system",
                        "team": "infrastructure",
                        "environment": "production"
                    },
                    "annotations": {
                        "summary": "ç£ç›˜ç©ºé—´ä¸è¶³: {{ $value }}%",
                        "description": "ä¸»æœº {{ $labels.instance }} çš„ç£ç›˜å¯ç”¨ç©ºé—´ä»…å‰© {{ $value }}%",
                        "runbook": "https://wiki.company.com/runbooks/disk-space"
                    }
                },
                {
                    "id": "api_response_time_high",
                    "name": "APIå“åº”æ—¶é—´è¿‡é•¿",
                    "description": "APIå¹³å‡å“åº”æ—¶é—´è¶…è¿‡é˜ˆå€¼",
                    "severity": "medium",
                    "condition": "threshold",
                    "metric": "api.response_time.avg",
                    "threshold": 2000.0,
                    "duration": 300,
                    "labels": {
                        "component": "api",
                        "team": "backend",
                        "environment": "production"
                    },
                    "annotations": {
                        "summary": "APIå“åº”æ—¶é—´è¿‡é•¿: {{ $value }}ms",
                        "description": "API {{ $labels.endpoint }} çš„å¹³å‡å“åº”æ—¶é—´ä¸º {{ $value }}ms",
                        "runbook": "https://wiki.company.com/runbooks/api-performance"
                    }
                },
                {
                    "id": "error_rate_high",
                    "name": "é”™è¯¯ç‡è¿‡é«˜",
                    "description": "APIé”™è¯¯ç‡è¶…è¿‡é˜ˆå€¼",
                    "severity": "high",
                    "condition": "threshold",
                    "metric": "api.error_rate",
                    "threshold": 5.0,
                    "duration": 120,
                    "labels": {
                        "component": "api",
                        "team": "backend",
                        "environment": "production"
                    },
                    "annotations": {
                        "summary": "é”™è¯¯ç‡è¿‡é«˜: {{ $value }}%",
                        "description": "APIé”™è¯¯ç‡å·²è¾¾åˆ° {{ $value }}%ï¼Œéœ€è¦ç«‹å³æ£€æŸ¥",
                        "runbook": "https://wiki.company.com/runbooks/high-error-rate"
                    }
                }
            ],
            "notification": {
                "channels": [
                    {
                        "name": "console",
                        "type": "console",
                        "enabled": True,
                        "config": {}
                    },
                    {
                        "name": "ops_email",
                        "type": "email",
                        "enabled": True,
                        "config": {
                            "smtp_host": "smtp.company.com",
                            "smtp_port": 587,
                            "username": "alerts@company.com",
                            "password": "${SMTP_PASSWORD}",
                            "from_email": "alerts@company.com",
                            "use_tls": True
                        }
                    },
                    {
                        "name": "ops_slack",
                        "type": "slack",
                        "enabled": True,
                        "config": {
                            "webhook_url": "${SLACK_WEBHOOK_URL}",
                            "channel": "#ops-alerts",
                            "username": "AlertBot",
                            "icon_emoji": ":warning:"
                        }
                    },
                    {
                        "name": "dev_dingtalk",
                        "type": "dingtalk",
                        "enabled": True,
                        "config": {
                            "webhook_url": "${DINGTALK_WEBHOOK_URL}",
                            "secret": "${DINGTALK_SECRET}",
                            "at_all": False,
                            "at_mobiles": []
                        }
                    }
                ],
                "routing": {
                    "default_channels": ["console"],
                    "rules": [
                        {
                            "match": {"severity": "critical"},
                            "channels": ["console", "ops_email", "ops_slack"]
                        },
                        {
                            "match": {"severity": "high"},
                            "channels": ["console", "ops_slack"]
                        },
                        {
                            "match": {"team": "backend"},
                            "channels": ["console", "dev_dingtalk"]
                        },
                        {
                            "match": {"component": "system"},
                            "channels": ["console", "ops_email"]
                        }
                    ]
                },
                "rate_limits": {
                    "enabled": True,
                    "max_notifications_per_minute": 20,
                    "burst_limit": 50
                },
                "retry": {
                    "enabled": True,
                    "max_attempts": 3,
                    "backoff_factor": 2.0,
                    "max_delay": 300
                }
            },
            "suppression": {
                "rules": [
                    {
                        "id": "maintenance_window",
                        "name": "ç»´æŠ¤çª—å£",
                        "description": "å¤œé—´ç»´æŠ¤çª—å£æœŸé—´æŠ‘åˆ¶å‘Šè­¦",
                        "type": "time_based",
                        "enabled": True,
                        "start_time": "02:00",
                        "end_time": "04:00",
                        "timezone": "Asia/Shanghai",
                        "weekdays": [1, 2, 3, 4, 5]  # å·¥ä½œæ—¥
                    },
                    {
                        "id": "duplicate_alerts",
                        "name": "é‡å¤å‘Šè­¦æŠ‘åˆ¶",
                        "description": "æŠ‘åˆ¶çŸ­æ—¶é—´å†…çš„é‡å¤å‘Šè­¦",
                        "type": "duplicate",
                        "enabled": True,
                        "duplicate_window": 300,
                        "duplicate_threshold": 3
                    },
                    {
                        "id": "cascade_suppression",
                        "name": "çº§è”æŠ‘åˆ¶",
                        "description": "å½“ä¸»è¦æœåŠ¡å‘Šè­¦æ—¶æŠ‘åˆ¶ä¾èµ–æœåŠ¡å‘Šè­¦",
                        "type": "dependency",
                        "enabled": True,
                        "dependency_alerts": ["api_response_time_high"],
                        "dependency_rules": ["error_rate_high"]
                    },
                    {
                        "id": "low_priority_night",
                        "name": "å¤œé—´ä½ä¼˜å…ˆçº§æŠ‘åˆ¶",
                        "description": "å¤œé—´æŠ‘åˆ¶ä½ä¼˜å…ˆçº§å‘Šè­¦",
                        "type": "time_based",
                        "enabled": True,
                        "start_time": "22:00",
                        "end_time": "08:00",
                        "timezone": "Asia/Shanghai",
                        "severity_filter": ["low", "medium"]
                    }
                ]
            },
            "escalation": {
                "enabled": True,
                "global_settings": {
                    "escalation_timeout": 1800,
                    "auto_resolve_timeout": 3600,
                    "escalation_cooldown": 300,
                    "max_total_escalations": 5,
                    "business_hours": {
                        "start": "09:00",
                        "end": "18:00",
                        "timezone": "Asia/Shanghai",
                        "weekdays": [1, 2, 3, 4, 5]
                    }
                },
                "rules": [
                    {
                        "severity": "critical",
                        "steps": [
                            {
                                "delay": 0,
                                "channels": ["ops_slack"],
                                "message_template": "escalation_immediate",
                                "conditions": {
                                    "require_ack": False,
                                    "business_hours_only": False
                                }
                            },
                            {
                                "delay": 300,
                                "channels": ["ops_email"],
                                "message_template": "escalation_level1",
                                "conditions": {
                                    "require_ack": True,
                                    "business_hours_only": False
                                },
                                "auto_actions": ["create_incident"]
                            },
                            {
                                "delay": 900,
                                "channels": ["ops_email"],
                                "message_template": "escalation_level2",
                                "conditions": {
                                    "escalate_to": "manager",
                                    "business_hours_only": False
                                },
                                "auto_actions": ["page_on_call"]
                            }
                        ],
                        "max_escalations": 3
                    },
                    {
                        "severity": "high",
                        "steps": [
                            {
                                "delay": 600,
                                "channels": ["ops_slack"],
                                "message_template": "escalation_level1",
                                "conditions": {
                                    "require_ack": True,
                                    "business_hours_only": True
                                }
                            },
                            {
                                "delay": 1800,
                                "channels": ["ops_email"],
                                "message_template": "escalation_level2",
                                "conditions": {
                                    "business_hours_only": True
                                }
                            }
                        ],
                        "max_escalations": 2
                    }
                ],
                "notification_templates": {
                    "escalation_immediate": {
                        "subject": "ğŸš¨ ç´§æ€¥å‘Šè­¦ - {{ alert.name }}",
                        "body": "å‘Šè­¦å·²è§¦å‘ï¼Œéœ€è¦ç«‹å³å¤„ç†ï¼\n\nè¯¦æƒ…ï¼š{{ alert.description }}\næ—¶é—´ï¼š{{ alert.timestamp }}"
                    },
                    "escalation_level1": {
                        "subject": "âš ï¸ å‘Šè­¦å‡çº§ - {{ alert.name }}",
                        "body": "å‘Šè­¦å·²å‡çº§ï¼Œè¯·åŠæ—¶å¤„ç†ã€‚\n\nè¯¦æƒ…ï¼š{{ alert.description }}\næŒç»­æ—¶é—´ï¼š{{ alert.duration }}"
                    },
                    "escalation_level2": {
                        "subject": "ğŸ”¥ é«˜çº§åˆ«å‘Šè­¦å‡çº§ - {{ alert.name }}",
                        "body": "å‘Šè­¦å·²å‡çº§åˆ°é«˜çº§åˆ«ï¼Œéœ€è¦ç®¡ç†å±‚ä»‹å…¥ã€‚\n\nè¯¦æƒ…ï¼š{{ alert.description }}\nå½±å“ï¼š{{ alert.impact }}"
                    }
                },
                "escalation_policies": {
                    "default": {
                        "on_call_schedule": {
                            "primary": ["ops-team@company.com"],
                            "secondary": ["dev-team@company.com"],
                            "manager": ["manager@company.com"]
                        }
                    }
                }
            },
            "aggregation": {
                "enabled": True,
                "window_size": 300,
                "rules": [
                    {
                        "id": "system_alerts",
                        "name": "ç³»ç»Ÿå‘Šè­¦èšåˆ",
                        "group_by": ["instance", "component"],
                        "match": {"component": "system"},
                        "threshold": 3
                    },
                    {
                        "id": "api_alerts",
                        "name": "APIå‘Šè­¦èšåˆ",
                        "group_by": ["endpoint"],
                        "match": {"component": "api"},
                        "threshold": 2
                    }
                ]
            },
            "metrics": {
                "collection_interval": 60,
                "retention_days": 30,
                "storage_path": "/var/lib/harborai/metrics",
                "compression": True
            },
            "health_check": {
                "enabled": True,
                "interval": 30,
                "timeout": 10,
                "endpoints": [
                    "http://localhost:8080/health",
                    "http://localhost:9090/metrics"
                ]
            }
        }
    
    @pytest.fixture
    def config_with_errors(self):
        """åŒ…å«é”™è¯¯çš„é…ç½®"""
        return {
            "alert_rules": [
                {
                    "id": "",  # é”™è¯¯ï¼šç©ºID
                    "name": "æ— æ•ˆè§„åˆ™",
                    "severity": "invalid_severity",  # é”™è¯¯ï¼šæ— æ•ˆä¸¥é‡çº§åˆ«
                    "condition": "threshold",
                    "metric": "test_metric",
                    "threshold": "not_a_number"  # é”™è¯¯ï¼šéæ•°å­—é˜ˆå€¼
                },
                {
                    "id": "duplicate_id",
                    "name": "è§„åˆ™1",
                    "severity": "high",
                    "condition": "threshold",
                    "metric": "metric1",
                    "threshold": 80.0
                },
                {
                    "id": "duplicate_id",  # é”™è¯¯ï¼šé‡å¤ID
                    "name": "è§„åˆ™2",
                    "severity": "medium",
                    "condition": "threshold",
                    "metric": "metric2",
                    "threshold": 70.0
                }
            ],
            "notification": {
                "channels": [
                    {
                        "name": "",  # é”™è¯¯ï¼šç©ºåç§°
                        "type": "invalid_type",  # é”™è¯¯ï¼šæ— æ•ˆç±»å‹
                        "enabled": "not_boolean"  # é”™è¯¯ï¼šéå¸ƒå°”å€¼
                    },
                    {
                        "name": "email_channel",
                        "type": "email",
                        "config": {}  # é”™è¯¯ï¼šç¼ºå°‘å¿…éœ€çš„é‚®ä»¶é…ç½®
                    }
                ],
                "routing": {
                    "rules": [
                        {
                            "match": {"severity": "critical"},
                            "channels": ["nonexistent_channel"]  # é”™è¯¯ï¼šä¸å­˜åœ¨çš„æ¸ é“
                        }
                    ]
                }
            },
            "suppression": {
                "rules": [
                    {
                        "id": "time_rule",
                        "name": "æ—¶é—´è§„åˆ™",
                        "type": "time_based"
                        # é”™è¯¯ï¼šç¼ºå°‘æ—¶é—´é…ç½®
                    },
                    {
                        "id": "dep_rule",
                        "name": "ä¾èµ–è§„åˆ™",
                        "type": "dependency",
                        "dependency_alerts": ["nonexistent_alert"]  # é”™è¯¯ï¼šä¸å­˜åœ¨çš„å‘Šè­¦
                    }
                ]
            },
            "escalation": {
                "enabled": True,
                "rules": [
                    {
                        "severity": "critical",
                        "escalation_channels": ["nonexistent_channel"]  # é”™è¯¯ï¼šä¸å­˜åœ¨çš„æ¸ é“
                    }
                ]
            }
        }
    
    def test_validate_production_config(self, production_like_config):
        """æµ‹è¯•éªŒè¯ç”Ÿäº§ç¯å¢ƒé…ç½®"""
        validator = ConfigValidator()
        results = validator.validate_config(production_like_config)
        
        # ç»Ÿè®¡ç»“æœ
        errors = [r for r in results if r.level == ValidationLevel.ERROR]
        warnings = [r for r in results if r.level == ValidationLevel.WARNING]
        info = [r for r in results if r.level == ValidationLevel.INFO]
        
        # ç”Ÿäº§é…ç½®ä¸åº”è¯¥æœ‰é”™è¯¯
        assert len(errors) == 0, f"ç”Ÿäº§é…ç½®ä¸åº”è¯¥æœ‰é”™è¯¯: {[e.message for e in errors]}"
        
        # å¯èƒ½æœ‰ä¸€äº›è­¦å‘Šï¼ˆè¿™æ˜¯æ­£å¸¸çš„ï¼‰
        print(f"éªŒè¯ç»“æœ: {len(errors)} é”™è¯¯, {len(warnings)} è­¦å‘Š, {len(info)} ä¿¡æ¯")
        
        # æ£€æŸ¥é…ç½®å®Œæ•´æ€§
        summary = validator.get_summary()
        assert summary["errors"] == 0
    
    def test_validate_config_with_errors(self, config_with_errors):
        """æµ‹è¯•éªŒè¯åŒ…å«é”™è¯¯çš„é…ç½®"""
        validator = ConfigValidator()
        results = validator.validate_config(config_with_errors)
        
        errors = [r for r in results if r.level == ValidationLevel.ERROR]
        
        # åº”è¯¥æ£€æµ‹åˆ°æ‰€æœ‰é”™è¯¯
        assert len(errors) > 0, "åº”è¯¥æ£€æµ‹åˆ°é…ç½®é”™è¯¯"
        
        # æ£€æŸ¥ç‰¹å®šé”™è¯¯ç±»å‹
        error_messages = [e.message for e in errors]
        
        # å‘Šè­¦è§„åˆ™é”™è¯¯
        assert any("IDä¸èƒ½ä¸ºç©º" in msg for msg in error_messages)
        assert any("æ— æ•ˆçš„ä¸¥é‡çº§åˆ«" in msg for msg in error_messages)
        assert any("é‡å¤çš„å‘Šè­¦è§„åˆ™ID" in msg for msg in error_messages)
        
        # é€šçŸ¥æ¸ é“é”™è¯¯
        assert any("åç§°ä¸èƒ½ä¸ºç©º" in msg for msg in error_messages)
        assert any("ä¸æ”¯æŒçš„é€šçŸ¥ç±»å‹" in msg for msg in error_messages)
        assert any("é‚®ä»¶æ¸ é“ç¼ºå°‘å¿…éœ€çš„é…ç½®" in msg for msg in error_messages)
        
        # äº¤å‰å¼•ç”¨é”™è¯¯
        assert any("å¼•ç”¨äº†ä¸å­˜åœ¨çš„é€šçŸ¥æ¸ é“" in msg for msg in error_messages)
    
    def test_config_file_validation_json(self, production_like_config):
        """æµ‹è¯•JSONé…ç½®æ–‡ä»¶éªŒè¯"""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
            json.dump(production_like_config, f, indent=2, ensure_ascii=False)
            temp_path = f.name
        
        try:
            is_valid, results = validate_config_file(temp_path)
            
            assert is_valid, f"é…ç½®æ–‡ä»¶åº”è¯¥æœ‰æ•ˆ: {[r.message for r in results if r.level == ValidationLevel.ERROR]}"
            
            # æ£€æŸ¥ç»“æœæ ¼å¼
            assert isinstance(results, list)
            for result in results:
                assert isinstance(result, ValidationResult)
                assert hasattr(result, 'level')
                assert hasattr(result, 'category')
                assert hasattr(result, 'message')
        finally:
            Path(temp_path).unlink()
    
    def test_config_file_validation_yaml(self, production_like_config):
        """æµ‹è¯•YAMLé…ç½®æ–‡ä»¶éªŒè¯"""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as f:
            yaml.dump(production_like_config, f, default_flow_style=False, allow_unicode=True)
            temp_path = f.name
        
        try:
            # ä¿®æ”¹éªŒè¯å‡½æ•°ä»¥æ”¯æŒYAML
            with open(temp_path, 'r', encoding='utf-8') as file:
                config = yaml.safe_load(file)
            
            validator = ConfigValidator()
            results = validator.validate_config(config)
            
            errors = [r for r in results if r.level == ValidationLevel.ERROR]
            assert len(errors) == 0, f"YAMLé…ç½®ä¸åº”è¯¥æœ‰é”™è¯¯: {[e.message for e in errors]}"
        finally:
            Path(temp_path).unlink()
    
    def test_config_hot_reload_validation(self, production_like_config):
        """æµ‹è¯•é…ç½®çƒ­é‡è½½éªŒè¯"""
        # åˆ›å»ºåˆå§‹é…ç½®æ–‡ä»¶
        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
            json.dump(production_like_config, f, indent=2)
            temp_path = f.name
        
        try:
            # åˆå§‹éªŒè¯
            is_valid, results = validate_config_file(temp_path)
            assert is_valid
            
            # ä¿®æ”¹é…ç½®ï¼ˆæ·»åŠ é”™è¯¯ï¼‰
            invalid_config = production_like_config.copy()
            invalid_config["alert_rules"][0]["severity"] = "invalid_severity"
            
            with open(temp_path, 'w', encoding='utf-8') as f:
                json.dump(invalid_config, f, indent=2)
            
            # é‡æ–°éªŒè¯
            is_valid, results = validate_config_file(temp_path)
            assert not is_valid
            
            errors = [r for r in results if r.level == ValidationLevel.ERROR]
            assert any("æ— æ•ˆçš„ä¸¥é‡çº§åˆ«" in e.message for e in errors)
        finally:
            Path(temp_path).unlink()
    
    def test_cross_component_validation(self, production_like_config):
        """æµ‹è¯•è·¨ç»„ä»¶éªŒè¯"""
        validator = ConfigValidator()
        results = validator.validate_config(production_like_config)
        
        # æ£€æŸ¥äº¤å‰å¼•ç”¨éªŒè¯
        # 1. é€šçŸ¥è·¯ç”±ä¸­çš„æ¸ é“åº”è¯¥å­˜åœ¨
        # 2. æŠ‘åˆ¶è§„åˆ™ä¸­çš„ä¾èµ–å‘Šè­¦åº”è¯¥å­˜åœ¨
        # 3. å‡çº§é…ç½®ä¸­çš„æ¸ é“åº”è¯¥å­˜åœ¨
        
        errors = [r for r in results if r.level == ValidationLevel.ERROR]
        cross_ref_errors = [e for e in errors if "å¼•ç”¨" in e.message or "ä¸å­˜åœ¨" in e.message]
        
        # ç”Ÿäº§é…ç½®çš„äº¤å‰å¼•ç”¨åº”è¯¥æ˜¯æ­£ç¡®çš„
        assert len(cross_ref_errors) == 0, f"äº¤å‰å¼•ç”¨é”™è¯¯: {[e.message for e in cross_ref_errors]}"
    
    def test_performance_with_large_config(self):
        """æµ‹è¯•å¤§å‹é…ç½®çš„éªŒè¯æ€§èƒ½"""
        import time
        
        # ç”Ÿæˆå¤§å‹é…ç½®
        large_config = {
            "alert_rules": [],
            "notification": {"channels": []},
            "suppression": {"rules": []},
            "escalation": {"enabled": False},
            "aggregation": {"enabled": False},
            "metrics": {},
            "health_check": {"enabled": False}
        }
        
        # ç”Ÿæˆ1000ä¸ªå‘Šè­¦è§„åˆ™
        for i in range(1000):
            rule = {
                "id": f"rule_{i}",
                "name": f"è§„åˆ™ {i}",
                "description": f"æµ‹è¯•è§„åˆ™ {i}",
                "severity": "medium",
                "condition": "threshold",
                "metric": f"metric_{i}",
                "threshold": 80.0,
                "duration": 300,
                "labels": {"component": f"comp_{i % 10}"},
                "annotations": {"summary": f"å‘Šè­¦ {i}"}
            }
            large_config["alert_rules"].append(rule)
        
        # ç”Ÿæˆ100ä¸ªé€šçŸ¥æ¸ é“
        for i in range(100):
            channel = {
                "name": f"channel_{i}",
                "type": "console",
                "enabled": True,
                "config": {}
            }
            large_config["notification"]["channels"].append(channel)
        
        # æµ‹è¯•éªŒè¯æ€§èƒ½
        validator = ConfigValidator()
        start_time = time.time()
        results = validator.validate_config(large_config)
        end_time = time.time()
        
        validation_time = end_time - start_time
        print(f"éªŒè¯1000ä¸ªè§„åˆ™å’Œ100ä¸ªæ¸ é“è€—æ—¶: {validation_time:.2f}ç§’")
        
        # éªŒè¯åº”è¯¥åœ¨åˆç†æ—¶é—´å†…å®Œæˆï¼ˆæ¯”å¦‚5ç§’ï¼‰
        assert validation_time < 5.0, f"éªŒè¯æ—¶é—´è¿‡é•¿: {validation_time:.2f}ç§’"
        
        # æ£€æŸ¥ç»“æœ
        errors = [r for r in results if r.level == ValidationLevel.ERROR]
        assert len(errors) == 0, "å¤§å‹é…ç½®ä¸åº”è¯¥æœ‰é”™è¯¯"
    
    @pytest.mark.asyncio
    async def test_integration_with_alert_manager(self, production_like_config):
        """æµ‹è¯•ä¸å‘Šè­¦ç®¡ç†å™¨çš„é›†æˆ"""
        # é¦–å…ˆéªŒè¯é…ç½®
        validator = ConfigValidator()
        results = validator.validate_config(production_like_config)
        
        errors = [r for r in results if r.level == ValidationLevel.ERROR]
        assert len(errors) == 0, "é…ç½®å¿…é¡»æœ‰æ•ˆæ‰èƒ½é›†æˆ"
        
        # æ¨¡æ‹Ÿå‘Šè­¦ç®¡ç†å™¨ä½¿ç”¨é…ç½®
        with patch('harborai.core.alerts.alert_manager.AlertManager') as mock_manager:
            mock_instance = AsyncMock()
            mock_manager.return_value = mock_instance
            
            # æ¨¡æ‹ŸåŠ è½½é…ç½®
            mock_instance.load_rules.return_value = True
            
            # åˆ›å»ºå‘Šè­¦ç®¡ç†å™¨å®ä¾‹
            alert_manager = mock_manager()
            
            # åŠ è½½å‘Šè­¦è§„åˆ™
            rules_loaded = await alert_manager.load_rules(production_like_config["alert_rules"])
            assert rules_loaded
            
            # éªŒè¯è°ƒç”¨
            mock_instance.load_rules.assert_called_once()
    
    def test_default_config_validation(self):
        """æµ‹è¯•é»˜è®¤é…ç½®éªŒè¯"""
        is_valid, results = validate_default_config()
        
        # é»˜è®¤é…ç½®åº”è¯¥æ˜¯æœ‰æ•ˆçš„
        errors = [r for r in results if r.level == ValidationLevel.ERROR]
        assert len(errors) == 0, f"é»˜è®¤é…ç½®ä¸åº”è¯¥æœ‰é”™è¯¯: {[e.message for e in errors]}"
        
        # å¯èƒ½æœ‰ä¸€äº›ä¿¡æ¯æ€§æ¶ˆæ¯
        info_count = len([r for r in results if r.level == ValidationLevel.INFO])
        print(f"é»˜è®¤é…ç½®éªŒè¯: {info_count} æ¡ä¿¡æ¯")
    
    def test_config_schema_validation(self):
        """æµ‹è¯•é…ç½®æ¨¡å¼éªŒè¯"""
        from harborai.core.alerts.config_validator import create_config_schema
        
        schema = create_config_schema()
        
        # éªŒè¯æ¨¡å¼ç»“æ„
        assert "type" in schema
        assert schema["type"] == "object"
        assert "properties" in schema
        assert "required" in schema
        
        # éªŒè¯å¿…éœ€å­—æ®µ
        required_fields = schema["required"]
        assert "alert_rules" in required_fields
        assert "notification" in required_fields
        
        # éªŒè¯å±æ€§å®šä¹‰
        properties = schema["properties"]
        assert "alert_rules" in properties
        assert "notification" in properties
        assert "suppression" in properties
        assert "escalation" in properties
    
    def test_validation_result_formatting(self, config_with_errors):
        """æµ‹è¯•éªŒè¯ç»“æœæ ¼å¼åŒ–"""
        validator = ConfigValidator()
        results = validator.validate_config(config_with_errors)
        
        # æµ‹è¯•æ–‡æœ¬æ ¼å¼
        text_output = validator.format_results(format_type="text")
        assert isinstance(text_output, str)
        assert len(text_output) > 0
        assert "é”™è¯¯" in text_output or "ERROR" in text_output
        
        # æµ‹è¯•JSONæ ¼å¼
        json_output = validator.format_results(format_type="json")
        parsed = json.loads(json_output)
        
        assert "summary" in parsed
        assert "results" in parsed
        assert "total_results" in parsed["summary"]
        assert "errors" in parsed["summary"]
        assert "warnings" in parsed["summary"]
        
        # éªŒè¯ç»“æœæ•°æ®
        assert parsed["summary"]["errors"] > 0
        assert len(parsed["results"]) > 0


if __name__ == "__main__":
    pytest.main([__file__, "-v"])