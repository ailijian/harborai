#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€å•çš„å‚æ•°è¿‡æ»¤æµ‹è¯•è„šæœ¬
é¿å…pytestçš„å¤æ‚ç¯å¢ƒé—®é¢˜
"""

import os
import sys
from unittest.mock import Mock, patch

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

def test_parameter_filtering():
    """æµ‹è¯•æ¨ç†æ¨¡å‹çš„å‚æ•°è¿‡æ»¤åŠŸèƒ½"""
    print("å¼€å§‹æµ‹è¯•å‚æ•°è¿‡æ»¤åŠŸèƒ½...")
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ["DEEPSEEK_API_KEY"] = "test-key"
    os.environ["WENXIN_API_KEY"] = "test-key"
    os.environ["DOUBAO_API_KEY"] = "test-key"
    
    try:
        from harborai import HarborAI
        from harborai.core.models import filter_parameters_for_model, is_reasoning_model
        
        print("âœ“ æˆåŠŸå¯¼å…¥HarborAIæ¨¡å—")
        
        # æµ‹è¯•æ¨¡å‹æ£€æµ‹
        assert is_reasoning_model("deepseek-r1") == True
        assert is_reasoning_model("deepseek-chat") == False
        print("âœ“ æ¨ç†æ¨¡å‹æ£€æµ‹åŠŸèƒ½æ­£å¸¸")
        
        # æµ‹è¯•å‚æ•°è¿‡æ»¤
        original_params = {
            "model": "deepseek-r1",
            "messages": [{"role": "user", "content": "test"}],
            "temperature": 0.7,
            "top_p": 0.9,
            "frequency_penalty": 0.1,
            "presence_penalty": 0.1,
            "stream": True,
            "max_tokens": 1000
        }
        
        filtered_params = filter_parameters_for_model("deepseek-r1", original_params)
        
        # æ£€æŸ¥è¿‡æ»¤ç»“æœ
        assert "model" in filtered_params
        assert "messages" in filtered_params
        assert "max_tokens" in filtered_params
        
        # è¿™äº›å‚æ•°åº”è¯¥è¢«è¿‡æ»¤æ‰
        filtered_out = ["temperature", "top_p", "frequency_penalty", "presence_penalty", "stream"]
        for param in filtered_out:
            assert param not in filtered_params, f"å‚æ•° {param} åº”è¯¥è¢«è¿‡æ»¤"
        
        print("âœ“ å‚æ•°è¿‡æ»¤åŠŸèƒ½æ­£å¸¸")
        
        # æµ‹è¯•HarborAIå®¢æˆ·ç«¯çš„å‚æ•°è¿‡æ»¤
        client = HarborAI()
        
        # Mockåº•å±‚çš„client_managerè°ƒç”¨
        with patch.object(client.client_manager, 'chat_completion_sync_with_fallback') as mock_completion:
            # åˆ›å»ºä¸€ä¸ªæ›´å®Œæ•´çš„Mockå“åº”å¯¹è±¡
            mock_response = Mock()
            mock_response.choices = [Mock(
                message=Mock(
                    content="æµ‹è¯•å“åº”",
                    role="assistant"
                ),
                finish_reason="stop"
            )]
            mock_response.usage = Mock(
                prompt_tokens=10,
                completion_tokens=20,
                total_tokens=30
            )
            # æ·»åŠ model_dumpæ–¹æ³•
            mock_response.model_dump.return_value = {
                "choices": [{
                    "message": {
                        "content": "æµ‹è¯•å“åº”",
                        "role": "assistant"
                    },
                    "finish_reason": "stop"
                }],
                "usage": {
                    "prompt_tokens": 10,
                    "completion_tokens": 20,
                    "total_tokens": 30
                }
            }
            mock_completion.return_value = mock_response
            
            # è°ƒç”¨createæ–¹æ³•
            response = client.chat.completions.create(
                model="deepseek-r1",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹"},
                    {"role": "user", "content": "è§£å†³è¿™ä¸ªé—®é¢˜"}
                ],
                temperature=0.7,
                top_p=0.9,
                frequency_penalty=0.1,
                presence_penalty=0.1,
                stream=True,
                max_tokens=1000
            )
            
            # æ£€æŸ¥è°ƒç”¨å‚æ•°
            call_args = mock_completion.call_args
            if call_args:
                call_kwargs = call_args[1] if len(call_args) > 1 else call_args[0]
                
                # åº”è¯¥ä¿ç•™çš„å‚æ•°
                assert call_kwargs.get('model') == "deepseek-r1"
                assert call_kwargs.get('max_tokens') == 1000
                
                # åº”è¯¥è¢«è¿‡æ»¤çš„å‚æ•°
                filtered_params = ['temperature', 'top_p', 'frequency_penalty', 'presence_penalty', 'stream']
                for param in filtered_params:
                    assert param not in call_kwargs, f"å‚æ•° {param} åº”è¯¥è¢«è¿‡æ»¤"
                
                # éªŒè¯systemæ¶ˆæ¯å¤„ç†
                messages = call_kwargs.get('messages', [])
                system_messages = []
                for msg in messages:
                    if hasattr(msg, 'role'):
                        if msg.role == 'system':
                            system_messages.append(msg)
                    elif isinstance(msg, dict) and msg.get('role') == 'system':
                        system_messages.append(msg)
                assert len(system_messages) == 0, "æ¨ç†æ¨¡å‹ä¸åº”è¯¥åŒ…å«systemæ¶ˆæ¯"
                
                print("âœ“ HarborAIå®¢æˆ·ç«¯å‚æ•°è¿‡æ»¤åŠŸèƒ½æ­£å¸¸")
                print(f"âœ“ ä¼ é€’ç»™client_managerçš„å‚æ•°: {list(call_kwargs.keys())}")
                print(f"âœ“ å¤„ç†åçš„æ¶ˆæ¯æ•°é‡: {len(messages)}")
                
                return True
            else:
                print("âœ— æœªèƒ½è·å–client_managerçš„è°ƒç”¨å‚æ•°")
                return False
                
    except Exception as e:
        print(f"âœ— æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_parameter_filtering()
    if success:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        sys.exit(0)
    else:
        print("\nâŒ æµ‹è¯•å¤±è´¥ï¼")
        sys.exit(1)