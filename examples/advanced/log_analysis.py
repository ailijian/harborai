#!/usr/bin/env python3
"""
HarborAI é«˜çº§æ—¥å¿—åˆ†æå·¥å…·

è¿™ä¸ªè„šæœ¬æä¾›äº† HarborAI æ—¥å¿—çš„é«˜çº§åˆ†æåŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
1. å¤šç»´åº¦æ—¥å¿—è¿‡æ»¤å’ŒæŸ¥è¯¢
2. æ—¥å¿—ç±»å‹ç»Ÿè®¡å’Œå¯è§†åŒ–
3. æ€§èƒ½åˆ†æå’Œè¶‹åŠ¿ç›‘æ§
4. é”™è¯¯æ¨¡å¼è¯†åˆ«å’Œåˆ†æ
5. è‡ªå®šä¹‰æŠ¥å‘Šç”Ÿæˆ
6. äº¤äº’å¼æ—¥å¿—æµè§ˆ
7. æ—¥å¿—æ•°æ®å¯¼å‡ºå’Œå¤‡ä»½

ä½œè€…: HarborAI Team
ç‰ˆæœ¬: 1.0.0
åˆ›å»ºæ—¶é—´: 2024-01-01
"""

import subprocess
import time
import sys
import json
import argparse
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime, timedelta
import re
from collections import defaultdict, Counter
import statistics


class LogAnalyzer:
    """é«˜çº§æ—¥å¿—åˆ†æå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        self.project_root = Path.cwd()
        self.view_logs_script = self.project_root / "view_logs.py"
        
        # æ£€æŸ¥ä¾èµ–
        if not self.view_logs_script.exists():
            raise FileNotFoundError(f"æœªæ‰¾åˆ° view_logs.py è„šæœ¬: {self.view_logs_script}")
    
    def _extract_json_content(self, output: str) -> Optional[str]:
        """ä»è¾“å‡ºä¸­æå–JSONå†…å®¹ï¼Œå¿½ç•¥æ—¥å¿—å‰ç¼€
        
        Args:
            output: åŸå§‹è¾“å‡ºå†…å®¹
            
        Returns:
            Optional[str]: æå–çš„JSONå†…å®¹ï¼Œå¦‚æœæœªæ‰¾åˆ°è¿”å›None
        """
        if not output or not output.strip():
            return None
        
        # æŸ¥æ‰¾JSONå¼€å§‹ä½ç½®ï¼Œä¼˜å…ˆæŸ¥æ‰¾æ•°ç»„ï¼Œç„¶åæŸ¥æ‰¾å¯¹è±¡
        json_start = -1
        for char in ['[', '{']:
            pos = output.find(char)
            if pos != -1:
                if json_start == -1 or pos < json_start:
                    json_start = pos
        
        if json_start != -1:
            return output[json_start:].strip()
        
        return None
    
    def run_view_logs_command(self, args: List[str]) -> Tuple[bool, str, str]:
        """è¿è¡Œ view_logs.py å‘½ä»¤"""
        cmd = ["python", str(self.view_logs_script)] + args
        
        try:
            result = subprocess.run(
                cmd, 
                capture_output=True, 
                text=True, 
                encoding='utf-8', 
                errors='ignore',
                timeout=30
            )
            return result.returncode == 0, result.stdout, result.stderr
        except subprocess.TimeoutExpired:
            return False, "", "å‘½ä»¤æ‰§è¡Œè¶…æ—¶"
        except Exception as e:
            return False, "", f"æ‰§è¡Œå‘½ä»¤æ—¶å‡ºé”™: {e}"
    
    def get_log_statistics(self, days: int = 7) -> Dict[str, Any]:
        """è·å–æ—¥å¿—ç»Ÿè®¡ä¿¡æ¯"""
        success, stdout, stderr = self.run_view_logs_command([
            "--stats", "--format", "json", "--days", str(days)
        ])
        
        if not success:
            print(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {stderr}")
            return {}
        
        try:
            # æå–JSONéƒ¨åˆ†ï¼Œå¿½ç•¥æ—¥å¿—å‰ç¼€
            json_content = self._extract_json_content(stdout)
            if json_content:
                return json.loads(json_content)
            else:
                print(f"âŒ æœªæ‰¾åˆ°JSONå†…å®¹")
                return {}
        except json.JSONDecodeError as e:
            print(f"âŒ è§£æç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            print(f"åŸå§‹è¾“å‡º: {stdout[:200]}...")  # æ˜¾ç¤ºå‰200å­—ç¬¦ç”¨äºè°ƒè¯•
            return {}
    
    def get_logs_by_type(self, log_type: str, limit: int = 100, days: int = 7) -> List[Dict[str, Any]]:
        """æŒ‰ç±»å‹è·å–æ—¥å¿—"""
        success, stdout, stderr = self.run_view_logs_command([
            "--type", log_type, 
            "--format", "json", 
            "--limit", str(limit),
            "--days", str(days)
        ])
        
        if not success:
            print(f"âŒ è·å– {log_type} æ—¥å¿—å¤±è´¥: {stderr}")
            return []
        
        try:
            # æå–JSONéƒ¨åˆ†ï¼Œå¿½ç•¥æ—¥å¿—å‰ç¼€
            json_content = self._extract_json_content(stdout)
            if json_content:
                data = json.loads(json_content)
                # å¤„ç†ä¸åŒçš„JSONç»“æ„
                if isinstance(data, list):
                    return data
                elif isinstance(data, dict):
                    return data.get('data', data.get('logs', []))
                else:
                    return []
            else:
                print(f"âŒ æœªæ‰¾åˆ°JSONå†…å®¹")
                return []
        except json.JSONDecodeError as e:
            print(f"âŒ è§£æ {log_type} æ—¥å¿—å¤±è´¥: {e}")
            print(f"åŸå§‹è¾“å‡º: {stdout[:200]}...")  # æ˜¾ç¤ºå‰200å­—ç¬¦ç”¨äºè°ƒè¯•
            return []
    
    def analyze_performance_trends(self, days: int = 7) -> Dict[str, Any]:
        """åˆ†ææ€§èƒ½è¶‹åŠ¿"""
        print(f"ğŸ” åˆ†ææœ€è¿‘ {days} å¤©çš„æ€§èƒ½è¶‹åŠ¿...")
        
        # è·å–å“åº”æ—¥å¿—
        response_logs = self.get_logs_by_type("response", limit=1000, days=days)
        
        if not response_logs:
            return {"error": "æ²¡æœ‰æ‰¾åˆ°å“åº”æ—¥å¿—"}
        
        # æŒ‰æ¨¡å‹åˆ†ç»„åˆ†æ
        model_performance = defaultdict(list)
        daily_performance = defaultdict(list)
        
        for log in response_logs:
            model = log.get('model', 'unknown')
            timestamp = log.get('timestamp', '')
            
            # æå–å“åº”æ—¶é—´
            response_time = None
            if 'response_time' in log:
                response_time = log['response_time']
            elif 'metadata' in log and isinstance(log['metadata'], dict):
                response_time = log['metadata'].get('response_time')
            
            if response_time is not None:
                model_performance[model].append(response_time)
                
                # æŒ‰æ—¥æœŸåˆ†ç»„
                try:
                    date = datetime.fromisoformat(timestamp.replace('Z', '+00:00')).date()
                    daily_performance[str(date)].append(response_time)
                except:
                    pass
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        analysis = {
            "model_performance": {},
            "daily_trends": {},
            "overall_stats": {}
        }
        
        # æ¨¡å‹æ€§èƒ½åˆ†æ
        for model, times in model_performance.items():
            if times:
                analysis["model_performance"][model] = {
                    "count": len(times),
                    "avg_response_time": statistics.mean(times),
                    "median_response_time": statistics.median(times),
                    "min_response_time": min(times),
                    "max_response_time": max(times),
                    "std_dev": statistics.stdev(times) if len(times) > 1 else 0
                }
        
        # æ¯æ—¥è¶‹åŠ¿åˆ†æ
        for date, times in daily_performance.items():
            if times:
                analysis["daily_trends"][date] = {
                    "count": len(times),
                    "avg_response_time": statistics.mean(times),
                    "median_response_time": statistics.median(times)
                }
        
        # æ€»ä½“ç»Ÿè®¡
        all_times = [t for times in model_performance.values() for t in times]
        if all_times:
            analysis["overall_stats"] = {
                "total_requests": len(all_times),
                "avg_response_time": statistics.mean(all_times),
                "median_response_time": statistics.median(all_times),
                "p95_response_time": sorted(all_times)[int(len(all_times) * 0.95)] if len(all_times) > 20 else max(all_times),
                "fastest_response": min(all_times),
                "slowest_response": max(all_times)
            }
        
        return analysis
    
    def analyze_error_patterns(self, days: int = 7) -> Dict[str, Any]:
        """åˆ†æé”™è¯¯æ¨¡å¼"""
        print(f"ğŸ” åˆ†ææœ€è¿‘ {days} å¤©çš„é”™è¯¯æ¨¡å¼...")
        
        # è·å–æ‰€æœ‰æ—¥å¿—
        all_logs = self.get_logs_by_type("all", limit=1000, days=days)
        
        if not all_logs:
            return {"error": "æ²¡æœ‰æ‰¾åˆ°æ—¥å¿—"}
        
        # é”™è¯¯åˆ†æ
        error_patterns = {
            "error_by_model": defaultdict(int),
            "error_by_type": defaultdict(int),
            "error_by_hour": defaultdict(int),
            "common_errors": Counter(),
            "success_rate_by_model": {},
            "total_requests": 0,
            "total_errors": 0
        }
        
        model_stats = defaultdict(lambda: {"total": 0, "errors": 0})
        
        for log in all_logs:
            model = log.get('model', 'unknown')
            level = log.get('level', '').upper()
            message = log.get('message', '')
            timestamp = log.get('timestamp', '')
            
            model_stats[model]["total"] += 1
            error_patterns["total_requests"] += 1
            
            # è¯†åˆ«é”™è¯¯
            is_error = (
                level in ['ERROR', 'CRITICAL'] or
                'error' in message.lower() or
                'failed' in message.lower() or
                'exception' in message.lower()
            )
            
            if is_error:
                error_patterns["total_errors"] += 1
                model_stats[model]["errors"] += 1
                error_patterns["error_by_model"][model] += 1
                
                # é”™è¯¯ç±»å‹åˆ†ç±»
                if 'timeout' in message.lower():
                    error_patterns["error_by_type"]["timeout"] += 1
                elif 'api' in message.lower():
                    error_patterns["error_by_type"]["api_error"] += 1
                elif 'auth' in message.lower() or 'key' in message.lower():
                    error_patterns["error_by_type"]["auth_error"] += 1
                elif 'rate' in message.lower() or 'limit' in message.lower():
                    error_patterns["error_by_type"]["rate_limit"] += 1
                else:
                    error_patterns["error_by_type"]["other"] += 1
                
                # æŒ‰å°æ—¶ç»Ÿè®¡
                try:
                    dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
                    hour = dt.hour
                    error_patterns["error_by_hour"][hour] += 1
                except:
                    pass
                
                # å¸¸è§é”™è¯¯æ¶ˆæ¯
                error_patterns["common_errors"][message[:100]] += 1
        
        # è®¡ç®—æˆåŠŸç‡
        for model, stats in model_stats.items():
            if stats["total"] > 0:
                success_rate = (stats["total"] - stats["errors"]) / stats["total"] * 100
                error_patterns["success_rate_by_model"][model] = {
                    "total_requests": stats["total"],
                    "errors": stats["errors"],
                    "success_rate": success_rate
                }
        
        return dict(error_patterns)
    
    def generate_comprehensive_report(self, days: int = 7) -> Dict[str, Any]:
        """ç”Ÿæˆç»¼åˆæŠ¥å‘Š"""
        print(f"ğŸ“Š ç”Ÿæˆæœ€è¿‘ {days} å¤©çš„ç»¼åˆåˆ†ææŠ¥å‘Š...")
        
        report = {
            "report_info": {
                "generated_at": datetime.now().isoformat(),
                "analysis_period_days": days,
                "report_version": "1.0.0"
            }
        }
        
        # åŸºç¡€ç»Ÿè®¡
        print("  ğŸ“ˆ è·å–åŸºç¡€ç»Ÿè®¡ä¿¡æ¯...")
        report["basic_stats"] = self.get_log_statistics(days)
        
        # æ€§èƒ½åˆ†æ
        print("  âš¡ åˆ†ææ€§èƒ½è¶‹åŠ¿...")
        report["performance_analysis"] = self.analyze_performance_trends(days)
        
        # é”™è¯¯åˆ†æ
        print("  ğŸš¨ åˆ†æé”™è¯¯æ¨¡å¼...")
        report["error_analysis"] = self.analyze_error_patterns(days)
        
        # ä½¿ç”¨æ¨¡å¼åˆ†æ
        print("  ğŸ“± åˆ†æä½¿ç”¨æ¨¡å¼...")
        report["usage_patterns"] = self.analyze_usage_patterns(days)
        
        return report
    
    def analyze_usage_patterns(self, days: int = 7) -> Dict[str, Any]:
        """åˆ†æä½¿ç”¨æ¨¡å¼"""
        all_logs = self.get_logs_by_type("all", limit=1000, days=days)
        
        if not all_logs:
            return {"error": "æ²¡æœ‰æ‰¾åˆ°æ—¥å¿—"}
        
        patterns = {
            "hourly_distribution": defaultdict(int),
            "daily_distribution": defaultdict(int),
            "model_popularity": defaultdict(int),
            "request_size_distribution": defaultdict(int),
            "peak_hours": [],
            "busiest_days": []
        }
        
        for log in all_logs:
            timestamp = log.get('timestamp', '')
            model = log.get('model', 'unknown')
            
            try:
                dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
                hour = dt.hour
                day = dt.strftime('%A')
                
                patterns["hourly_distribution"][hour] += 1
                patterns["daily_distribution"][day] += 1
                patterns["model_popularity"][model] += 1
                
                # è¯·æ±‚å¤§å°åˆ†æï¼ˆåŸºäºæ¶ˆæ¯é•¿åº¦ï¼‰
                message = log.get('message', '')
                if len(message) < 100:
                    patterns["request_size_distribution"]["small"] += 1
                elif len(message) < 500:
                    patterns["request_size_distribution"]["medium"] += 1
                else:
                    patterns["request_size_distribution"]["large"] += 1
                    
            except:
                continue
        
        # æ‰¾å‡ºå³°å€¼æ—¶é—´
        if patterns["hourly_distribution"]:
            sorted_hours = sorted(patterns["hourly_distribution"].items(), key=lambda x: x[1], reverse=True)
            patterns["peak_hours"] = sorted_hours[:3]
        
        # æ‰¾å‡ºæœ€å¿™çš„æ—¥å­
        if patterns["daily_distribution"]:
            sorted_days = sorted(patterns["daily_distribution"].items(), key=lambda x: x[1], reverse=True)
            patterns["busiest_days"] = sorted_days[:3]
        
        return dict(patterns)
    
    def interactive_log_browser(self):
        """äº¤äº’å¼æ—¥å¿—æµè§ˆå™¨"""
        print("ğŸ” è¿›å…¥äº¤äº’å¼æ—¥å¿—æµè§ˆæ¨¡å¼")
        print("=" * 60)
        print("å¯ç”¨å‘½ä»¤:")
        print("  1. stats [days] - æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯")
        print("  2. errors [days] - æ˜¾ç¤ºé”™è¯¯åˆ†æ")
        print("  3. performance [days] - æ˜¾ç¤ºæ€§èƒ½åˆ†æ")
        print("  4. model <model_name> [days] - æ˜¾ç¤ºç‰¹å®šæ¨¡å‹çš„æ—¥å¿—")
        print("  5. recent [limit] - æ˜¾ç¤ºæœ€è¿‘çš„æ—¥å¿—")
        print("  6. search <keyword> - æœç´¢åŒ…å«å…³é”®è¯çš„æ—¥å¿—")
        print("  7. export <filename> - å¯¼å‡ºåˆ†ææŠ¥å‘Š")
        print("  8. help - æ˜¾ç¤ºå¸®åŠ©")
        print("  9. quit - é€€å‡º")
        print("=" * 60)
        
        while True:
            try:
                command = input("\nğŸ” è¯·è¾“å…¥å‘½ä»¤: ").strip().lower()
                
                if command == "quit" or command == "exit":
                    print("ğŸ‘‹ é€€å‡ºäº¤äº’å¼æµè§ˆå™¨")
                    break
                elif command == "help":
                    self.show_interactive_help()
                elif command.startswith("stats"):
                    parts = command.split()
                    days = int(parts[1]) if len(parts) > 1 else 7
                    self.show_interactive_stats(days)
                elif command.startswith("errors"):
                    parts = command.split()
                    days = int(parts[1]) if len(parts) > 1 else 7
                    self.show_interactive_errors(days)
                elif command.startswith("performance"):
                    parts = command.split()
                    days = int(parts[1]) if len(parts) > 1 else 7
                    self.show_interactive_performance(days)
                elif command.startswith("model"):
                    parts = command.split()
                    if len(parts) < 2:
                        print("âŒ è¯·æŒ‡å®šæ¨¡å‹åç§°")
                        continue
                    model_name = parts[1]
                    days = int(parts[2]) if len(parts) > 2 else 7
                    self.show_model_logs(model_name, days)
                elif command.startswith("recent"):
                    parts = command.split()
                    limit = int(parts[1]) if len(parts) > 1 else 10
                    self.show_recent_logs(limit)
                elif command.startswith("search"):
                    parts = command.split(maxsplit=1)
                    if len(parts) < 2:
                        print("âŒ è¯·æŒ‡å®šæœç´¢å…³é”®è¯")
                        continue
                    keyword = parts[1]
                    self.search_logs(keyword)
                elif command.startswith("export"):
                    parts = command.split()
                    filename = parts[1] if len(parts) > 1 else f"log_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                    self.export_report(filename)
                else:
                    print("âŒ æœªçŸ¥å‘½ä»¤ï¼Œè¾“å…¥ 'help' æŸ¥çœ‹å¸®åŠ©")
                    
            except KeyboardInterrupt:
                print("\nğŸ‘‹ é€€å‡ºäº¤äº’å¼æµè§ˆå™¨")
                break
            except Exception as e:
                print(f"âŒ æ‰§è¡Œå‘½ä»¤æ—¶å‡ºé”™: {e}")
    
    def show_interactive_help(self):
        """æ˜¾ç¤ºäº¤äº’å¼å¸®åŠ©"""
        print("\nğŸ“š äº¤äº’å¼æ—¥å¿—æµè§ˆå™¨å¸®åŠ©")
        print("=" * 50)
        print("å‘½ä»¤æ ¼å¼:")
        print("  stats [days]           - æ˜¾ç¤ºæŒ‡å®šå¤©æ•°çš„ç»Ÿè®¡ä¿¡æ¯ (é»˜è®¤7å¤©)")
        print("  errors [days]          - æ˜¾ç¤ºé”™è¯¯åˆ†æ (é»˜è®¤7å¤©)")
        print("  performance [days]     - æ˜¾ç¤ºæ€§èƒ½åˆ†æ (é»˜è®¤7å¤©)")
        print("  model <name> [days]    - æ˜¾ç¤ºç‰¹å®šæ¨¡å‹çš„æ—¥å¿—")
        print("  recent [limit]         - æ˜¾ç¤ºæœ€è¿‘çš„æ—¥å¿— (é»˜è®¤10æ¡)")
        print("  search <keyword>       - æœç´¢åŒ…å«å…³é”®è¯çš„æ—¥å¿—")
        print("  export [filename]      - å¯¼å‡ºå®Œæ•´åˆ†ææŠ¥å‘Š")
        print("  help                   - æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯")
        print("  quit/exit              - é€€å‡ºæµè§ˆå™¨")
        print("\nç¤ºä¾‹:")
        print("  stats 3                - æ˜¾ç¤ºæœ€è¿‘3å¤©çš„ç»Ÿè®¡")
        print("  model deepseek-chat 1  - æ˜¾ç¤ºdeepseek-chatæ¨¡å‹æœ€è¿‘1å¤©çš„æ—¥å¿—")
        print("  search error           - æœç´¢åŒ…å«'error'çš„æ—¥å¿—")
        print("  export my_report.json  - å¯¼å‡ºæŠ¥å‘Šåˆ°my_report.json")
    
    def show_interactive_stats(self, days: int):
        """æ˜¾ç¤ºäº¤äº’å¼ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.get_log_statistics(days)
        if stats:
            print(f"\nğŸ“Š æœ€è¿‘ {days} å¤©çš„ç»Ÿè®¡ä¿¡æ¯:")
            print(json.dumps(stats, indent=2, ensure_ascii=False))
        else:
            print("âŒ æ— æ³•è·å–ç»Ÿè®¡ä¿¡æ¯")
    
    def show_interactive_errors(self, days: int):
        """æ˜¾ç¤ºäº¤äº’å¼é”™è¯¯åˆ†æ"""
        errors = self.analyze_error_patterns(days)
        if errors and "error" not in errors:
            print(f"\nğŸš¨ æœ€è¿‘ {days} å¤©çš„é”™è¯¯åˆ†æ:")
            print(f"æ€»è¯·æ±‚æ•°: {errors.get('total_requests', 0)}")
            print(f"æ€»é”™è¯¯æ•°: {errors.get('total_errors', 0)}")
            
            if errors.get('total_requests', 0) > 0:
                error_rate = errors.get('total_errors', 0) / errors.get('total_requests', 1) * 100
                print(f"é”™è¯¯ç‡: {error_rate:.2f}%")
            
            print("\næŒ‰æ¨¡å‹åˆ†ç»„çš„é”™è¯¯:")
            for model, count in errors.get('error_by_model', {}).items():
                print(f"  {model}: {count}")
            
            print("\né”™è¯¯ç±»å‹åˆ†å¸ƒ:")
            for error_type, count in errors.get('error_by_type', {}).items():
                print(f"  {error_type}: {count}")
        else:
            print("âŒ æ— æ³•è·å–é”™è¯¯åˆ†ææˆ–æ²¡æœ‰é”™è¯¯æ•°æ®")
    
    def show_interactive_performance(self, days: int):
        """æ˜¾ç¤ºäº¤äº’å¼æ€§èƒ½åˆ†æ"""
        perf = self.analyze_performance_trends(days)
        if perf and "error" not in perf:
            print(f"\nâš¡ æœ€è¿‘ {days} å¤©çš„æ€§èƒ½åˆ†æ:")
            
            overall = perf.get('overall_stats', {})
            if overall:
                print(f"æ€»è¯·æ±‚æ•°: {overall.get('total_requests', 0)}")
                print(f"å¹³å‡å“åº”æ—¶é—´: {overall.get('avg_response_time', 0):.3f}s")
                print(f"ä¸­ä½æ•°å“åº”æ—¶é—´: {overall.get('median_response_time', 0):.3f}s")
                print(f"95%åˆ†ä½æ•°: {overall.get('p95_response_time', 0):.3f}s")
            
            print("\næŒ‰æ¨¡å‹åˆ†ç»„çš„æ€§èƒ½:")
            for model, stats in perf.get('model_performance', {}).items():
                print(f"  {model}:")
                print(f"    è¯·æ±‚æ•°: {stats.get('count', 0)}")
                print(f"    å¹³å‡å“åº”æ—¶é—´: {stats.get('avg_response_time', 0):.3f}s")
                print(f"    ä¸­ä½æ•°: {stats.get('median_response_time', 0):.3f}s")
        else:
            print("âŒ æ— æ³•è·å–æ€§èƒ½åˆ†ææˆ–æ²¡æœ‰æ€§èƒ½æ•°æ®")
    
    def show_model_logs(self, model_name: str, days: int):
        """æ˜¾ç¤ºç‰¹å®šæ¨¡å‹çš„æ—¥å¿—"""
        success, stdout, stderr = self.run_view_logs_command([
            "--model", model_name,
            "--days", str(days),
            "--limit", "10"
        ])
        
        if success:
            print(f"\nğŸ“± æ¨¡å‹ {model_name} æœ€è¿‘ {days} å¤©çš„æ—¥å¿—:")
            print(stdout)
        else:
            print(f"âŒ è·å–æ¨¡å‹ {model_name} çš„æ—¥å¿—å¤±è´¥: {stderr}")
    
    def show_recent_logs(self, limit: int):
        """æ˜¾ç¤ºæœ€è¿‘çš„æ—¥å¿—"""
        success, stdout, stderr = self.run_view_logs_command([
            "--limit", str(limit)
        ])
        
        if success:
            print(f"\nğŸ“‹ æœ€è¿‘ {limit} æ¡æ—¥å¿—:")
            print(stdout)
        else:
            print(f"âŒ è·å–æœ€è¿‘æ—¥å¿—å¤±è´¥: {stderr}")
    
    def search_logs(self, keyword: str):
        """æœç´¢æ—¥å¿—"""
        # è·å–æ‰€æœ‰æ—¥å¿—å¹¶æœç´¢
        all_logs = self.get_logs_by_type("all", limit=500, days=7)
        
        matching_logs = []
        for log in all_logs:
            message = log.get('message', '').lower()
            if keyword.lower() in message:
                matching_logs.append(log)
        
        if matching_logs:
            print(f"\nğŸ” æ‰¾åˆ° {len(matching_logs)} æ¡åŒ…å« '{keyword}' çš„æ—¥å¿—:")
            for i, log in enumerate(matching_logs[:10], 1):  # åªæ˜¾ç¤ºå‰10æ¡
                timestamp = log.get('timestamp', 'N/A')
                model = log.get('model', 'unknown')
                message = log.get('message', '')[:100]  # æˆªæ–­é•¿æ¶ˆæ¯
                print(f"  [{i}] {timestamp} | {model} | {message}")
            
            if len(matching_logs) > 10:
                print(f"  ... è¿˜æœ‰ {len(matching_logs) - 10} æ¡åŒ¹é…çš„æ—¥å¿—")
        else:
            print(f"âŒ æ²¡æœ‰æ‰¾åˆ°åŒ…å« '{keyword}' çš„æ—¥å¿—")
    
    def export_report(self, filename: str):
        """å¯¼å‡ºåˆ†ææŠ¥å‘Š"""
        try:
            print(f"ğŸ“¤ æ­£åœ¨ç”Ÿæˆå¹¶å¯¼å‡ºæŠ¥å‘Šåˆ° {filename}...")
            report = self.generate_comprehensive_report(days=7)
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            
            print(f"âœ… æŠ¥å‘Šå·²æˆåŠŸå¯¼å‡ºåˆ° {filename}")
            print(f"ğŸ“Š æŠ¥å‘ŠåŒ…å«:")
            print(f"  - åŸºç¡€ç»Ÿè®¡ä¿¡æ¯")
            print(f"  - æ€§èƒ½åˆ†æ")
            print(f"  - é”™è¯¯æ¨¡å¼åˆ†æ")
            print(f"  - ä½¿ç”¨æ¨¡å¼åˆ†æ")
            
        except Exception as e:
            print(f"âŒ å¯¼å‡ºæŠ¥å‘Šå¤±è´¥: {e}")


def run_demo_suite():
    """è¿è¡Œæ¼”ç¤ºå¥—ä»¶"""
    print("ğŸš€ HarborAI é«˜çº§æ—¥å¿—åˆ†æå·¥å…·æ¼”ç¤ºå¥—ä»¶")
    print("=" * 60)
    
    analyzer = LogAnalyzer()
    
    demos = [
        {
            "name": "åŸºç¡€æ—¥å¿—æŸ¥çœ‹åŠŸèƒ½",
            "func": lambda: demo_basic_log_viewing(analyzer)
        },
        {
            "name": "æ€§èƒ½è¶‹åŠ¿åˆ†æ",
            "func": lambda: demo_performance_analysis(analyzer)
        },
        {
            "name": "é”™è¯¯æ¨¡å¼è¯†åˆ«",
            "func": lambda: demo_error_analysis(analyzer)
        },
        {
            "name": "ä½¿ç”¨æ¨¡å¼åˆ†æ",
            "func": lambda: demo_usage_patterns(analyzer)
        },
        {
            "name": "ç»¼åˆæŠ¥å‘Šç”Ÿæˆ",
            "func": lambda: demo_comprehensive_report(analyzer)
        }
    ]
    
    for i, demo in enumerate(demos, 1):
        print(f"\nğŸ“‹ æ¼”ç¤º {i}/{len(demos)}: {demo['name']}")
        print("-" * 40)
        
        try:
            demo['func']()
        except Exception as e:
            print(f"âŒ æ¼”ç¤ºå¤±è´¥: {e}")
        
        if i < len(demos):
            input("\næŒ‰ Enter é”®ç»§ç»­ä¸‹ä¸€ä¸ªæ¼”ç¤º...")
    
    print(f"\n{'='*60}")
    print("ğŸ‰ æ¼”ç¤ºå¥—ä»¶å®Œæˆï¼")
    print("ğŸ’¡ æç¤º: ä½¿ç”¨ --interactive å‚æ•°å¯åŠ¨äº¤äº’å¼æµè§ˆå™¨")


def demo_log_types(analyzer: LogAnalyzer):
    """æ¼”ç¤ºæ—¥å¿—ç±»å‹åˆ†æ"""
    print("ğŸ“Š æ—¥å¿—ç±»å‹åˆ†ææ¼”ç¤º")
    print("-" * 40)
    
    # è·å–å„ç§ç±»å‹çš„æ—¥å¿—
    log_types = ['request', 'response', 'paired']
    
    for log_type in log_types:
        print(f"\nğŸ” åˆ†æ {log_type.upper()} ç±»å‹æ—¥å¿—:")
        logs = analyzer.get_logs_by_type(log_type, limit=5)
        
        if logs:
            print(f"   âœ… æ‰¾åˆ° {len(logs)} æ¡ {log_type} æ—¥å¿—")
            # æ˜¾ç¤ºæœ€æ–°çš„ä¸€æ¡æ—¥å¿—æ‘˜è¦
            latest = logs[0] if logs else None
            if latest:
                print(f"   ğŸ“ æœ€æ–°è®°å½•: {latest.get('timestamp', 'N/A')}")
                print(f"   ğŸ¤– æ¨¡å‹: {latest.get('model', 'unknown')}")
                print(f"   ğŸ¢ æä¾›å•†: {latest.get('provider', 'unknown')}")
        else:
            print(f"   âŒ æœªæ‰¾åˆ° {log_type} ç±»å‹çš„æ—¥å¿—")
    
    print("\nâœ… æ—¥å¿—ç±»å‹åˆ†æå®Œæˆ")


def demo_basic_log_viewing(analyzer: LogAnalyzer):
    """æ¼”ç¤ºåŸºç¡€æ—¥å¿—æŸ¥çœ‹åŠŸèƒ½"""
    print("ğŸ” æ¼”ç¤ºåŸºç¡€æ—¥å¿—æŸ¥çœ‹åŠŸèƒ½...")
    
    # æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
    success, stdout, stderr = analyzer.run_view_logs_command(["--help"])
    if success:
        print("ğŸ“š view_logs.py å¸®åŠ©ä¿¡æ¯:")
        print(stdout[:500] + "..." if len(stdout) > 500 else stdout)
    
    # æ˜¾ç¤ºä¸åŒç±»å‹çš„æ—¥å¿—
    log_types = ["all", "request", "response", "paired"]
    
    for log_type in log_types:
        print(f"\nğŸ“‹ æ˜¾ç¤º {log_type} ç±»å‹çš„æ—¥å¿— (å‰3æ¡):")
        success, stdout, stderr = analyzer.run_view_logs_command([
            "--type", log_type, "--limit", "3"
        ])
        if success and stdout.strip():
            print(stdout)
        else:
            print(f"  æ²¡æœ‰æ‰¾åˆ° {log_type} ç±»å‹çš„æ—¥å¿—")


def demo_performance_analysis(analyzer: LogAnalyzer):
    """æ¼”ç¤ºæ€§èƒ½åˆ†æ"""
    print("âš¡ æ¼”ç¤ºæ€§èƒ½è¶‹åŠ¿åˆ†æ...")
    
    analysis = analyzer.analyze_performance_trends(days=7)
    
    if "error" in analysis:
        print(f"âŒ {analysis['error']}")
        return
    
    overall = analysis.get('overall_stats', {})
    if overall:
        print("ğŸ“Š æ€»ä½“æ€§èƒ½ç»Ÿè®¡:")
        print(f"  æ€»è¯·æ±‚æ•°: {overall.get('total_requests', 0)}")
        print(f"  å¹³å‡å“åº”æ—¶é—´: {overall.get('avg_response_time', 0):.3f}s")
        print(f"  ä¸­ä½æ•°å“åº”æ—¶é—´: {overall.get('median_response_time', 0):.3f}s")
        print(f"  95%åˆ†ä½æ•°: {overall.get('p95_response_time', 0):.3f}s")
        print(f"  æœ€å¿«å“åº”: {overall.get('fastest_response', 0):.3f}s")
        print(f"  æœ€æ…¢å“åº”: {overall.get('slowest_response', 0):.3f}s")
    
    model_perf = analysis.get('model_performance', {})
    if model_perf:
        print("\nğŸ“± æŒ‰æ¨¡å‹åˆ†ç»„çš„æ€§èƒ½:")
        for model, stats in list(model_perf.items())[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
            print(f"  {model}:")
            print(f"    è¯·æ±‚æ•°: {stats.get('count', 0)}")
            print(f"    å¹³å‡å“åº”æ—¶é—´: {stats.get('avg_response_time', 0):.3f}s")
            print(f"    æ ‡å‡†å·®: {stats.get('std_dev', 0):.3f}s")


def demo_error_analysis(analyzer: LogAnalyzer):
    """æ¼”ç¤ºé”™è¯¯åˆ†æ"""
    print("ğŸš¨ æ¼”ç¤ºé”™è¯¯æ¨¡å¼è¯†åˆ«...")
    
    analysis = analyzer.analyze_error_patterns(days=7)
    
    if "error" in analysis:
        print(f"âŒ {analysis['error']}")
        return
    
    print("ğŸ“Š é”™è¯¯ç»Ÿè®¡æ¦‚è§ˆ:")
    print(f"  æ€»è¯·æ±‚æ•°: {analysis.get('total_requests', 0)}")
    print(f"  æ€»é”™è¯¯æ•°: {analysis.get('total_errors', 0)}")
    
    if analysis.get('total_requests', 0) > 0:
        error_rate = analysis.get('total_errors', 0) / analysis.get('total_requests', 1) * 100
        print(f"  é”™è¯¯ç‡: {error_rate:.2f}%")
    
    # æŒ‰æ¨¡å‹åˆ†ç»„çš„æˆåŠŸç‡
    success_rates = analysis.get('success_rate_by_model', {})
    if success_rates:
        print("\nğŸ“± æŒ‰æ¨¡å‹åˆ†ç»„çš„æˆåŠŸç‡:")
        for model, stats in list(success_rates.items())[:5]:
            print(f"  {model}: {stats.get('success_rate', 0):.1f}% ({stats.get('errors', 0)}/{stats.get('total_requests', 0)})")
    
    # é”™è¯¯ç±»å‹åˆ†å¸ƒ
    error_types = analysis.get('error_by_type', {})
    if error_types:
        print("\nğŸ·ï¸ é”™è¯¯ç±»å‹åˆ†å¸ƒ:")
        for error_type, count in error_types.items():
            print(f"  {error_type}: {count}")


def demo_usage_patterns(analyzer: LogAnalyzer):
    """æ¼”ç¤ºä½¿ç”¨æ¨¡å¼åˆ†æ"""
    print("ğŸ“± æ¼”ç¤ºä½¿ç”¨æ¨¡å¼åˆ†æ...")
    
    patterns = analyzer.analyze_usage_patterns(days=7)
    
    if "error" in patterns:
        print(f"âŒ {patterns['error']}")
        return
    
    # æ¨¡å‹æµè¡Œåº¦
    model_popularity = patterns.get('model_popularity', {})
    if model_popularity:
        print("ğŸ“Š æ¨¡å‹ä½¿ç”¨é¢‘ç‡:")
        sorted_models = sorted(model_popularity.items(), key=lambda x: x[1], reverse=True)
        for model, count in sorted_models[:5]:
            print(f"  {model}: {count} æ¬¡")
    
    # å³°å€¼æ—¶é—´
    peak_hours = patterns.get('peak_hours', [])
    if peak_hours:
        print("\nâ° ä½¿ç”¨å³°å€¼æ—¶é—´:")
        for hour, count in peak_hours:
            print(f"  {hour:02d}:00 - {count} æ¬¡è¯·æ±‚")
    
    # æœ€å¿™çš„æ—¥å­
    busiest_days = patterns.get('busiest_days', [])
    if busiest_days:
        print("\nğŸ“… æœ€å¿™çš„æ—¥å­:")
        for day, count in busiest_days:
            print(f"  {day}: {count} æ¬¡è¯·æ±‚")


def demo_comprehensive_report(analyzer: LogAnalyzer):
    """æ¼”ç¤ºç»¼åˆæŠ¥å‘Šç”Ÿæˆ"""
    print("ğŸ“Š æ¼”ç¤ºç»¼åˆæŠ¥å‘Šç”Ÿæˆ...")
    
    report = analyzer.generate_comprehensive_report(days=3)  # ä½¿ç”¨è¾ƒçŸ­æ—¶é—´ä»¥åŠ å¿«æ¼”ç¤º
    
    print("âœ… ç»¼åˆæŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
    print("\nğŸ“‹ æŠ¥å‘ŠåŒ…å«ä»¥ä¸‹éƒ¨åˆ†:")
    
    for section, data in report.items():
        if section == "report_info":
            continue
        
        print(f"  ğŸ“Œ {section}")
        if isinstance(data, dict) and data:
            # æ˜¾ç¤ºæ¯ä¸ªéƒ¨åˆ†çš„ç®€è¦ä¿¡æ¯
            if "total_requests" in data:
                print(f"     æ€»è¯·æ±‚æ•°: {data['total_requests']}")
            if "total_errors" in data:
                print(f"     æ€»é”™è¯¯æ•°: {data['total_errors']}")
            if "overall_stats" in data and data["overall_stats"]:
                stats = data["overall_stats"]
                if "avg_response_time" in stats:
                    print(f"     å¹³å‡å“åº”æ—¶é—´: {stats['avg_response_time']:.3f}s")
    
    # ä¿å­˜æŠ¥å‘Šç¤ºä¾‹
    filename = f"demo_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        print(f"\nğŸ’¾ æ¼”ç¤ºæŠ¥å‘Šå·²ä¿å­˜åˆ°: {filename}")
    except Exception as e:
        print(f"âŒ ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")


def demo_new_logging_features(analyzer: LogAnalyzer):
    """æ¼”ç¤ºæ–°çš„æ—¥å¿—åŠŸèƒ½ç‰¹æ€§"""
    print("ğŸ†• æ¼”ç¤ºæ–°çš„æ—¥å¿—åŠŸèƒ½ç‰¹æ€§...")
    
    # æ¼”ç¤ºå¸ƒå±€æ¨¡å¼
    print("\nğŸ“ æ¼”ç¤ºå¸ƒå±€æ¨¡å¼:")
    layouts = ["classic", "enhanced"]
    
    for layout in layouts:
        print(f"\n  ğŸ¨ {layout.upper()} å¸ƒå±€æ¨¡å¼:")
        success, stdout, stderr = analyzer.run_view_logs_command([
            "--layout", layout, "--limit", "2"
        ])
        if success and stdout.strip():
            print(stdout)
        else:
            print(f"    æ²¡æœ‰æ‰¾åˆ°æ—¥å¿—æ•°æ®")
    
    # æ¼”ç¤º trace_id æŸ¥è¯¢ (hb_ å‰ç¼€)
    print("\nğŸ” æ¼”ç¤º trace_id æŸ¥è¯¢åŠŸèƒ½:")
    
    # é¦–å…ˆè·å–ä¸€äº› trace_id
    success, stdout, stderr = analyzer.run_view_logs_command([
        "--limit", "5", "--json"
    ])
    
    if success and stdout.strip():
        try:
            import json
            # æå–JSONéƒ¨åˆ†ï¼Œå¿½ç•¥æ—¥å¿—å‰ç¼€
            json_content = analyzer._extract_json_content(stdout)
            if json_content:
                logs = json.loads(json_content)
                # ç¡®ä¿logsæ˜¯åˆ—è¡¨æ ¼å¼
                if isinstance(logs, dict):
                    logs = logs.get('data', logs.get('logs', []))
                elif not isinstance(logs, list):
                    logs = []
            else:
                logs = []
            trace_ids = []
            
            for log in logs:
                if isinstance(log, dict) and 'trace_id' in log:
                    trace_id = log['trace_id']
                    if trace_id and trace_id.startswith('hb_'):
                        trace_ids.append(trace_id)
            
            if trace_ids:
                # ä½¿ç”¨ç¬¬ä¸€ä¸ª trace_id è¿›è¡ŒæŸ¥è¯¢æ¼”ç¤º
                test_trace_id = trace_ids[0]
                print(f"  ğŸ¯ æŸ¥è¯¢ trace_id: {test_trace_id}")
                
                success, stdout, stderr = analyzer.run_view_logs_command([
                    "--trace-id", test_trace_id
                ])
                
                if success and stdout.strip():
                    print(stdout)
                else:
                    print(f"    æœªæ‰¾åˆ° trace_id {test_trace_id} çš„ç›¸å…³æ—¥å¿—")
            else:
                print("    æ²¡æœ‰æ‰¾åˆ°å¸¦æœ‰ hb_ å‰ç¼€çš„ trace_id")
                
        except json.JSONDecodeError:
            print("    JSON è§£æå¤±è´¥")
    else:
        print("    æ— æ³•è·å–æ—¥å¿—æ•°æ®è¿›è¡Œ trace_id æ¼”ç¤º")
    
    # æ¼”ç¤ºé…å¯¹æ˜¾ç¤º
    print("\nğŸ‘¥ æ¼”ç¤ºé…å¯¹æ˜¾ç¤ºåŠŸèƒ½:")
    success, stdout, stderr = analyzer.run_view_logs_command([
        "--type", "paired", "--limit", "3"
    ])
    if success and stdout.strip():
        print(stdout)
    else:
        print("    æ²¡æœ‰æ‰¾åˆ°é…å¯¹çš„æ—¥å¿—æ•°æ®")
    
    # æ¼”ç¤º JSON è¾“å‡º
    print("\nğŸ“„ æ¼”ç¤º JSON æ ¼å¼è¾“å‡º:")
    success, stdout, stderr = analyzer.run_view_logs_command([
        "--json", "--limit", "2"
    ])
    if success and stdout.strip():
        try:
            import json
            # æå–JSONéƒ¨åˆ†ï¼Œå¿½ç•¥æ—¥å¿—å‰ç¼€
            json_content = analyzer._extract_json_content(stdout)
            if json_content:
                logs = json.loads(json_content)
                # ç¡®ä¿logsæ˜¯åˆ—è¡¨æ ¼å¼
                if isinstance(logs, dict):
                    logs = logs.get('data', logs.get('logs', []))
                elif not isinstance(logs, list):
                    logs = []
            else:
                logs = []
            print(f"    è·å–åˆ° {len(logs)} æ¡æ—¥å¿—è®°å½•")
            if logs:
                print("    ç¤ºä¾‹æ—¥å¿—ç»“æ„:")
                sample_log = logs[0]
                for key in ['timestamp', 'level', 'trace_id', 'type']:
                    if key in sample_log:
                        print(f"      {key}: {sample_log[key]}")
        except json.JSONDecodeError:
            print("    JSON è§£æå¤±è´¥")
            print(stdout[:200] + "..." if len(stdout) > 200 else stdout)
    else:
        print("    æ— æ³•è·å– JSON æ ¼å¼çš„æ—¥å¿—æ•°æ®")


def demo_trace_id_optimization():
    """æ¼”ç¤º trace_id ä¼˜åŒ–åŠŸèƒ½"""
    print("ğŸ”§ æ¼”ç¤º trace_id ä¼˜åŒ–åŠŸèƒ½...")
    
    # æ£€æŸ¥æœ€è¿‘çš„æ—¥å¿—æ–‡ä»¶ä¸­æ˜¯å¦æœ‰æ–°æ ¼å¼çš„ trace_id
    import os
    import glob
    from datetime import datetime, timedelta
    
    log_dir = "logs"
    if not os.path.exists(log_dir):
        print("    æ—¥å¿—ç›®å½•ä¸å­˜åœ¨ï¼Œæ— æ³•æ¼”ç¤º trace_id ä¼˜åŒ–")
        return
    
    # æŸ¥æ‰¾æœ€è¿‘å‡ å¤©çš„æ—¥å¿—æ–‡ä»¶
    recent_files = []
    for i in range(3):  # æ£€æŸ¥æœ€è¿‘3å¤©
        date_str = (datetime.now() - timedelta(days=i)).strftime("%Y%m%d")
        pattern = f"{log_dir}/harborai_{date_str}.jsonl"
        files = glob.glob(pattern)
        recent_files.extend(files)
    
    if not recent_files:
        print("    æ²¡æœ‰æ‰¾åˆ°æœ€è¿‘çš„æ—¥å¿—æ–‡ä»¶")
        return
    
    # ç»Ÿè®¡ trace_id æ ¼å¼
    hb_prefix_count = 0
    old_format_count = 0
    total_count = 0
    
    for file_path in recent_files[:2]:  # åªæ£€æŸ¥å‰2ä¸ªæ–‡ä»¶
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        try:
                            import json
                            log_entry = json.loads(line)
                            if 'trace_id' in log_entry:
                                trace_id = log_entry['trace_id']
                                total_count += 1
                                if trace_id and trace_id.startswith('hb_'):
                                    hb_prefix_count += 1
                                else:
                                    old_format_count += 1
                        except json.JSONDecodeError:
                            continue
        except Exception as e:
            print(f"    è¯»å–æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
    
    if total_count > 0:
        print(f"    ğŸ“Š trace_id æ ¼å¼ç»Ÿè®¡:")
        print(f"      æ€»æ•°: {total_count}")
        print(f"      æ–°æ ¼å¼ (hb_ å‰ç¼€): {hb_prefix_count} ({hb_prefix_count/total_count*100:.1f}%)")
        print(f"      æ—§æ ¼å¼: {old_format_count} ({old_format_count/total_count*100:.1f}%)")
        
        if hb_prefix_count > 0:
            print("    âœ… æ£€æµ‹åˆ°æ–°çš„ hb_ å‰ç¼€ trace_id æ ¼å¼")
        else:
            print("    âš ï¸ æœªæ£€æµ‹åˆ°æ–°çš„ hb_ å‰ç¼€ trace_id æ ¼å¼")
    else:
        print("    æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„ trace_id æ•°æ®")


def run_demo_suite():
    """è¿è¡Œå®Œæ•´çš„æ¼”ç¤ºå¥—ä»¶"""
    print("ğŸš€ å¯åŠ¨ HarborAI é«˜çº§æ—¥å¿—åˆ†ææ¼”ç¤ºå¥—ä»¶")
    print("=" * 60)
    
    analyzer = LogAnalyzer()
    
    # åŸºç¡€åŠŸèƒ½æ¼”ç¤º
    demo_log_types(analyzer)
    print("\n" + "=" * 60)
    
    # æ€§èƒ½åˆ†ææ¼”ç¤º
    demo_performance_analysis(analyzer)
    print("\n" + "=" * 60)
    
    # é”™è¯¯åˆ†ææ¼”ç¤º
    demo_error_analysis(analyzer)
    print("\n" + "=" * 60)
    
    # ä½¿ç”¨æ¨¡å¼åˆ†ææ¼”ç¤º
    demo_usage_patterns(analyzer)
    print("\n" + "=" * 60)
    
    # æ–°åŠŸèƒ½æ¼”ç¤º
    demo_new_logging_features(analyzer)
    print("\n" + "=" * 60)
    
    # trace_id ä¼˜åŒ–æ¼”ç¤º
    demo_trace_id_optimization()
    print("\n" + "=" * 60)
    
    # ç»¼åˆæŠ¥å‘Šæ¼”ç¤º
    demo_comprehensive_report(analyzer)
    
    print("\nğŸ‰ æ¼”ç¤ºå¥—ä»¶è¿è¡Œå®Œæˆï¼")
    print("ğŸ’¡ æç¤º: ä½¿ç”¨ --interactive å‚æ•°å¯åŠ¨äº¤äº’å¼æ—¥å¿—æµè§ˆå™¨")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="HarborAI é«˜çº§æ—¥å¿—åˆ†æå·¥å…·")
    parser.add_argument("--interactive", "-i", action="store_true", help="å¯åŠ¨äº¤äº’å¼æ—¥å¿—æµè§ˆå™¨")
    parser.add_argument("--demo", "-d", action="store_true", help="è¿è¡Œæ¼”ç¤ºå¥—ä»¶")
    parser.add_argument("--new-features", action="store_true", help="æ¼”ç¤ºæ–°çš„æ—¥å¿—åŠŸèƒ½ç‰¹æ€§")
    parser.add_argument("--trace-id-demo", action="store_true", help="æ¼”ç¤º trace_id ä¼˜åŒ–åŠŸèƒ½")
    parser.add_argument("--stats", "-s", type=int, default=7, help="æ˜¾ç¤ºæŒ‡å®šå¤©æ•°çš„ç»Ÿè®¡ä¿¡æ¯")
    parser.add_argument("--performance", "-p", type=int, help="åˆ†ææŒ‡å®šå¤©æ•°çš„æ€§èƒ½è¶‹åŠ¿")
    parser.add_argument("--errors", "-e", type=int, help="åˆ†ææŒ‡å®šå¤©æ•°çš„é”™è¯¯æ¨¡å¼")
    parser.add_argument("--report", "-r", help="ç”Ÿæˆç»¼åˆæŠ¥å‘Šå¹¶ä¿å­˜åˆ°æŒ‡å®šæ–‡ä»¶")
    parser.add_argument("--days", type=int, default=7, help="åˆ†æå¤©æ•° (é»˜è®¤7å¤©)")
    
    args = parser.parse_args()
    
    try:
        analyzer = LogAnalyzer()
        
        if args.interactive:
            analyzer.interactive_log_browser()
        elif args.demo:
            run_demo_suite()
        elif args.new_features:
            demo_new_logging_features(analyzer)
        elif args.trace_id_demo:
            demo_trace_id_optimization()
        elif args.performance is not None:
            analysis = analyzer.analyze_performance_trends(args.performance)
            print(json.dumps(analysis, indent=2, ensure_ascii=False))
        elif args.errors is not None:
            analysis = analyzer.analyze_error_patterns(args.errors)
            print(json.dumps(analysis, indent=2, ensure_ascii=False))
        elif args.report:
            report = analyzer.generate_comprehensive_report(args.days)
            with open(args.report, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜åˆ°: {args.report}")
        else:
            # é»˜è®¤æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            stats = analyzer.get_log_statistics(args.stats)
            if stats:
                print(json.dumps(stats, indent=2, ensure_ascii=False))
            else:
                print("âŒ æ— æ³•è·å–ç»Ÿè®¡ä¿¡æ¯")
                
    except FileNotFoundError as e:
        print(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
        print("ğŸ’¡ è¯·ç¡®ä¿åœ¨ HarborAI é¡¹ç›®æ ¹ç›®å½•ä¸‹è¿è¡Œæ­¤è„šæœ¬")
        sys.exit(1)
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(0)
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()