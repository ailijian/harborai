#!/usr/bin/env python3
"""
é…ç½®ç®¡ç†åŠ©æ‰‹

è¿™ä¸ªç¤ºä¾‹å±•ç¤ºäº† HarborAI çš„é…ç½®ç®¡ç†åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
1. å¤šæ¨¡å‹é…ç½®ç®¡ç†
2. ç¯å¢ƒå˜é‡é…ç½®
3. åŠ¨æ€é…ç½®åˆ‡æ¢
4. é…ç½®éªŒè¯å’Œæµ‹è¯•
5. æœ€ä½³å®è·µç¤ºä¾‹

åœºæ™¯ï¼š
- å¤šç¯å¢ƒéƒ¨ç½²ï¼ˆå¼€å‘ã€æµ‹è¯•ã€ç”Ÿäº§ï¼‰
- å¤šæ¨¡å‹ä¾›åº”å•†ç®¡ç†
- åŠ¨æ€é…ç½®åˆ‡æ¢
- é…ç½®å®‰å…¨ç®¡ç†

ä»·å€¼ï¼š
- ç®€åŒ–é…ç½®ç®¡ç†æµç¨‹
- æé«˜é…ç½®å®‰å…¨æ€§
- æ”¯æŒå¤šç¯å¢ƒéƒ¨ç½²
- é™ä½é…ç½®é”™è¯¯é£é™©
"""

import os
import json
import asyncio
import logging
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass
from enum import Enum

# æ­£ç¡®çš„ HarborAI å¯¼å…¥æ–¹å¼
from harborai import HarborAI

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class ModelProvider(Enum):
    """æ¨¡å‹ä¾›åº”å•†æšä¸¾"""
    DEEPSEEK = "deepseek"
    ERNIE = "ernie"
    DOUBAO = "doubao"
    OPENAI = "openai"

@dataclass
class ModelConfig:
    """æ¨¡å‹é…ç½®"""
    provider: ModelProvider
    model_name: str
    api_key_env: str
    base_url_env: str
    default_base_url: str
    description: str
    max_tokens: int = 4096
    temperature: float = 0.7
    timeout: float = 30.0

class ConfigManager:
    """é…ç½®ç®¡ç†å™¨"""
    
    def __init__(self):
        self.configs = self._load_default_configs()
        self.current_config: Optional[ModelConfig] = None
        self.client: Optional[HarborAI] = None
    
    def _load_default_configs(self) -> Dict[ModelProvider, ModelConfig]:
        """åŠ è½½é»˜è®¤é…ç½®"""
        return {
            ModelProvider.DEEPSEEK: ModelConfig(
                provider=ModelProvider.DEEPSEEK,
                model_name="deepseek-chat",
                api_key_env="DEEPSEEK_API_KEY",
                base_url_env="DEEPSEEK_BASE_URL",
                default_base_url="https://api.deepseek.com",
                description="DeepSeek èŠå¤©æ¨¡å‹ - é«˜æ€§ä»·æ¯”ï¼Œæ”¯æŒä¸­æ–‡",
                max_tokens=8192,
                temperature=0.7,
                timeout=30.0
            ),
            ModelProvider.ERNIE: ModelConfig(
                provider=ModelProvider.ERNIE,
                model_name="ernie-3.5-8k",
                api_key_env="ERNIE_API_KEY",
                base_url_env="ERNIE_BASE_URL",
                default_base_url="https://aip.baidubce.com",
                description="ç™¾åº¦æ–‡å¿ƒä¸€è¨€ - ä¸­æ–‡ä¼˜åŒ–ï¼Œä¼ä¸šçº§",
                max_tokens=8192,
                temperature=0.7,
                timeout=30.0
            ),
            ModelProvider.DOUBAO: ModelConfig(
                provider=ModelProvider.DOUBAO,
                model_name="doubao-1-5-pro-32k-character-250715",
                api_key_env="DOUBAO_API_KEY",
                base_url_env="DOUBAO_BASE_URL",
                default_base_url="https://ark.cn-beijing.volces.com",
                description="å­—èŠ‚è·³åŠ¨è±†åŒ… - é•¿ä¸Šä¸‹æ–‡ï¼Œå¤šæ¨¡æ€",
                max_tokens=32768,
                temperature=0.7,
                timeout=45.0
            ),
            ModelProvider.OPENAI: ModelConfig(
                provider=ModelProvider.OPENAI,
                model_name="gpt-3.5-turbo",
                api_key_env="OPENAI_API_KEY",
                base_url_env="OPENAI_BASE_URL",
                default_base_url="https://api.openai.com/v1",
                description="OpenAI GPT-3.5 - é€šç”¨æ¨¡å‹ï¼Œå¹¿æ³›æ”¯æŒ",
                max_tokens=4096,
                temperature=0.7,
                timeout=30.0
            )
        }
    
    def get_available_providers(self) -> List[ModelProvider]:
        """è·å–å¯ç”¨çš„æ¨¡å‹ä¾›åº”å•†"""
        available = []
        for provider, config in self.configs.items():
            if os.getenv(config.api_key_env):
                available.append(provider)
        return available
    
    def get_config(self, provider: ModelProvider) -> Optional[ModelConfig]:
        """è·å–æŒ‡å®šä¾›åº”å•†çš„é…ç½®"""
        return self.configs.get(provider)
    
    def is_provider_configured(self, provider: ModelProvider) -> bool:
        """æ£€æŸ¥ä¾›åº”å•†æ˜¯å¦å·²é…ç½®"""
        config = self.get_config(provider)
        if not config:
            return False
        return bool(os.getenv(config.api_key_env))
    
    def get_primary_provider(self) -> Optional[ModelProvider]:
        """è·å–ä¸»è¦ä¾›åº”å•†ï¼ˆä¼˜å…ˆçº§ï¼šDeepSeek > Ernie > Doubao > OpenAIï¼‰"""
        priority_order = [
            ModelProvider.DEEPSEEK,
            ModelProvider.ERNIE,
            ModelProvider.DOUBAO,
            ModelProvider.OPENAI
        ]
        
        for provider in priority_order:
            if self.is_provider_configured(provider):
                return provider
        
        return None
    
    def create_client(self, provider: Optional[ModelProvider] = None) -> Tuple[Optional[HarborAI], Optional[ModelConfig]]:
        """åˆ›å»º HarborAI å®¢æˆ·ç«¯"""
        if provider is None:
            provider = self.get_primary_provider()
        
        if provider is None:
            return None, None
        
        config = self.get_config(provider)
        if not config or not self.is_provider_configured(provider):
            return None, None
        
        api_key = os.getenv(config.api_key_env)
        base_url = os.getenv(config.base_url_env, config.default_base_url)
        
        try:
            client = HarborAI(
                api_key=api_key,
                base_url=base_url
            )
            
            self.current_config = config
            self.client = client
            
            return client, config
            
        except Exception as e:
            logger.error(f"åˆ›å»ºå®¢æˆ·ç«¯å¤±è´¥ ({provider.value}): {e}")
            return None, None
    
    def get_fallback_models(self, exclude_provider: Optional[ModelProvider] = None) -> List[str]:
        """è·å–é™çº§æ¨¡å‹åˆ—è¡¨"""
        fallback_models = []
        
        for provider in [ModelProvider.DEEPSEEK, ModelProvider.ERNIE, ModelProvider.DOUBAO]:
            if provider == exclude_provider:
                continue
            
            if self.is_provider_configured(provider):
                config = self.get_config(provider)
                if config:
                    fallback_models.append(config.model_name)
        
        return fallback_models
    
    def print_configuration_status(self):
        """æ‰“å°é…ç½®çŠ¶æ€"""
        print("\nğŸ“‹ HarborAI é…ç½®çŠ¶æ€")
        print("=" * 50)
        
        available_providers = self.get_available_providers()
        primary_provider = self.get_primary_provider()
        
        print(f"ğŸ” å·²é…ç½®çš„ä¾›åº”å•†: {len(available_providers)}/{len(self.configs)}")
        
        for provider, config in self.configs.items():
            status = "âœ…" if provider in available_providers else "âŒ"
            primary_mark = "ğŸŒŸ" if provider == primary_provider else "  "
            
            print(f"{primary_mark} {status} {config.provider.value.upper()}")
            print(f"     æ¨¡å‹: {config.model_name}")
            print(f"     æè¿°: {config.description}")
            print(f"     ç¯å¢ƒå˜é‡: {config.api_key_env}")
            
            if provider in available_providers:
                base_url = os.getenv(config.base_url_env, config.default_base_url)
                print(f"     APIåœ°å€: {base_url}")
            else:
                print(f"     çŠ¶æ€: æœªé…ç½® API Key")
            print()
        
        if primary_provider:
            print(f"ğŸ¯ ä¸»è¦ä¾›åº”å•†: {primary_provider.value.upper()}")
            fallback_models = self.get_fallback_models(primary_provider)
            if fallback_models:
                print(f"ğŸ”„ é™çº§æ¨¡å‹: {', '.join(fallback_models)}")
        else:
            print("âš ï¸ è­¦å‘Š: æœªé…ç½®ä»»ä½•ä¾›åº”å•†")
            print("è¯·è®¾ç½®è‡³å°‘ä¸€ä¸ª API Key:")
            for config in self.configs.values():
                print(f"   export {config.api_key_env}=your_api_key")

async def demo_basic_configuration():
    """æ¼”ç¤ºåŸºç¡€é…ç½®"""
    print("\nğŸ”§ æ¼”ç¤ºåŸºç¡€é…ç½®ç®¡ç†")
    print("=" * 50)
    
    config_manager = ConfigManager()
    
    # æ˜¾ç¤ºé…ç½®çŠ¶æ€
    config_manager.print_configuration_status()
    
    # åˆ›å»ºå®¢æˆ·ç«¯
    client, config = config_manager.create_client()
    
    if not client or not config:
        print("âŒ æ— æ³•åˆ›å»ºå®¢æˆ·ç«¯ï¼Œè¯·æ£€æŸ¥é…ç½®")
        return
    
    print(f"âœ… æˆåŠŸåˆ›å»ºå®¢æˆ·ç«¯")
    print(f"   ä¾›åº”å•†: {config.provider.value.upper()}")
    print(f"   æ¨¡å‹: {config.model_name}")
    
    # æµ‹è¯•åŸºç¡€è°ƒç”¨
    try:
        response = await client.chat.completions.create(
            model=config.model_name,
            messages=[{"role": "user", "content": "ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"}],
            max_tokens=100,
            temperature=config.temperature,
            timeout=config.timeout
        )
        
        content = response.choices[0].message.content if response.choices else "æ— å“åº”"
        print(f"âœ… æµ‹è¯•è°ƒç”¨æˆåŠŸ")
        print(f"   å“åº”: {content[:100]}...")
        
        if response.usage:
            print(f"   Tokenä½¿ç”¨: {response.usage.total_tokens}")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è°ƒç”¨å¤±è´¥: {e}")

async def demo_multi_provider_switching():
    """æ¼”ç¤ºå¤šä¾›åº”å•†åˆ‡æ¢"""
    print("\nğŸ”„ æ¼”ç¤ºå¤šä¾›åº”å•†åˆ‡æ¢")
    print("=" * 50)
    
    config_manager = ConfigManager()
    available_providers = config_manager.get_available_providers()
    
    if len(available_providers) < 2:
        print("âš ï¸ éœ€è¦è‡³å°‘é…ç½®2ä¸ªä¾›åº”å•†æ‰èƒ½æ¼”ç¤ºåˆ‡æ¢åŠŸèƒ½")
        print(f"å½“å‰å·²é…ç½®: {[p.value for p in available_providers]}")
        return
    
    test_message = "è¯·ç”¨ä¸€å¥è¯è§£é‡Šä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½"
    
    for provider in available_providers[:3]:  # æœ€å¤šæµ‹è¯•3ä¸ªä¾›åº”å•†
        print(f"\nğŸ”„ åˆ‡æ¢åˆ° {provider.value.upper()}")
        
        client, config = config_manager.create_client(provider)
        
        if not client or not config:
            print(f"âŒ æ— æ³•åˆ›å»º {provider.value} å®¢æˆ·ç«¯")
            continue
        
        try:
            start_time = asyncio.get_event_loop().time()
            
            response = await client.chat.completions.create(
                model=config.model_name,
                messages=[{"role": "user", "content": test_message}],
                max_tokens=100,
                temperature=0.7,
                timeout=config.timeout
            )
            
            response_time = asyncio.get_event_loop().time() - start_time
            content = response.choices[0].message.content if response.choices else "æ— å“åº”"
            
            print(f"   âœ… å“åº”æ—¶é—´: {response_time:.2f}ç§’")
            print(f"   ğŸ“ å†…å®¹: {content[:80]}...")
            
            if response.usage:
                print(f"   ğŸ”¢ Token: {response.usage.total_tokens}")
            
        except Exception as e:
            print(f"   âŒ è°ƒç”¨å¤±è´¥: {e}")

async def demo_fallback_configuration():
    """æ¼”ç¤ºé™çº§é…ç½®"""
    print("\nğŸ›¡ï¸ æ¼”ç¤ºé™çº§é…ç½®")
    print("=" * 50)
    
    config_manager = ConfigManager()
    client, config = config_manager.create_client()
    
    if not client or not config:
        print("âŒ æ— æ³•åˆ›å»ºå®¢æˆ·ç«¯")
        return
    
    # è·å–é™çº§æ¨¡å‹åˆ—è¡¨
    fallback_models = config_manager.get_fallback_models(config.provider)
    
    print(f"ğŸ¯ ä¸»æ¨¡å‹: {config.model_name}")
    print(f"ğŸ”„ é™çº§æ¨¡å‹: {fallback_models}")
    
    if not fallback_models:
        print("âš ï¸ æœªé…ç½®é™çº§æ¨¡å‹ï¼Œå»ºè®®é…ç½®å¤šä¸ªä¾›åº”å•†")
        return
    
    # æµ‹è¯•å¸¦é™çº§çš„è°ƒç”¨
    try:
        response = await client.chat.completions.create(
            model=config.model_name,
            messages=[{"role": "user", "content": "æµ‹è¯•é™çº§æœºåˆ¶ï¼šè¯·ç®€å•å›ç­”ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ "}],
            fallback=fallback_models,
            retry_policy={
                "max_attempts": 3,
                "base_delay": 1.0,
                "max_delay": 5.0
            },
            max_tokens=100,
            timeout=30.0
        )
        
        content = response.choices[0].message.content if response.choices else "æ— å“åº”"
        print(f"âœ… é™çº§é…ç½®æµ‹è¯•æˆåŠŸ")
        print(f"   å“åº”: {content[:100]}...")
        
    except Exception as e:
        print(f"âŒ é™çº§é…ç½®æµ‹è¯•å¤±è´¥: {e}")

async def demo_environment_configuration():
    """æ¼”ç¤ºç¯å¢ƒé…ç½®"""
    print("\nğŸŒ æ¼”ç¤ºç¯å¢ƒé…ç½®ç®¡ç†")
    print("=" * 50)
    
    # æ¨¡æ‹Ÿä¸åŒç¯å¢ƒçš„é…ç½®
    environments = {
        "development": {
            "description": "å¼€å‘ç¯å¢ƒ - å¿«é€Ÿå“åº”ï¼Œæˆæœ¬ä¼˜åŒ–",
            "preferred_providers": [ModelProvider.DEEPSEEK, ModelProvider.ERNIE],
            "max_tokens": 1024,
            "temperature": 0.8,
            "timeout": 15.0
        },
        "testing": {
            "description": "æµ‹è¯•ç¯å¢ƒ - ç¨³å®šæ€§ä¼˜å…ˆ",
            "preferred_providers": [ModelProvider.ERNIE, ModelProvider.DEEPSEEK],
            "max_tokens": 2048,
            "temperature": 0.5,
            "timeout": 30.0
        },
        "production": {
            "description": "ç”Ÿäº§ç¯å¢ƒ - é«˜å¯ç”¨ï¼Œå¤šé™çº§",
            "preferred_providers": [ModelProvider.DEEPSEEK, ModelProvider.ERNIE, ModelProvider.DOUBAO],
            "max_tokens": 4096,
            "temperature": 0.7,
            "timeout": 45.0
        }
    }
    
    current_env = os.getenv("HARBORAI_ENV", "development")
    env_config = environments.get(current_env, environments["development"])
    
    print(f"ğŸ” å½“å‰ç¯å¢ƒ: {current_env}")
    print(f"ğŸ“ ç¯å¢ƒæè¿°: {env_config['description']}")
    print(f"ğŸ¯ é¦–é€‰ä¾›åº”å•†: {[p.value for p in env_config['preferred_providers']]}")
    print(f"âš™ï¸ é…ç½®å‚æ•°:")
    print(f"   - max_tokens: {env_config['max_tokens']}")
    print(f"   - temperature: {env_config['temperature']}")
    print(f"   - timeout: {env_config['timeout']}s")
    
    # æ ¹æ®ç¯å¢ƒé…ç½®åˆ›å»ºå®¢æˆ·ç«¯
    config_manager = ConfigManager()
    
    # å°è¯•ä½¿ç”¨é¦–é€‰ä¾›åº”å•†
    client = None
    config = None
    
    for provider in env_config['preferred_providers']:
        if config_manager.is_provider_configured(provider):
            client, config = config_manager.create_client(provider)
            if client and config:
                print(f"âœ… ä½¿ç”¨ä¾›åº”å•†: {provider.value.upper()}")
                break
    
    if not client or not config:
        print("âŒ æ— æ³•æ ¹æ®ç¯å¢ƒé…ç½®åˆ›å»ºå®¢æˆ·ç«¯")
        return
    
    # æµ‹è¯•ç¯å¢ƒé…ç½®
    try:
        response = await client.chat.completions.create(
            model=config.model_name,
            messages=[{"role": "user", "content": f"è¿™æ˜¯{current_env}ç¯å¢ƒçš„æµ‹è¯•"}],
            max_tokens=env_config['max_tokens'],
            temperature=env_config['temperature'],
            timeout=env_config['timeout']
        )
        
        content = response.choices[0].message.content if response.choices else "æ— å“åº”"
        print(f"âœ… ç¯å¢ƒé…ç½®æµ‹è¯•æˆåŠŸ")
        print(f"   å“åº”: {content[:80]}...")
        
    except Exception as e:
        print(f"âŒ ç¯å¢ƒé…ç½®æµ‹è¯•å¤±è´¥: {e}")

async def demo_configuration_validation():
    """æ¼”ç¤ºé…ç½®éªŒè¯"""
    print("\nâœ… æ¼”ç¤ºé…ç½®éªŒè¯")
    print("=" * 50)
    
    config_manager = ConfigManager()
    
    print("ğŸ” éªŒè¯æ‰€æœ‰ä¾›åº”å•†é…ç½®...")
    
    validation_results = {}
    
    for provider in ModelProvider:
        print(f"\nğŸ“‹ éªŒè¯ {provider.value.upper()}:")
        
        config = config_manager.get_config(provider)
        if not config:
            print("   âŒ é…ç½®ä¸å­˜åœ¨")
            validation_results[provider] = False
            continue
        
        # æ£€æŸ¥ç¯å¢ƒå˜é‡
        api_key = os.getenv(config.api_key_env)
        if not api_key:
            print(f"   âŒ ç¼ºå°‘ç¯å¢ƒå˜é‡: {config.api_key_env}")
            validation_results[provider] = False
            continue
        
        print(f"   âœ… API Key: å·²è®¾ç½®")
        
        # æ£€æŸ¥ Base URL
        base_url = os.getenv(config.base_url_env, config.default_base_url)
        print(f"   âœ… Base URL: {base_url}")
        
        # å°è¯•åˆ›å»ºå®¢æˆ·ç«¯
        try:
            client, _ = config_manager.create_client(provider)
            if client:
                print(f"   âœ… å®¢æˆ·ç«¯åˆ›å»º: æˆåŠŸ")
                
                # ç®€å•è¿æ¥æµ‹è¯•
                try:
                    response = await client.chat.completions.create(
                        model=config.model_name,
                        messages=[{"role": "user", "content": "æµ‹è¯•"}],
                        max_tokens=10,
                        timeout=10.0
                    )
                    print(f"   âœ… è¿æ¥æµ‹è¯•: æˆåŠŸ")
                    validation_results[provider] = True
                    
                except Exception as e:
                    print(f"   âŒ è¿æ¥æµ‹è¯•: å¤±è´¥ - {e}")
                    validation_results[provider] = False
            else:
                print(f"   âŒ å®¢æˆ·ç«¯åˆ›å»º: å¤±è´¥")
                validation_results[provider] = False
                
        except Exception as e:
            print(f"   âŒ å®¢æˆ·ç«¯åˆ›å»º: å¤±è´¥ - {e}")
            validation_results[provider] = False
    
    # æ±‡æ€»éªŒè¯ç»“æœ
    valid_providers = [p for p, valid in validation_results.items() if valid]
    invalid_providers = [p for p, valid in validation_results.items() if not valid]
    
    print(f"\nğŸ“Š éªŒè¯æ±‡æ€»:")
    print(f"   âœ… æœ‰æ•ˆä¾›åº”å•†: {len(valid_providers)}")
    print(f"   âŒ æ— æ•ˆä¾›åº”å•†: {len(invalid_providers)}")
    
    if valid_providers:
        print(f"   ğŸ¯ å¯ç”¨: {[p.value for p in valid_providers]}")
    
    if invalid_providers:
        print(f"   âš ï¸ éœ€ä¿®å¤: {[p.value for p in invalid_providers]}")

async def demo_best_practices():
    """æ¼”ç¤ºæœ€ä½³å®è·µ"""
    print("\nğŸ’¡ æ¼”ç¤ºé…ç½®æœ€ä½³å®è·µ")
    print("=" * 50)
    
    print("ğŸ“‹ HarborAI é…ç½®æœ€ä½³å®è·µ:")
    print()
    
    print("1. ğŸ” å®‰å…¨é…ç½®:")
    print("   - ä½¿ç”¨ç¯å¢ƒå˜é‡å­˜å‚¨ API Key")
    print("   - ä¸è¦åœ¨ä»£ç ä¸­ç¡¬ç¼–ç å¯†é’¥")
    print("   - ä½¿ç”¨ .env æ–‡ä»¶ç®¡ç†æœ¬åœ°é…ç½®")
    print("   - ç”Ÿäº§ç¯å¢ƒä½¿ç”¨å¯†é’¥ç®¡ç†æœåŠ¡")
    print()
    
    print("2. ğŸ”„ å¤šä¾›åº”å•†é…ç½®:")
    print("   - é…ç½®å¤šä¸ªæ¨¡å‹ä¾›åº”å•†ä½œä¸ºå¤‡é€‰")
    print("   - è®¾ç½®åˆç†çš„é™çº§é¡ºåº")
    print("   - æ ¹æ®æˆæœ¬å’Œæ€§èƒ½é€‰æ‹©ä¸»ä¾›åº”å•†")
    print("   - å®šæœŸæµ‹è¯•æ‰€æœ‰ä¾›åº”å•†çš„å¯ç”¨æ€§")
    print()
    
    print("3. ğŸŒ ç¯å¢ƒç®¡ç†:")
    print("   - ä¸ºä¸åŒç¯å¢ƒè®¾ç½®ä¸åŒçš„é…ç½®")
    print("   - å¼€å‘ç¯å¢ƒä¼˜åŒ–å“åº”é€Ÿåº¦")
    print("   - ç”Ÿäº§ç¯å¢ƒä¼˜åŒ–ç¨³å®šæ€§å’Œæˆæœ¬")
    print("   - ä½¿ç”¨ç¯å¢ƒå˜é‡åŒºåˆ†é…ç½®")
    print()
    
    print("4. âš™ï¸ å‚æ•°è°ƒä¼˜:")
    print("   - æ ¹æ®ä¸šåŠ¡éœ€æ±‚è°ƒæ•´ max_tokens")
    print("   - åˆ›æ„ä»»åŠ¡ä½¿ç”¨è¾ƒé«˜ temperature")
    print("   - åˆ†æä»»åŠ¡ä½¿ç”¨è¾ƒä½ temperature")
    print("   - è®¾ç½®åˆç†çš„è¶…æ—¶æ—¶é—´")
    print()
    
    print("5. ğŸ“Š ç›‘æ§å’Œç»´æŠ¤:")
    print("   - å®šæœŸéªŒè¯é…ç½®æœ‰æ•ˆæ€§")
    print("   - ç›‘æ§ API è°ƒç”¨æˆåŠŸç‡")
    print("   - è·Ÿè¸ªæˆæœ¬å’Œä½¿ç”¨é‡")
    print("   - åŠæ—¶æ›´æ–°è¿‡æœŸçš„é…ç½®")
    print()
    
    # ç¤ºä¾‹é…ç½®æ–‡ä»¶
    print("ğŸ“„ ç¤ºä¾‹ .env é…ç½®æ–‡ä»¶:")
    print("```")
    print("# HarborAI é…ç½®")
    print("HARBORAI_ENV=production")
    print()
    print("# DeepSeek é…ç½®")
    print("DEEPSEEK_API_KEY=your_deepseek_api_key")
    print("DEEPSEEK_BASE_URL=https://api.deepseek.com")
    print()
    print("# ç™¾åº¦æ–‡å¿ƒä¸€è¨€é…ç½®")
    print("ERNIE_API_KEY=your_ernie_api_key")
    print("ERNIE_BASE_URL=https://aip.baidubce.com")
    print()
    print("# å­—èŠ‚è·³åŠ¨è±†åŒ…é…ç½®")
    print("DOUBAO_API_KEY=your_doubao_api_key")
    print("DOUBAO_BASE_URL=https://ark.cn-beijing.volces.com")
    print("```")

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ HarborAI é…ç½®ç®¡ç†æ¼”ç¤º")
    print("=" * 60)
    
    demos = [
        ("åŸºç¡€é…ç½®ç®¡ç†", demo_basic_configuration),
        ("å¤šä¾›åº”å•†åˆ‡æ¢", demo_multi_provider_switching),
        ("é™çº§é…ç½®", demo_fallback_configuration),
        ("ç¯å¢ƒé…ç½®ç®¡ç†", demo_environment_configuration),
        ("é…ç½®éªŒè¯", demo_configuration_validation),
        ("æœ€ä½³å®è·µ", demo_best_practices)
    ]
    
    for name, demo_func in demos:
        try:
            await demo_func()
            await asyncio.sleep(1)  # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
        except Exception as e:
            print(f"âŒ {name} æ¼”ç¤ºå¤±è´¥: {e}")
    
    print("\nğŸ‰ é…ç½®ç®¡ç†æ¼”ç¤ºå®Œæˆï¼")
    print("\nğŸ’¡ å…³é”®è¦ç‚¹:")
    print("1. ä½¿ç”¨ç¯å¢ƒå˜é‡ç®¡ç†æ•æ„Ÿé…ç½®")
    print("2. é…ç½®å¤šä¸ªä¾›åº”å•†ç¡®ä¿é«˜å¯ç”¨")
    print("3. æ ¹æ®ç¯å¢ƒè°ƒæ•´é…ç½®å‚æ•°")
    print("4. å®šæœŸéªŒè¯é…ç½®æœ‰æ•ˆæ€§")
    print("5. éµå¾ªå®‰å…¨é…ç½®æœ€ä½³å®è·µ")

if __name__ == "__main__":
    asyncio.run(main())