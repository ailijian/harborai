#!/usr/bin/env python3
"""
é™çº§ç­–ç•¥æ¼”ç¤º

è¿™ä¸ªç¤ºä¾‹å±•ç¤ºäº† HarborAI çš„é™çº§ç­–ç•¥åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
1. å¤šå±‚çº§é™çº§ç­–ç•¥
2. æœåŠ¡å¥åº·ç›‘æ§
3. è‡ªåŠ¨æ•…éšœè½¬ç§»
4. æ€§èƒ½ç›‘æ§ä¸å‘Šè­¦
5. ä¼˜é›…é™çº§å¤„ç†

åœºæ™¯ï¼š
- ä¸»è¦AIæœåŠ¡ä¸å¯ç”¨æˆ–æ€§èƒ½ä¸‹é™æ—¶è‡ªåŠ¨åˆ‡æ¢åˆ°å¤‡ç”¨æ–¹æ¡ˆ
- ç¡®ä¿æœåŠ¡è¿ç»­æ€§å’Œå¯ç”¨æ€§
- åœ¨æˆæœ¬å’Œæ€§èƒ½ä¹‹é—´æ‰¾åˆ°å¹³è¡¡

ä»·å€¼ï¼š
- ç¡®ä¿æœåŠ¡è¿ç»­æ€§å’Œå¯ç”¨æ€§
- ä¼˜åŒ–ç”¨æˆ·ä½“éªŒï¼Œé¿å…æœåŠ¡ä¸­æ–­
- é™ä½æœåŠ¡ä¸­æ–­é£é™©
- æ™ºèƒ½é€‰æ‹©æœ€ä¼˜æœåŠ¡
"""

import asyncio
import time
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Callable, Any, Union
from dataclasses import dataclass, field
from enum import Enum
import json

# å¯¼å…¥é…ç½®åŠ©æ‰‹
from config_helper import get_model_configs, get_primary_model_config, print_available_models

# å¯¼å…¥ HarborAI
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

from harborai import HarborAI

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class ServiceTier(Enum):
    """æœåŠ¡å±‚çº§"""
    PRIMARY = 1      # ä¸»è¦æœåŠ¡
    SECONDARY = 2    # æ¬¡è¦æœåŠ¡
    FALLBACK = 3     # é™çº§æœåŠ¡
    EMERGENCY = 4    # ç´§æ€¥æœåŠ¡

class ServiceStatus(Enum):
    """æœåŠ¡çŠ¶æ€"""
    HEALTHY = "healthy"
    DEGRADED = "degraded"
    UNHEALTHY = "unhealthy"
    OFFLINE = "offline"

@dataclass
class ServiceConfig:
    """æœåŠ¡é…ç½®"""
    name: str
    model: str
    vendor: str
    tier: ServiceTier
    api_key: str
    base_url: str
    temperature: float = 0.7
    cost_per_token: float = 0.0001
    expected_latency: float = 3.0
    quality_score: float = 1.0
    timeout: int = 90

@dataclass
class ServiceMetrics:
    """æœåŠ¡æŒ‡æ ‡"""
    total_requests: int = 0
    successful_requests: int = 0
    failed_requests: int = 0
    total_latency: float = 0.0
    total_cost: float = 0.0
    last_request_time: Optional[datetime] = None
    last_error_time: Optional[datetime] = None
    consecutive_failures: int = 0
    
    def add_success(self, latency: float, cost: float):
        """æ·»åŠ æˆåŠŸè®°å½•"""
        self.total_requests += 1
        self.successful_requests += 1
        self.total_latency += latency
        self.total_cost += cost
        self.last_request_time = datetime.now()
        self.consecutive_failures = 0
    
    def add_failure(self):
        """æ·»åŠ å¤±è´¥è®°å½•"""
        self.total_requests += 1
        self.failed_requests += 1
        self.last_error_time = datetime.now()
        self.consecutive_failures += 1
    
    def get_success_rate(self) -> float:
        """è·å–æˆåŠŸç‡"""
        if self.total_requests == 0:
            return 0.0
        return self.successful_requests / self.total_requests
    
    def get_average_latency(self) -> float:
        """è·å–å¹³å‡å»¶è¿Ÿ"""
        if self.successful_requests == 0:
            return 0.0
        return self.total_latency / self.successful_requests
    
    def get_average_cost(self) -> float:
        """è·å–å¹³å‡æˆæœ¬"""
        if self.successful_requests == 0:
            return 0.0
        return self.total_cost / self.successful_requests

class ServiceHealthChecker:
    """æœåŠ¡å¥åº·æ£€æŸ¥å™¨"""
    
    def __init__(self, config: ServiceConfig):
        self.config = config
        self.client = HarborAI()
        self.metrics = ServiceMetrics()
        self.status = ServiceStatus.HEALTHY
        
    async def health_check(self) -> bool:
        """æ‰§è¡Œå¥åº·æ£€æŸ¥"""
        try:
            start_time = time.time()
            
            # å‘é€ç®€å•çš„å¥åº·æ£€æŸ¥è¯·æ±‚
            response = await asyncio.to_thread(
                self.client.chat.completions.create,
                model=self.config.model,
                messages=[{"role": "user", "content": "ç®€å•å›ç­”ï¼šä½ å¥½"}],
                timeout=10
            )
            
            latency = time.time() - start_time
            
            # ä¼°ç®—æˆæœ¬
            content_length = len(response.choices[0].message.content) if response.choices else 0
            cost = content_length * self.config.cost_per_token
            
            self.metrics.add_success(latency, cost)
            self._update_status()
            
            logger.info(f"âœ… {self.config.name} å¥åº·æ£€æŸ¥é€šè¿‡ - å»¶è¿Ÿ: {latency:.2f}s")
            return True
            
        except Exception as e:
            self.metrics.add_failure()
            self._update_status()
            
            logger.warning(f"âŒ {self.config.name} å¥åº·æ£€æŸ¥å¤±è´¥: {str(e)}")
            return False
    
    def _update_status(self):
        """æ›´æ–°æœåŠ¡çŠ¶æ€"""
        success_rate = self.metrics.get_success_rate()
        avg_latency = self.metrics.get_average_latency()
        
        if self.metrics.consecutive_failures >= 3:
            self.status = ServiceStatus.OFFLINE
        elif success_rate < 0.5:
            self.status = ServiceStatus.UNHEALTHY
        elif success_rate < 0.8 or avg_latency > self.config.expected_latency * 2:
            self.status = ServiceStatus.DEGRADED
        else:
            self.status = ServiceStatus.HEALTHY
    
    async def make_request(self, messages: List[Dict], **kwargs) -> Any:
        """å‘é€è¯·æ±‚"""
        start_time = time.time()
        
        try:
            # æ„å»ºè¯·æ±‚å‚æ•°
            request_params = {
                "model": self.config.model,
                "messages": messages,
                "temperature": self.config.temperature,
                "timeout": self.config.timeout,
                **kwargs
            }
            
            response = await asyncio.to_thread(
                self.client.chat.completions.create, 
                **request_params
            )
            
            latency = time.time() - start_time
            
            # ä¼°ç®—æˆæœ¬
            content_length = len(response.choices[0].message.content) if response.choices else 0
            cost = content_length * self.config.cost_per_token
            
            self.metrics.add_success(latency, cost)
            self._update_status()
            
            return response
            
        except Exception as e:
            self.metrics.add_failure()
            self._update_status()
            raise e

class FallbackStrategy:
    """é™çº§ç­–ç•¥"""
    
    def __init__(self):
        self.services: Dict[str, ServiceHealthChecker] = {}
        self.service_order: List[ServiceConfig] = []
        self.current_service: Optional[str] = None
        self.fallback_history: List[Dict] = []
        
        # åˆå§‹åŒ–æœåŠ¡é…ç½®
        self._initialize_services()
        
    def _initialize_services(self):
        """åˆå§‹åŒ–æœåŠ¡é…ç½®"""
        model_configs = get_model_configs()
        
        if not model_configs:
            raise ValueError("æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„æ¨¡å‹é…ç½®ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒå˜é‡è®¾ç½®")
        
        # ä¸ºæ¯ä¸ªæ¨¡å‹åˆ›å»ºæœåŠ¡é…ç½®
        tier_mapping = {
            'deepseek': ServiceTier.PRIMARY,
            'ernie': ServiceTier.SECONDARY,
            'doubao': ServiceTier.FALLBACK
        }
        
        for i, model_config in enumerate(model_configs):
            tier = tier_mapping.get(model_config.vendor, ServiceTier.EMERGENCY)
            
            service_config = ServiceConfig(
                name=f"{model_config.vendor}_{model_config.model}",
                model=model_config.model,
                vendor=model_config.vendor,
                tier=tier,
                api_key=model_config.api_key,
                base_url=model_config.base_url,
                expected_latency=2.0 if model_config.vendor == 'deepseek' else 3.0,
                quality_score=1.0 if not model_config.is_reasoning else 1.2
            )
            
            self.services[service_config.name] = ServiceHealthChecker(service_config)
            self.service_order.append(service_config)
        
        # æŒ‰å±‚çº§æ’åº
        self.service_order.sort(key=lambda x: x.tier.value)
        
        logger.info(f"âœ… åˆå§‹åŒ–äº† {len(self.services)} ä¸ªæœåŠ¡")
        for config in self.service_order:
            logger.info(f"   - {config.name} (å±‚çº§: {config.tier.name})")
        
    async def initialize(self):
        """åˆå§‹åŒ–æœåŠ¡å¥åº·æ£€æŸ¥"""
        logger.info("ğŸ” å¼€å§‹æœåŠ¡å¥åº·æ£€æŸ¥...")
        
        # å¯¹æ‰€æœ‰æœåŠ¡è¿›è¡Œå¥åº·æ£€æŸ¥
        health_results = {}
        for service_name, checker in self.services.items():
            health_results[service_name] = await checker.health_check()
        
        # é€‰æ‹©æœ€ä½³æœåŠ¡
        self.current_service = self._select_best_service()
        
        if self.current_service:
            logger.info(f"ğŸ¯ é€‰æ‹©ä¸»è¦æœåŠ¡: {self.current_service}")
        else:
            logger.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„æœåŠ¡")
    
    def _select_best_service(self) -> Optional[str]:
        """é€‰æ‹©æœ€ä½³æœåŠ¡"""
        # æŒ‰ä¼˜å…ˆçº§æ’åºï¼Œé€‰æ‹©å¥åº·çš„æœåŠ¡
        for config in self.service_order:
            checker = self.services[config.name]
            if checker.status in [ServiceStatus.HEALTHY, ServiceStatus.DEGRADED]:
                return config.name
        
        # å¦‚æœæ²¡æœ‰å¥åº·çš„æœåŠ¡ï¼Œé€‰æ‹©æˆåŠŸç‡æœ€é«˜çš„
        available_services = [(name, checker) for name, checker in self.services.items()]
        if available_services:
            best_service = max(available_services, key=lambda x: x[1].metrics.get_success_rate())
            return best_service[0]
        
        return None
    
    async def make_request(self, messages: List[Dict], **kwargs) -> Any:
        """å‘é€è¯·æ±‚ï¼ˆå¸¦é™çº§ç­–ç•¥ï¼‰"""
        original_service = self.current_service
        
        # å°è¯•æ‰€æœ‰å¯ç”¨æœåŠ¡
        for config in self.service_order:
            service_name = config.name
            checker = self.services[service_name]
            
            # è·³è¿‡ç¦»çº¿æœåŠ¡
            if checker.status == ServiceStatus.OFFLINE:
                logger.debug(f"â­ï¸ è·³è¿‡ç¦»çº¿æœåŠ¡: {service_name}")
                continue
            
            try:
                logger.info(f"ğŸ”„ å°è¯•ä½¿ç”¨æœåŠ¡: {service_name}")
                response = await checker.make_request(messages, **kwargs)
                
                # å¦‚æœä½¿ç”¨äº†é™çº§æœåŠ¡ï¼Œè®°å½•é™çº§äº‹ä»¶
                if service_name != original_service:
                    self._record_fallback(original_service, service_name, "success")
                    self.current_service = service_name
                    logger.info(f"ğŸ”„ é™çº§åˆ°æœåŠ¡: {service_name}")
                
                return response
                
            except Exception as e:
                logger.warning(f"âŒ æœåŠ¡ {service_name} è¯·æ±‚å¤±è´¥: {str(e)}")
                
                # è®°å½•é™çº§äº‹ä»¶
                if service_name == original_service:
                    self._record_fallback(original_service, None, "failure")
                
                continue
        
        # æ‰€æœ‰æœåŠ¡éƒ½å¤±è´¥äº†
        raise Exception("æ‰€æœ‰æœåŠ¡éƒ½ä¸å¯ç”¨")
    
    def _record_fallback(self, from_service: Optional[str], to_service: Optional[str], reason: str):
        """è®°å½•é™çº§äº‹ä»¶"""
        event = {
            "timestamp": datetime.now().isoformat(),
            "from_service": from_service,
            "to_service": to_service,
            "reason": reason
        }
        self.fallback_history.append(event)
        logger.info(f"ğŸ“ è®°å½•é™çº§äº‹ä»¶: {from_service} -> {to_service} ({reason})")
    
    def get_service_status(self) -> Dict[str, Any]:
        """è·å–æœåŠ¡çŠ¶æ€"""
        status = {}
        for name, checker in self.services.items():
            status[name] = {
                "status": checker.status.value,
                "metrics": {
                    "total_requests": checker.metrics.total_requests,
                    "success_rate": checker.metrics.get_success_rate(),
                    "average_latency": checker.metrics.get_average_latency(),
                    "consecutive_failures": checker.metrics.consecutive_failures
                }
            }
        return status
    
    def get_fallback_history(self) -> List[Dict]:
        """è·å–é™çº§å†å²"""
        return self.fallback_history.copy()

# æ¼”ç¤ºå‡½æ•°
async def demo_basic_fallback():
    """æ¼”ç¤ºåŸºç¡€é™çº§ç­–ç•¥"""
    print("\nğŸ”„ åŸºç¡€é™çº§ç­–ç•¥æ¼”ç¤º")
    print("=" * 50)
    
    # åˆ›å»ºé™çº§ç­–ç•¥
    strategy = FallbackStrategy()
    await strategy.initialize()
    
    # æµ‹è¯•è¯·æ±‚
    test_messages = [
        [{"role": "user", "content": "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ"}],
        [{"role": "user", "content": "è§£é‡Šæœºå™¨å­¦ä¹ çš„æ¦‚å¿µ"}],
        [{"role": "user", "content": "æ·±åº¦å­¦ä¹ æœ‰ä»€ä¹ˆç‰¹ç‚¹ï¼Ÿ"}]
    ]
    
    print(f"\nğŸ“ å‘é€ {len(test_messages)} ä¸ªæµ‹è¯•è¯·æ±‚...")
    
    for i, messages in enumerate(test_messages, 1):
        try:
            print(f"\nğŸ”„ è¯·æ±‚ {i}: {messages[0]['content']}")
            response = await strategy.make_request(messages)
            
            if response and response.choices:
                content = response.choices[0].message.content
                print(f"âœ… å“åº”: {content[:100]}...")
            else:
                print("âœ… è¯·æ±‚æˆåŠŸï¼Œä½†æ— å“åº”å†…å®¹")
                
        except Exception as e:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {str(e)}")
    
    # æ˜¾ç¤ºæœåŠ¡çŠ¶æ€
    print(f"\nğŸ“Š æœåŠ¡çŠ¶æ€:")
    status = strategy.get_service_status()
    for service_name, service_status in status.items():
        print(f"   {service_name}:")
        print(f"     çŠ¶æ€: {service_status['status']}")
        print(f"     æˆåŠŸç‡: {service_status['metrics']['success_rate']:.1%}")
        print(f"     å¹³å‡å»¶è¿Ÿ: {service_status['metrics']['average_latency']:.2f}s")

async def demo_service_failure_simulation():
    """æ¼”ç¤ºæœåŠ¡æ•…éšœæ¨¡æ‹Ÿ"""
    print("\nğŸš¨ æœåŠ¡æ•…éšœæ¨¡æ‹Ÿæ¼”ç¤º")
    print("=" * 50)
    
    strategy = FallbackStrategy()
    await strategy.initialize()
    
    # æ¨¡æ‹Ÿä¸»æœåŠ¡æ•…éšœ
    if strategy.current_service:
        current_checker = strategy.services[strategy.current_service]
        print(f"ğŸ¯ å½“å‰ä¸»æœåŠ¡: {strategy.current_service}")
        
        # äººä¸ºå¢åŠ å¤±è´¥æ¬¡æ•°æ¥æ¨¡æ‹Ÿæ•…éšœ
        for _ in range(3):
            current_checker.metrics.add_failure()
        current_checker._update_status()
        
        print(f"ğŸ’¥ æ¨¡æ‹Ÿ {strategy.current_service} æœåŠ¡æ•…éšœ")
        print(f"   çŠ¶æ€å˜æ›´ä¸º: {current_checker.status.value}")
    
    # æµ‹è¯•é™çº§
    test_message = [{"role": "user", "content": "åœ¨æœåŠ¡æ•…éšœæƒ…å†µä¸‹ï¼Œè¿™ä¸ªè¯·æ±‚åº”è¯¥è‡ªåŠ¨é™çº§"}]
    
    try:
        print(f"\nğŸ”„ å‘é€æµ‹è¯•è¯·æ±‚...")
        response = await strategy.make_request(test_message)
        
        if response and response.choices:
            print(f"âœ… é™çº§æˆåŠŸï¼Œå½“å‰æœåŠ¡: {strategy.current_service}")
            print(f"   å“åº”: {response.choices[0].message.content[:100]}...")
        
    except Exception as e:
        print(f"âŒ é™çº§å¤±è´¥: {str(e)}")
    
    # æ˜¾ç¤ºé™çº§å†å²
    history = strategy.get_fallback_history()
    if history:
        print(f"\nğŸ“ é™çº§å†å²:")
        for event in history:
            print(f"   {event['timestamp']}: {event['from_service']} -> {event['to_service']} ({event['reason']})")

async def demo_performance_monitoring():
    """æ¼”ç¤ºæ€§èƒ½ç›‘æ§"""
    print("\nğŸ“Š æ€§èƒ½ç›‘æ§æ¼”ç¤º")
    print("=" * 50)
    
    strategy = FallbackStrategy()
    await strategy.initialize()
    
    # å‘é€å¤šä¸ªè¯·æ±‚æ¥æ”¶é›†æ€§èƒ½æ•°æ®
    test_requests = [
        "ä»€ä¹ˆæ˜¯äº‘è®¡ç®—ï¼Ÿ",
        "è§£é‡ŠåŒºå—é“¾æŠ€æœ¯",
        "äººå·¥æ™ºèƒ½çš„åº”ç”¨é¢†åŸŸ",
        "æœºå™¨å­¦ä¹ ç®—æ³•åˆ†ç±»",
        "æ·±åº¦å­¦ä¹ çš„ä¼˜åŠ¿"
    ]
    
    print(f"ğŸ“ å‘é€ {len(test_requests)} ä¸ªè¯·æ±‚æ”¶é›†æ€§èƒ½æ•°æ®...")
    
    for i, prompt in enumerate(test_requests, 1):
        try:
            messages = [{"role": "user", "content": prompt}]
            start_time = time.time()
            
            response = await strategy.make_request(messages)
            
            elapsed = time.time() - start_time
            print(f"   è¯·æ±‚ {i}: {elapsed:.2f}s")
            
        except Exception as e:
            print(f"   è¯·æ±‚ {i}: å¤±è´¥ - {str(e)}")
        
        # çŸ­æš‚å»¶è¿Ÿ
        await asyncio.sleep(0.5)
    
    # æ˜¾ç¤ºè¯¦ç»†æ€§èƒ½ç»Ÿè®¡
    print(f"\nğŸ“Š è¯¦ç»†æ€§èƒ½ç»Ÿè®¡:")
    status = strategy.get_service_status()
    
    for service_name, service_status in status.items():
        metrics = service_status['metrics']
        print(f"\n   {service_name}:")
        print(f"     æ€»è¯·æ±‚æ•°: {metrics['total_requests']}")
        print(f"     æˆåŠŸç‡: {metrics['success_rate']:.1%}")
        print(f"     å¹³å‡å»¶è¿Ÿ: {metrics['average_latency']:.2f}s")
        print(f"     è¿ç»­å¤±è´¥: {metrics['consecutive_failures']}")

async def demo_adaptive_strategy():
    """æ¼”ç¤ºè‡ªé€‚åº”ç­–ç•¥"""
    print("\nğŸ§  è‡ªé€‚åº”ç­–ç•¥æ¼”ç¤º")
    print("=" * 50)
    
    strategy = FallbackStrategy()
    await strategy.initialize()
    
    print("ğŸ”„ æµ‹è¯•è‡ªé€‚åº”æœåŠ¡é€‰æ‹©...")
    
    # æ¨¡æ‹Ÿä¸åŒç±»å‹çš„è¯·æ±‚
    request_types = [
        ("ç®€å•é—®ç­”", "ä»€ä¹ˆæ˜¯AIï¼Ÿ"),
        ("å¤æ‚åˆ†æ", "åˆ†æäººå·¥æ™ºèƒ½å¯¹æœªæ¥ç¤¾ä¼šçš„å½±å“ï¼ŒåŒ…æ‹¬æŠ€æœ¯ã€ç»æµã€ä¼¦ç†ç­‰å¤šä¸ªç»´åº¦"),
        ("åˆ›æ„ç”Ÿæˆ", "å†™ä¸€é¦–å…³äºç§‘æŠ€å‘å±•çš„è¯—"),
        ("ä»£ç è§£é‡Š", "è§£é‡ŠPythonä¸­çš„è£…é¥°å™¨æ¦‚å¿µ"),
        ("ç¿»è¯‘ä»»åŠ¡", "å°†'Hello World'ç¿»è¯‘æˆä¸­æ–‡")
    ]
    
    for request_type, prompt in request_types:
        print(f"\nğŸ“ {request_type}: {prompt}")
        
        try:
            messages = [{"role": "user", "content": prompt}]
            response = await strategy.make_request(messages)
            
            if response and response.choices:
                print(f"âœ… ä½¿ç”¨æœåŠ¡: {strategy.current_service}")
                print(f"   å“åº”é•¿åº¦: {len(response.choices[0].message.content)} å­—ç¬¦")
            
        except Exception as e:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {str(e)}")
        
        await asyncio.sleep(1)

async def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸ”„ HarborAI é™çº§ç­–ç•¥æ¼”ç¤º")
    print("=" * 60)
    
    # æ˜¾ç¤ºå¯ç”¨æ¨¡å‹é…ç½®
    print_available_models()
    
    try:
        # åŸºç¡€é™çº§ç­–ç•¥æ¼”ç¤º
        await demo_basic_fallback()
        
        # æœåŠ¡æ•…éšœæ¨¡æ‹Ÿæ¼”ç¤º
        await demo_service_failure_simulation()
        
        # æ€§èƒ½ç›‘æ§æ¼”ç¤º
        await demo_performance_monitoring()
        
        # è‡ªé€‚åº”ç­–ç•¥æ¼”ç¤º
        await demo_adaptive_strategy()
        
        print("\nâœ… æ‰€æœ‰æ¼”ç¤ºå®Œæˆï¼")
        print("\nğŸ’¡ ç”Ÿäº§ç¯å¢ƒå»ºè®®:")
        print("   1. å®æ–½å®æ—¶å¥åº·æ£€æŸ¥å’Œç›‘æ§")
        print("   2. é…ç½®åˆç†çš„é™çº§é˜ˆå€¼")
        print("   3. å»ºç«‹å‘Šè­¦æœºåˆ¶")
        print("   4. å®šæœŸè¯„ä¼°æœåŠ¡æ€§èƒ½")
        print("   5. å®ç°æ™ºèƒ½è·¯ç”±ç­–ç•¥")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    # è¿è¡Œæ¼”ç¤º
    asyncio.run(main())