#!/usr/bin/env python3
"""
HarborAI æ¨ç†æ¨¡å‹è°ƒç”¨ç¤ºä¾‹

è¿™ä¸ªç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨HarborAIè°ƒç”¨æ¨ç†æ¨¡å‹ï¼Œ
åŒ…æ‹¬DeepSeek-R1ç­‰ä¸“é—¨ç”¨äºå¤æ‚æ¨ç†ä»»åŠ¡çš„æ¨¡å‹ã€‚

åœºæ™¯æè¿°:
- æ¨ç†æ¨¡å‹è°ƒç”¨
- å¤æ‚é—®é¢˜è§£å†³
- æ€ç»´é“¾å±•ç¤º

åº”ç”¨ä»·å€¼:
- è§£å†³å¤æ‚é€»è¾‘é—®é¢˜
- æ•°å­¦è®¡ç®—å’Œè¯æ˜
- å¤šæ­¥éª¤æ¨ç†ä»»åŠ¡
"""

import os
import time
import asyncio
import json
from typing import Dict, Any, List
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# æ·»åŠ æœ¬åœ°æºç è·¯å¾„
import sys
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..'))

try:
    from harborai import HarborAI
except ImportError:
    print("âŒ æ— æ³•å¯¼å…¥ HarborAIï¼Œè¯·æ£€æŸ¥è·¯å¾„é…ç½®")
    exit(1)


def create_client() -> HarborAI:
    """
    åˆ›å»ºHarborAIå®¢æˆ·ç«¯
    
    Returns:
        HarborAI: é…ç½®å¥½çš„å®¢æˆ·ç«¯å®ä¾‹
    """
    api_key = os.getenv("DEEPSEEK_API_KEY")
    base_url = os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com")
    
    if not api_key:
        raise ValueError("è¯·åœ¨ç¯å¢ƒå˜é‡ä¸­è®¾ç½® DEEPSEEK_API_KEY")
    
    return HarborAI(
        api_key=api_key,
        base_url=base_url
    )


def reasoning_call(client: HarborAI, question: str, model: str = "deepseek-reasoner") -> Dict[str, Any]:
    """
    æ¨ç†æ¨¡å‹è°ƒç”¨
    
    Args:
        client: HarborAIå®¢æˆ·ç«¯
        question: æ¨ç†é—®é¢˜
        model: æ¨ç†æ¨¡å‹åç§°
        
    Returns:
        Dict: åŒ…å«æ¨ç†è¿‡ç¨‹å’Œç»“æœçš„å­—å…¸
    """
    print(f"\nğŸ§  æ¨ç†é—®é¢˜: {question}")
    print("ğŸ” æ­£åœ¨è¿›è¡Œæ·±åº¦æ¨ç†...")
    
    start_time = time.time()
    
    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {
                    "role": "user", 
                    "content": question
                }
            ],
            temperature=0.1,  # æ¨ç†ä»»åŠ¡ä½¿ç”¨è¾ƒä½æ¸©åº¦
            max_tokens=2000,
            # æ¨ç†æ¨¡å‹ç‰¹å®šå‚æ•°
            reasoning_effort="medium"  # æ¨ç†å¼ºåº¦: low, medium, high
        )
        
        elapsed_time = time.time() - start_time
        
        # æå–æ¨ç†å†…å®¹
        reasoning_content = response.choices[0].message.reasoning if hasattr(response.choices[0].message, 'reasoning') else None
        final_answer = response.choices[0].message.content
        usage = response.usage
        
        result = {
            "success": True,
            "question": question,
            "reasoning_process": reasoning_content,
            "final_answer": final_answer,
            "usage": usage,
            "elapsed_time": elapsed_time,
            "model": model
        }
        
        # æ˜¾ç¤ºç»“æœ
        print(f"âœ… æ¨ç†å®Œæˆ (è€—æ—¶: {elapsed_time:.2f}ç§’)")
        
        if reasoning_content:
            print(f"\nğŸ¤” æ¨ç†è¿‡ç¨‹:")
            print("-" * 50)
            print(reasoning_content[:500] + "..." if len(reasoning_content) > 500 else reasoning_content)
        
        print(f"\nğŸ’¡ æœ€ç»ˆç­”æ¡ˆ:")
        print("-" * 50)
        print(final_answer)
        
        print(f"\nğŸ“Š ä½¿ç”¨ç»Ÿè®¡:")
        print(f"   - è¾“å…¥tokens: {usage.prompt_tokens}")
        print(f"   - è¾“å‡ºtokens: {usage.completion_tokens}")
        print(f"   - æ€»tokens: {usage.total_tokens}")
        
        return result
        
    except Exception as e:
        print(f"âŒ æ¨ç†è°ƒç”¨å¤±è´¥: {e}")
        return {
            "success": False,
            "question": question,
            "error": str(e),
            "elapsed_time": time.time() - start_time,
            "model": model
        }


async def async_reasoning_call(client: HarborAI, question: str, model: str = "deepseek-reasoner") -> Dict[str, Any]:
    """
    å¼‚æ­¥æ¨ç†æ¨¡å‹è°ƒç”¨
    
    Args:
        client: HarborAIå®¢æˆ·ç«¯
        question: æ¨ç†é—®é¢˜
        model: æ¨ç†æ¨¡å‹åç§°
        
    Returns:
        Dict: åŒ…å«æ¨ç†è¿‡ç¨‹å’Œç»“æœçš„å­—å…¸
    """
    print(f"\nğŸ§  å¼‚æ­¥æ¨ç†é—®é¢˜: {question}")
    print("ğŸ” æ­£åœ¨è¿›è¡Œå¼‚æ­¥æ·±åº¦æ¨ç†...")
    
    start_time = time.time()
    
    try:
        response = await client.chat.completions.acreate(
            model=model,
            messages=[
                {
                    "role": "user", 
                    "content": question
                }
            ],
            temperature=0.1,
            max_tokens=2000,
            reasoning_effort="high"  # å¼‚æ­¥è°ƒç”¨å¯ä»¥ä½¿ç”¨æ›´é«˜çš„æ¨ç†å¼ºåº¦
        )
        
        elapsed_time = time.time() - start_time
        
        reasoning_content = response.choices[0].message.reasoning if hasattr(response.choices[0].message, 'reasoning') else None
        final_answer = response.choices[0].message.content
        usage = response.usage
        
        result = {
            "success": True,
            "question": question,
            "reasoning_process": reasoning_content,
            "final_answer": final_answer,
            "usage": usage,
            "elapsed_time": elapsed_time,
            "model": model
        }
        
        print(f"âœ… å¼‚æ­¥æ¨ç†å®Œæˆ (è€—æ—¶: {elapsed_time:.2f}ç§’)")
        
        if reasoning_content:
            print(f"\nğŸ¤” æ¨ç†è¿‡ç¨‹:")
            print("-" * 50)
            print(reasoning_content[:500] + "..." if len(reasoning_content) > 500 else reasoning_content)
        
        print(f"\nğŸ’¡ æœ€ç»ˆç­”æ¡ˆ:")
        print("-" * 50)
        print(final_answer)
        
        return result
        
    except Exception as e:
        print(f"âŒ å¼‚æ­¥æ¨ç†è°ƒç”¨å¤±è´¥: {e}")
        return {
            "success": False,
            "question": question,
            "error": str(e),
            "elapsed_time": time.time() - start_time,
            "model": model
        }


def streaming_reasoning(client: HarborAI, question: str, model: str = "deepseek-reasoner") -> Dict[str, Any]:
    """
    æµå¼æ¨ç†æ¨¡å‹è°ƒç”¨
    
    Args:
        client: HarborAIå®¢æˆ·ç«¯
        question: æ¨ç†é—®é¢˜
        model: æ¨ç†æ¨¡å‹åç§°
        
    Returns:
        Dict: åŒ…å«æ¨ç†è¿‡ç¨‹å’Œç»“æœçš„å­—å…¸
    """
    print(f"\nğŸ§  æµå¼æ¨ç†é—®é¢˜: {question}")
    print("ğŸ” æ­£åœ¨è¿›è¡Œæµå¼æ¨ç†...")
    
    start_time = time.time()
    full_reasoning = ""
    full_answer = ""
    chunk_count = 0
    
    try:
        stream = client.chat.completions.create(
            model=model,
            messages=[
                {
                    "role": "user", 
                    "content": question
                }
            ],
            temperature=0.1,
            max_tokens=2000,
            stream=True,
            reasoning_effort="medium"
        )
        
        print("\nğŸ¤” æ¨ç†è¿‡ç¨‹:")
        print("-" * 50)
        
        for chunk in stream:
            chunk_count += 1
            
            # å¤„ç†æ¨ç†è¿‡ç¨‹
            if hasattr(chunk.choices[0].delta, 'reasoning') and chunk.choices[0].delta.reasoning:
                reasoning_content = chunk.choices[0].delta.reasoning
                full_reasoning += reasoning_content
                print(reasoning_content, end="", flush=True)
                time.sleep(0.02)
            
            # å¤„ç†æœ€ç»ˆç­”æ¡ˆ
            elif chunk.choices[0].delta.content:
                if not full_answer:  # ç¬¬ä¸€æ¬¡è¾“å‡ºç­”æ¡ˆæ—¶æ˜¾ç¤ºæ ‡é¢˜
                    print(f"\n\nğŸ’¡ æœ€ç»ˆç­”æ¡ˆ:")
                    print("-" * 50)
                
                content = chunk.choices[0].delta.content
                full_answer += content
                print(content, end="", flush=True)
                time.sleep(0.02)
        
        elapsed_time = time.time() - start_time
        
        print(f"\n\nâœ… æµå¼æ¨ç†å®Œæˆ")
        print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   - æ¨ç†æ—¶é—´: {elapsed_time:.2f}ç§’")
        print(f"   - æ•°æ®å—æ•°: {chunk_count}")
        print(f"   - æ¨ç†é•¿åº¦: {len(full_reasoning)}å­—ç¬¦")
        print(f"   - ç­”æ¡ˆé•¿åº¦: {len(full_answer)}å­—ç¬¦")
        
        return {
            "success": True,
            "question": question,
            "reasoning_process": full_reasoning,
            "final_answer": full_answer,
            "elapsed_time": elapsed_time,
            "chunk_count": chunk_count,
            "model": model
        }
        
    except Exception as e:
        print(f"âŒ æµå¼æ¨ç†è°ƒç”¨å¤±è´¥: {e}")
        return {
            "success": False,
            "question": question,
            "error": str(e),
            "elapsed_time": time.time() - start_time,
            "model": model
        }


def compare_reasoning_efforts(client: HarborAI, question: str, model: str = "deepseek-reasoner"):
    """
    å¯¹æ¯”ä¸åŒæ¨ç†å¼ºåº¦
    
    Args:
        client: HarborAIå®¢æˆ·ç«¯
        question: æ¨ç†é—®é¢˜
        model: æ¨ç†æ¨¡å‹åç§°
    """
    print("\n" + "="*60)
    print("âš–ï¸  ä¸åŒæ¨ç†å¼ºåº¦å¯¹æ¯”")
    print("="*60)
    
    efforts = ["low", "medium", "high"]
    results = []
    
    for effort in efforts:
        print(f"\nğŸ¯ æ¨ç†å¼ºåº¦: {effort}")
        print("-" * 30)
        
        start_time = time.time()
        
        try:
            response = client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": question}],
                temperature=0.1,
                max_tokens=1500,
                reasoning_effort=effort
            )
            
            elapsed_time = time.time() - start_time
            reasoning_content = response.choices[0].message.reasoning if hasattr(response.choices[0].message, 'reasoning') else ""
            final_answer = response.choices[0].message.content
            usage = response.usage
            
            result = {
                "effort": effort,
                "elapsed_time": elapsed_time,
                "reasoning_length": len(reasoning_content),
                "answer_length": len(final_answer),
                "total_tokens": usage.total_tokens,
                "reasoning_content": reasoning_content[:200] + "..." if len(reasoning_content) > 200 else reasoning_content,
                "final_answer": final_answer[:200] + "..." if len(final_answer) > 200 else final_answer
            }
            
            results.append(result)
            
            print(f"â±ï¸  è€—æ—¶: {elapsed_time:.2f}ç§’")
            print(f"ğŸ“ æ¨ç†é•¿åº¦: {len(reasoning_content)}å­—ç¬¦")
            print(f"ğŸ’¬ ç­”æ¡ˆé•¿åº¦: {len(final_answer)}å­—ç¬¦")
            print(f"ğŸ¯ æ€»tokens: {usage.total_tokens}")
            print(f"ğŸ’¡ ç­”æ¡ˆé¢„è§ˆ: {final_answer[:100]}...")
            
        except Exception as e:
            print(f"âŒ æ¨ç†å¼ºåº¦ {effort} å¤±è´¥: {e}")
            results.append({
                "effort": effort,
                "error": str(e)
            })
    
    # å¯¹æ¯”æ€»ç»“
    print(f"\nğŸ“Š æ¨ç†å¼ºåº¦å¯¹æ¯”æ€»ç»“:")
    print("-" * 40)
    successful_results = [r for r in results if "error" not in r]
    
    if successful_results:
        for result in successful_results:
            print(f"{result['effort']:>6}: {result['elapsed_time']:>6.2f}ç§’, "
                  f"{result['total_tokens']:>4}tokens, "
                  f"æ¨ç†{result['reasoning_length']:>4}å­—ç¬¦")
    
    return results


async def batch_reasoning_problems(client: HarborAI, problems: List[Dict[str, str]], model: str = "deepseek-reasoner"):
    """
    æ‰¹é‡å¤„ç†æ¨ç†é—®é¢˜
    
    Args:
        client: HarborAIå®¢æˆ·ç«¯
        problems: é—®é¢˜åˆ—è¡¨ï¼Œæ¯ä¸ªé—®é¢˜åŒ…å«categoryå’Œquestion
        model: æ¨ç†æ¨¡å‹åç§°
    """
    print("\n" + "="*60)
    print("ğŸ“š æ‰¹é‡æ¨ç†é—®é¢˜å¤„ç†")
    print("="*60)
    
    async def solve_problem(problem: Dict[str, str], index: int):
        """è§£å†³å•ä¸ªé—®é¢˜"""
        category = problem["category"]
        question = problem["question"]
        
        print(f"\nğŸ”¢ é—®é¢˜ {index+1} ({category}): {question[:50]}...")
        
        try:
            response = await client.chat.completions.acreate(
                model=model,
                messages=[{"role": "user", "content": question}],
                temperature=0.1,
                max_tokens=1500,
                reasoning_effort="medium"
            )
            
            reasoning_content = response.choices[0].message.reasoning if hasattr(response.choices[0].message, 'reasoning') else ""
            final_answer = response.choices[0].message.content
            
            print(f"âœ… é—®é¢˜ {index+1} è§£å†³å®Œæˆ")
            print(f"   ç­”æ¡ˆ: {final_answer[:100]}...")
            
            return {
                "index": index,
                "category": category,
                "question": question,
                "reasoning": reasoning_content,
                "answer": final_answer,
                "success": True
            }
            
        except Exception as e:
            print(f"âŒ é—®é¢˜ {index+1} è§£å†³å¤±è´¥: {e}")
            return {
                "index": index,
                "category": category,
                "question": question,
                "error": str(e),
                "success": False
            }
    
    # å¹¶å‘å¤„ç†æ‰€æœ‰é—®é¢˜
    start_time = time.time()
    tasks = [solve_problem(problem, i) for i, problem in enumerate(problems)]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    total_time = time.time() - start_time
    
    # ç»Ÿè®¡ç»“æœ
    successful = [r for r in results if isinstance(r, dict) and r.get("success")]
    failed = [r for r in results if isinstance(r, dict) and not r.get("success")]
    
    print(f"\nğŸ“Š æ‰¹é‡å¤„ç†å®Œæˆ:")
    print(f"   æ€»è€—æ—¶: {total_time:.2f}ç§’")
    print(f"   æˆåŠŸ: {len(successful)}/{len(problems)}")
    print(f"   å¤±è´¥: {len(failed)}")
    
    # æŒ‰ç±»åˆ«ç»Ÿè®¡
    if successful:
        categories = {}
        for result in successful:
            cat = result["category"]
            if cat not in categories:
                categories[cat] = 0
            categories[cat] += 1
        
        print(f"\nğŸ“ˆ æŒ‰ç±»åˆ«ç»Ÿè®¡:")
        for cat, count in categories.items():
            print(f"   {cat}: {count}ä¸ªé—®é¢˜")
    
    return results


def interactive_reasoning_session(client: HarborAI, model: str = "deepseek-reasoner"):
    """
    äº¤äº’å¼æ¨ç†ä¼šè¯
    
    Args:
        client: HarborAIå®¢æˆ·ç«¯
        model: æ¨ç†æ¨¡å‹åç§°
    """
    print("\n" + "="*60)
    print("ğŸ§  äº¤äº’å¼æ¨ç†ä¼šè¯")
    print("="*60)
    print("ğŸ’¡ è¾“å…¥å¤æ‚çš„æ¨ç†é—®é¢˜ï¼ŒAIå°†å±•ç¤ºè¯¦ç»†çš„æ€è€ƒè¿‡ç¨‹")
    print("ğŸ’¡ è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º")
    print("ğŸ’¡ è¾“å…¥ 'effort low/medium/high' è°ƒæ•´æ¨ç†å¼ºåº¦")
    
    current_effort = "medium"
    
    while True:
        try:
            user_input = input(f"\nğŸ¤” æ‚¨çš„æ¨ç†é—®é¢˜ (å½“å‰æ¨ç†å¼ºåº¦: {current_effort}): ").strip()
            
            if user_input.lower() in ['quit', 'exit', 'é€€å‡º']:
                print("ğŸ‘‹ æ¨ç†ä¼šè¯ç»“æŸï¼")
                break
            
            if user_input.startswith('effort '):
                new_effort = user_input.split(' ', 1)[1].strip()
                if new_effort in ['low', 'medium', 'high']:
                    current_effort = new_effort
                    print(f"âœ… æ¨ç†å¼ºåº¦å·²è°ƒæ•´ä¸º: {current_effort}")
                else:
                    print("âŒ æ¨ç†å¼ºåº¦å¿…é¡»æ˜¯: low, medium, high")
                continue
            
            if not user_input:
                continue
            
            # è¿›è¡Œæ¨ç†
            reasoning_call(client, user_input, model)
            
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ æ¨ç†ä¼šè¯è¢«ä¸­æ–­ï¼")
            break
        except Exception as e:
            print(f"\nâŒ æ¨ç†å‡ºé”™: {e}")


async def main():
    """ä¸»å‡½æ•°"""
    print("="*60)
    print("ğŸ§  HarborAI æ¨ç†æ¨¡å‹è°ƒç”¨ç¤ºä¾‹")
    print("="*60)
    
    try:
        # åˆ›å»ºå®¢æˆ·ç«¯
        client = create_client()
        print("âœ… HarborAI å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        
        # æµ‹è¯•æ¨ç†é—®é¢˜
        reasoning_problems = [
            "ä¸€ä¸ªå†œå¤«æœ‰17åªç¾Šï¼Œé™¤äº†9åªä»¥å¤–éƒ½æ­»äº†ï¼Œè¯·é—®å†œå¤«è¿˜æœ‰å‡ åªç¾Šï¼Ÿè¯·è¯¦ç»†è§£é‡Šä½ çš„æ¨ç†è¿‡ç¨‹ã€‚",
            "å¦‚æœä»Šå¤©æ˜¯æ˜ŸæœŸä¸‰ï¼Œé‚£ä¹ˆ100å¤©åæ˜¯æ˜ŸæœŸå‡ ï¼Ÿè¯·å±•ç¤ºè®¡ç®—æ­¥éª¤ã€‚",
            "æœ‰3ä¸ªå¼€å…³æ§åˆ¶3ç›ç¯ï¼Œä½ åœ¨å¦ä¸€ä¸ªæˆ¿é—´çœ‹ä¸åˆ°ç¯ï¼Œåªèƒ½è¿›å…¥æˆ¿é—´ä¸€æ¬¡ï¼Œå¦‚ä½•ç¡®å®šå“ªä¸ªå¼€å…³æ§åˆ¶å“ªç›ç¯ï¼Ÿ",
            "ä¸€ä¸ªæ•°åˆ—ï¼š2, 6, 12, 20, 30, ?ï¼Œè¯·æ‰¾å‡ºè§„å¾‹å¹¶è®¡ç®—ä¸‹ä¸€ä¸ªæ•°ã€‚"
        ]
        
        # 1. åŸºç¡€æ¨ç†è°ƒç”¨
        print("\nğŸ”¹ 1. åŸºç¡€æ¨ç†è°ƒç”¨ç¤ºä¾‹")
        reasoning_call(client, reasoning_problems[0])
        
        # 2. å¼‚æ­¥æ¨ç†è°ƒç”¨
        print("\nğŸ”¹ 2. å¼‚æ­¥æ¨ç†è°ƒç”¨ç¤ºä¾‹")
        await async_reasoning_call(client, reasoning_problems[1])
        
        # 3. æµå¼æ¨ç†è°ƒç”¨
        print("\nğŸ”¹ 3. æµå¼æ¨ç†è°ƒç”¨ç¤ºä¾‹")
        streaming_reasoning(client, reasoning_problems[2])
        
        # 4. ä¸åŒæ¨ç†å¼ºåº¦å¯¹æ¯”
        print("\nğŸ”¹ 4. ä¸åŒæ¨ç†å¼ºåº¦å¯¹æ¯”")
        compare_reasoning_efforts(client, reasoning_problems[3])
        
        # 5. æ‰¹é‡æ¨ç†é—®é¢˜
        print("\nğŸ”¹ 5. æ‰¹é‡æ¨ç†é—®é¢˜å¤„ç†")
        batch_problems = [
            {"category": "é€»è¾‘æ¨ç†", "question": "æ‰€æœ‰çš„çŒ«éƒ½æ˜¯åŠ¨ç‰©ï¼Œæ‰€æœ‰çš„åŠ¨ç‰©éƒ½éœ€è¦é£Ÿç‰©ï¼Œå› æ­¤æ‰€æœ‰çš„çŒ«éƒ½éœ€è¦é£Ÿç‰©ã€‚è¿™ä¸ªæ¨ç†æ˜¯å¦æ­£ç¡®ï¼Ÿ"},
            {"category": "æ•°å­¦è®¡ç®—", "question": "è®¡ç®— (2^10 * 3^5) / (2^7 * 3^3) çš„å€¼"},
            {"category": "æ¦‚ç‡é—®é¢˜", "question": "æŠ›ç¡¬å¸3æ¬¡ï¼Œè‡³å°‘å‡ºç°ä¸€æ¬¡æ­£é¢çš„æ¦‚ç‡æ˜¯å¤šå°‘ï¼Ÿ"},
            {"category": "å‡ ä½•é—®é¢˜", "question": "ä¸€ä¸ªåœ†çš„åŠå¾„æ˜¯5cmï¼Œæ±‚å…¶é¢ç§¯å’Œå‘¨é•¿"}
        ]
        await batch_reasoning_problems(client, batch_problems)
        
        # 6. äº¤äº’å¼æ¨ç†ä¼šè¯
        print("\nğŸ”¹ 6. äº¤äº’å¼æ¨ç†ä¼šè¯")
        choice = input("æ˜¯å¦å¼€å§‹äº¤äº’å¼æ¨ç†ä¼šè¯ï¼Ÿ(y/n): ").strip().lower()
        if choice in ['y', 'yes', 'æ˜¯']:
            interactive_reasoning_session(client)
        
        print(f"\nğŸ‰ æ‰€æœ‰æ¨ç†æ¨¡å‹ç¤ºä¾‹æ‰§è¡Œå®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        print("\nğŸ’¡ è¯·æ£€æŸ¥:")
        print("1. æ˜¯å¦æ­£ç¡®é…ç½®äº†ç¯å¢ƒå˜é‡")
        print("2. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
        print("3. APIå¯†é’¥æ˜¯å¦æœ‰æ•ˆ")
        print("4. æ˜¯å¦æœ‰æ¨ç†æ¨¡å‹çš„è®¿é—®æƒé™")


if __name__ == "__main__":
    asyncio.run(main())