#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HarborAI ä¸­çº§æ—¥å¿—åŠŸèƒ½æ¼”ç¤º - æ—¥å¿—ç›‘æ§ä¸åˆ†æ

è¿™ä¸ªè„šæœ¬æ¼”ç¤ºäº† HarborAI æ—¥å¿—ç³»ç»Ÿçš„ä¸­çº§åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
1. çœŸå®æ¨¡å‹è°ƒç”¨å’Œæ—¥å¿—è®°å½•
2. ç»“æ„åŒ–æ—¥å¿—è®°å½•
3. æ€§èƒ½æŒ‡æ ‡ç›‘æ§
4. é”™è¯¯è¿½è¸ªå’Œåˆ†æ
5. å‘Šè­¦è§„åˆ™è®¾ç½®
6. æ—¥å¿—æŸ¥çœ‹å’Œåˆ†æ
7. æ–°çš„å¸ƒå±€æ¨¡å¼æ¼”ç¤ºï¼ˆclassic å’Œ enhancedï¼‰
8. æ–°çš„ trace_id æ ¼å¼æ”¯æŒï¼ˆhb_ å‰ç¼€ï¼‰
9. é…å¯¹æ˜¾ç¤ºå’Œç»Ÿè®¡åˆ†æ

ä½¿ç”¨æ–¹æ³•ï¼š
    python logging_monitoring.py                    # è¿è¡Œå®Œæ•´æ¼”ç¤º
    python logging_monitoring.py --real-calls       # è¿›è¡ŒçœŸå®æ¨¡å‹è°ƒç”¨
    python logging_monitoring.py --monitoring-only  # ä»…æ¼”ç¤ºç›‘æ§åŠŸèƒ½
    python logging_monitoring.py --layout-demo      # æ¼”ç¤ºå¸ƒå±€æ¨¡å¼
    python logging_monitoring.py --trace-id-demo    # æ¼”ç¤º trace_id åŠŸèƒ½

æ›´æ–°å†…å®¹ï¼š
- æ”¯æŒæ–°çš„ hb_ å‰ç¼€ trace_id æ ¼å¼
- æ·»åŠ å¸ƒå±€æ¨¡å¼æ¼”ç¤ºï¼ˆclassic å’Œ enhancedï¼‰
- å¢å¼ºæ€§èƒ½ç›‘æ§å’Œå‘Šè­¦åŠŸèƒ½
- æ”¹è¿›é”™è¯¯å¤„ç†å’Œç”¨æˆ·ä½“éªŒ
- æ·»åŠ é…å¯¹æ˜¾ç¤ºå’Œç»Ÿè®¡åˆ†æ

ä½œè€…: HarborAI Team
ç‰ˆæœ¬: 2.0.0
æ›´æ–°æ—¶é—´: 2025-01-14
"""

import os
import json
import time
import asyncio
import logging
import sqlite3
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Callable, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
from pathlib import Path
import statistics
import threading
from collections import defaultdict, deque
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# æ·»åŠ æœ¬åœ°æºç è·¯å¾„
import sys
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..'))

try:
    from harborai import HarborAI
except ImportError:
    print("âŒ æ— æ³•å¯¼å…¥ HarborAIï¼Œè¯·æ£€æŸ¥è·¯å¾„é…ç½®")
    exit(1)


class LogLevel(Enum):
    """æ—¥å¿—çº§åˆ«"""
    DEBUG = "DEBUG"
    INFO = "INFO"
    WARNING = "WARNING"
    ERROR = "ERROR"
    CRITICAL = "CRITICAL"


class MetricType(Enum):
    """æŒ‡æ ‡ç±»å‹"""
    COUNTER = "counter"
    GAUGE = "gauge"
    HISTOGRAM = "histogram"
    TIMER = "timer"


@dataclass
class LogEntry:
    """æ—¥å¿—æ¡ç›®"""
    timestamp: str
    level: LogLevel
    message: str
    module: str
    function: str
    request_id: str = None
    user_id: str = None
    session_id: str = None
    model_name: str = None
    response_time: float = None
    token_count: int = None
    cost: float = None
    error_code: str = None
    stack_trace: str = None
    metadata: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}


@dataclass
class MetricEntry:
    """æŒ‡æ ‡æ¡ç›®"""
    timestamp: str
    name: str
    type: MetricType
    value: float
    tags: Dict[str, str] = None
    
    def __post_init__(self):
        if self.tags is None:
            self.tags = {}


@dataclass
class AlertRule:
    """å‘Šè­¦è§„åˆ™"""
    name: str
    metric_name: str
    condition: str  # >, <, >=, <=, ==
    threshold: float
    duration: int  # æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
    enabled: bool = True
    description: str = ""


class StructuredLogger:
    """ç»“æ„åŒ–æ—¥å¿—è®°å½•å™¨"""
    
    def __init__(self, name: str, db_path: str = "monitoring.db"):
        self.name = name
        self.db_path = db_path
        self.init_database()
        
        # è®¾ç½®æ ‡å‡†æ—¥å¿—è®°å½•å™¨
        self.logger = logging.getLogger(name)
        self.logger.setLevel(logging.DEBUG)
        
        # åˆ›å»ºæ–‡ä»¶å¤„ç†å™¨
        log_file = f"{name}.log"
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setLevel(logging.DEBUG)
        
        # åˆ›å»ºæ§åˆ¶å°å¤„ç†å™¨
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        
        # åˆ›å»ºæ ¼å¼å™¨
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        file_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)
        
        # æ·»åŠ å¤„ç†å™¨
        if not self.logger.handlers:
            self.logger.addHandler(file_handler)
            self.logger.addHandler(console_handler)
    
    def init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # åˆ›å»ºæ—¥å¿—è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS logs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT NOT NULL,
                level TEXT NOT NULL,
                message TEXT NOT NULL,
                module TEXT NOT NULL,
                function TEXT NOT NULL,
                request_id TEXT,
                user_id TEXT,
                session_id TEXT,
                model_name TEXT,
                response_time REAL,
                token_count INTEGER,
                cost REAL,
                error_code TEXT,
                stack_trace TEXT,
                metadata TEXT
            )
        ''')
        
        # åˆ›å»ºæŒ‡æ ‡è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS metrics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT NOT NULL,
                name TEXT NOT NULL,
                type TEXT NOT NULL,
                value REAL NOT NULL,
                tags TEXT
            )
        ''')
        
        # åˆ›å»ºå‘Šè­¦è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS alerts (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT NOT NULL,
                rule_name TEXT NOT NULL,
                metric_name TEXT NOT NULL,
                current_value REAL NOT NULL,
                threshold REAL NOT NULL,
                message TEXT NOT NULL,
                resolved BOOLEAN DEFAULT FALSE,
                resolved_at TEXT
            )
        ''')
        
        # åˆ›å»ºç´¢å¼•
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_logs_timestamp ON logs(timestamp)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_logs_level ON logs(level)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_logs_request_id ON logs(request_id)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_metrics_timestamp ON metrics(timestamp)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_metrics_name ON metrics(name)')
        
        conn.commit()
        conn.close()
    
    def log(self, entry: LogEntry):
        """è®°å½•æ—¥å¿—æ¡ç›®"""
        # è®°å½•åˆ°æ ‡å‡†æ—¥å¿—
        log_level = getattr(logging, entry.level.value)
        self.logger.log(log_level, entry.message)
        
        # è®°å½•åˆ°æ•°æ®åº“
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO logs 
            (timestamp, level, message, module, function, request_id, user_id, 
             session_id, model_name, response_time, token_count, cost, 
             error_code, stack_trace, metadata)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            entry.timestamp, entry.level.value, entry.message, entry.module,
            entry.function, entry.request_id, entry.user_id, entry.session_id,
            entry.model_name, entry.response_time, entry.token_count, entry.cost,
            entry.error_code, entry.stack_trace,
            json.dumps(entry.metadata) if entry.metadata else None
        ))
        
        conn.commit()
        conn.close()
    
    def debug(self, message: str, **kwargs):
        """è®°å½•DEBUGçº§åˆ«æ—¥å¿—"""
        entry = LogEntry(
            timestamp=datetime.now().isoformat(),
            level=LogLevel.DEBUG,
            message=message,
            module=self.name,
            function="debug",
            **kwargs
        )
        self.log(entry)
    
    def info(self, message: str, **kwargs):
        """è®°å½•INFOçº§åˆ«æ—¥å¿—"""
        entry = LogEntry(
            timestamp=datetime.now().isoformat(),
            level=LogLevel.INFO,
            message=message,
            module=self.name,
            function="info",
            **kwargs
        )
        self.log(entry)
    
    def warning(self, message: str, **kwargs):
        """è®°å½•WARNINGçº§åˆ«æ—¥å¿—"""
        entry = LogEntry(
            timestamp=datetime.now().isoformat(),
            level=LogLevel.WARNING,
            message=message,
            module=self.name,
            function="warning",
            **kwargs
        )
        self.log(entry)
    
    def error(self, message: str, **kwargs):
        """è®°å½•ERRORçº§åˆ«æ—¥å¿—"""
        entry = LogEntry(
            timestamp=datetime.now().isoformat(),
            level=LogLevel.ERROR,
            message=message,
            module=self.name,
            function="error",
            **kwargs
        )
        self.log(entry)
    
    def critical(self, message: str, **kwargs):
        """è®°å½•CRITICALçº§åˆ«æ—¥å¿—"""
        entry = LogEntry(
            timestamp=datetime.now().isoformat(),
            level=LogLevel.CRITICAL,
            message=message,
            module=self.name,
            function="critical",
            **kwargs
        )
        self.log(entry)


class MetricsCollector:
    """æŒ‡æ ‡æ”¶é›†å™¨"""
    
    def __init__(self, db_path: str = "monitoring.db"):
        self.db_path = db_path
        self.metrics_buffer = deque(maxlen=1000)  # å†…å­˜ç¼“å†²åŒº
        self.counters = defaultdict(float)
        self.gauges = defaultdict(float)
        self.histograms = defaultdict(list)
        self.timers = defaultdict(list)
        
        # å¯åŠ¨åå°çº¿ç¨‹å®šæœŸåˆ·æ–°æŒ‡æ ‡
        self.flush_thread = threading.Thread(target=self._flush_metrics_loop, daemon=True)
        self.flush_thread.start()
    
    def _flush_metrics_loop(self):
        """åå°çº¿ç¨‹å®šæœŸåˆ·æ–°æŒ‡æ ‡åˆ°æ•°æ®åº“"""
        while True:
            time.sleep(10)  # æ¯10ç§’åˆ·æ–°ä¸€æ¬¡
            self._flush_metrics()
    
    def _flush_metrics(self):
        """åˆ·æ–°æŒ‡æ ‡åˆ°æ•°æ®åº“"""
        if not self.metrics_buffer:
            return
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # æ‰¹é‡æ’å…¥æŒ‡æ ‡
        metrics_to_insert = []
        while self.metrics_buffer:
            metric = self.metrics_buffer.popleft()
            metrics_to_insert.append((
                metric.timestamp, metric.name, metric.type.value,
                metric.value, json.dumps(metric.tags) if metric.tags else None
            ))
        
        if metrics_to_insert:
            cursor.executemany('''
                INSERT INTO metrics (timestamp, name, type, value, tags)
                VALUES (?, ?, ?, ?, ?)
            ''', metrics_to_insert)
        
        conn.commit()
        conn.close()
    
    def record_metric(self, metric: MetricEntry):
        """è®°å½•æŒ‡æ ‡"""
        self.metrics_buffer.append(metric)
        
        # æ›´æ–°å†…å­˜ä¸­çš„æŒ‡æ ‡
        if metric.type == MetricType.COUNTER:
            self.counters[metric.name] += metric.value
        elif metric.type == MetricType.GAUGE:
            self.gauges[metric.name] = metric.value
        elif metric.type == MetricType.HISTOGRAM:
            self.histograms[metric.name].append(metric.value)
            # ä¿æŒæœ€è¿‘1000ä¸ªå€¼
            if len(self.histograms[metric.name]) > 1000:
                self.histograms[metric.name] = self.histograms[metric.name][-1000:]
        elif metric.type == MetricType.TIMER:
            self.timers[metric.name].append(metric.value)
            # ä¿æŒæœ€è¿‘1000ä¸ªå€¼
            if len(self.timers[metric.name]) > 1000:
                self.timers[metric.name] = self.timers[metric.name][-1000:]
    
    def increment_counter(self, name: str, value: float = 1.0, tags: Dict[str, str] = None):
        """å¢åŠ è®¡æ•°å™¨"""
        metric = MetricEntry(
            timestamp=datetime.now().isoformat(),
            name=name,
            type=MetricType.COUNTER,
            value=value,
            tags=tags
        )
        self.record_metric(metric)
    
    def set_gauge(self, name: str, value: float, tags: Dict[str, str] = None):
        """è®¾ç½®ä»ªè¡¨ç›˜å€¼"""
        metric = MetricEntry(
            timestamp=datetime.now().isoformat(),
            name=name,
            type=MetricType.GAUGE,
            value=value,
            tags=tags
        )
        self.record_metric(metric)
    
    def record_histogram(self, name: str, value: float, tags: Dict[str, str] = None):
        """è®°å½•ç›´æ–¹å›¾å€¼"""
        metric = MetricEntry(
            timestamp=datetime.now().isoformat(),
            name=name,
            type=MetricType.HISTOGRAM,
            value=value,
            tags=tags
        )
        self.record_metric(metric)
    
    def record_timer(self, name: str, duration: float, tags: Dict[str, str] = None):
        """è®°å½•è®¡æ—¶å™¨å€¼"""
        metric = MetricEntry(
            timestamp=datetime.now().isoformat(),
            name=name,
            type=MetricType.TIMER,
            value=duration,
            tags=tags
        )
        self.record_metric(metric)
    
    def get_metric_stats(self, name: str, metric_type: MetricType = None) -> Dict[str, Any]:
        """è·å–æŒ‡æ ‡ç»Ÿè®¡"""
        if metric_type == MetricType.COUNTER or name in self.counters:
            return {"type": "counter", "value": self.counters[name]}
        
        elif metric_type == MetricType.GAUGE or name in self.gauges:
            return {"type": "gauge", "value": self.gauges[name]}
        
        elif metric_type == MetricType.HISTOGRAM or name in self.histograms:
            values = self.histograms[name]
            if not values:
                return {"type": "histogram", "count": 0}
            
            return {
                "type": "histogram",
                "count": len(values),
                "min": min(values),
                "max": max(values),
                "mean": statistics.mean(values),
                "median": statistics.median(values),
                "p95": statistics.quantiles(values, n=20)[18] if len(values) >= 20 else max(values),
                "p99": statistics.quantiles(values, n=100)[98] if len(values) >= 100 else max(values)
            }
        
        elif metric_type == MetricType.TIMER or name in self.timers:
            values = self.timers[name]
            if not values:
                return {"type": "timer", "count": 0}
            
            return {
                "type": "timer",
                "count": len(values),
                "min": min(values),
                "max": max(values),
                "mean": statistics.mean(values),
                "median": statistics.median(values),
                "p95": statistics.quantiles(values, n=20)[18] if len(values) >= 20 else max(values),
                "p99": statistics.quantiles(values, n=100)[98] if len(values) >= 100 else max(values)
            }
        
        return {}


class AlertManager:
    """å‘Šè­¦ç®¡ç†å™¨"""
    
    def __init__(self, db_path: str = "monitoring.db"):
        self.db_path = db_path
        self.rules = []
        self.alert_handlers = []
        
        # é»˜è®¤å‘Šè­¦è§„åˆ™
        self.add_rule(AlertRule(
            name="high_response_time",
            metric_name="api_response_time",
            condition=">",
            threshold=5.0,
            duration=60,
            description="APIå“åº”æ—¶é—´è¿‡é«˜"
        ))
        
        self.add_rule(AlertRule(
            name="high_error_rate",
            metric_name="api_error_rate",
            condition=">",
            threshold=0.1,
            duration=300,
            description="APIé”™è¯¯ç‡è¿‡é«˜"
        ))
        
        self.add_rule(AlertRule(
            name="high_cost",
            metric_name="hourly_cost",
            condition=">",
            threshold=1.0,
            duration=3600,
            description="å°æ—¶æˆæœ¬è¿‡é«˜"
        ))
    
    def add_rule(self, rule: AlertRule):
        """æ·»åŠ å‘Šè­¦è§„åˆ™"""
        self.rules.append(rule)
    
    def add_alert_handler(self, handler: Callable[[str, Dict[str, Any]], None]):
        """æ·»åŠ å‘Šè­¦å¤„ç†å™¨"""
        self.alert_handlers.append(handler)
    
    def check_alerts(self, metrics: Dict[str, Any]):
        """æ£€æŸ¥å‘Šè­¦æ¡ä»¶"""
        for rule in self.rules:
            if not rule.enabled:
                continue
            
            if rule.metric_name not in metrics:
                continue
            
            current_value = metrics[rule.metric_name]
            
            # æ£€æŸ¥æ¡ä»¶
            triggered = False
            if rule.condition == ">" and current_value > rule.threshold:
                triggered = True
            elif rule.condition == "<" and current_value < rule.threshold:
                triggered = True
            elif rule.condition == ">=" and current_value >= rule.threshold:
                triggered = True
            elif rule.condition == "<=" and current_value <= rule.threshold:
                triggered = True
            elif rule.condition == "==" and current_value == rule.threshold:
                triggered = True
            
            if triggered:
                self._trigger_alert(rule, current_value)
    
    def _trigger_alert(self, rule: AlertRule, current_value: float):
        """è§¦å‘å‘Šè­¦"""
        alert_data = {
            "rule_name": rule.name,
            "metric_name": rule.metric_name,
            "current_value": current_value,
            "threshold": rule.threshold,
            "condition": rule.condition,
            "description": rule.description,
            "timestamp": datetime.now().isoformat()
        }
        
        # è®°å½•åˆ°æ•°æ®åº“
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO alerts 
            (timestamp, rule_name, metric_name, current_value, threshold, message)
            VALUES (?, ?, ?, ?, ?, ?)
        ''', (
            alert_data["timestamp"], rule.name, rule.metric_name,
            current_value, rule.threshold, rule.description
        ))
        
        conn.commit()
        conn.close()
        
        # è°ƒç”¨å‘Šè­¦å¤„ç†å™¨
        for handler in self.alert_handlers:
            try:
                handler(rule.name, alert_data)
            except Exception as e:
                print(f"å‘Šè­¦å¤„ç†å™¨é”™è¯¯: {e}")


class HarborAIMonitor:
    """HarborAIç›‘æ§å™¨"""
    
    def __init__(self, db_path: str = "monitoring.db"):
        self.logger = StructuredLogger("harborai_monitor", db_path)
        self.metrics = MetricsCollector(db_path)
        self.alerts = AlertManager(db_path)
        
        # æ·»åŠ æ§åˆ¶å°å‘Šè­¦å¤„ç†å™¨
        self.alerts.add_alert_handler(self._console_alert_handler)
        
        # æ€§èƒ½ç»Ÿè®¡
        self.request_count = 0
        self.error_count = 0
        self.total_response_time = 0
        self.total_cost = 0
    
    def _console_alert_handler(self, rule_name: str, alert_data: Dict[str, Any]):
        """æ§åˆ¶å°å‘Šè­¦å¤„ç†å™¨"""
        print(f"\nğŸš¨ å‘Šè­¦è§¦å‘: {rule_name}")
        print(f"   æŒ‡æ ‡: {alert_data['metric_name']}")
        print(f"   å½“å‰å€¼: {alert_data['current_value']}")
        print(f"   é˜ˆå€¼: {alert_data['threshold']}")
        print(f"   æè¿°: {alert_data['description']}")
        print(f"   æ—¶é—´: {alert_data['timestamp']}")
    
    async def monitor_api_call(self, client: HarborAI, model_name: str, 
                              prompt: str, **kwargs) -> Any:
        """
        ç›‘æ§APIè°ƒç”¨
        
        Args:
            client: HarborAIå®¢æˆ·ç«¯
            model_name: æ¨¡å‹åç§°
            prompt: æç¤ºè¯
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            APIå“åº”
        """
        request_id = f"req_{int(time.time() * 1000)}_{hash(prompt) % 10000}"
        start_time = time.time()
        
        # è®°å½•è¯·æ±‚å¼€å§‹
        self.logger.info(
            f"APIè¯·æ±‚å¼€å§‹: {model_name}",
            request_id=request_id,
            model_name=model_name,
            metadata={
                "prompt_length": len(prompt),
                "temperature": kwargs.get("temperature", 0.7),
                "max_tokens": kwargs.get("max_tokens")  # é»˜è®¤æ— é™åˆ¶ï¼Œç”±æ¨¡å‹å‚å•†æ§åˆ¶
            }
        )
        
        # å¢åŠ è¯·æ±‚è®¡æ•°
        self.metrics.increment_counter("api_requests_total", tags={"model": model_name})
        self.request_count += 1
        
        try:
            response = await client.chat.completions.acreate(
                model=model_name,
                messages=[{"role": "user", "content": prompt}],
                **kwargs
            )
            
            response_time = time.time() - start_time
            usage = response.usage
            
            # è®¡ç®—æˆæœ¬ï¼ˆç®€åŒ–ï¼‰
            cost = (usage.total_tokens / 1000) * 0.002
            
            # è®°å½•æˆåŠŸå“åº”
            self.logger.info(
                f"APIè¯·æ±‚æˆåŠŸ: {model_name}",
                request_id=request_id,
                model_name=model_name,
                response_time=response_time,
                token_count=usage.total_tokens,
                cost=cost,
                metadata={
                    "input_tokens": usage.prompt_tokens,
                    "output_tokens": usage.completion_tokens,
                    "response_length": len(response.choices[0].message.content)
                }
            )
            
            # è®°å½•æŒ‡æ ‡
            self.metrics.record_timer("api_response_time", response_time, tags={"model": model_name})
            self.metrics.record_histogram("api_token_count", usage.total_tokens, tags={"model": model_name})
            self.metrics.record_histogram("api_cost", cost, tags={"model": model_name})
            self.metrics.increment_counter("api_requests_success", tags={"model": model_name})
            
            # æ›´æ–°ç»Ÿè®¡
            self.total_response_time += response_time
            self.total_cost += cost
            
            return response
            
        except Exception as e:
            response_time = time.time() - start_time
            
            # è®°å½•é”™è¯¯
            self.logger.error(
                f"APIè¯·æ±‚å¤±è´¥: {model_name}",
                request_id=request_id,
                model_name=model_name,
                response_time=response_time,
                error_code=type(e).__name__,
                stack_trace=str(e),
                metadata={
                    "prompt_length": len(prompt)
                }
            )
            
            # è®°å½•é”™è¯¯æŒ‡æ ‡
            self.metrics.increment_counter("api_requests_error", tags={"model": model_name, "error": type(e).__name__})
            self.error_count += 1
            
            raise e
        
        finally:
            # æ›´æ–°å®æ—¶æŒ‡æ ‡
            if self.request_count > 0:
                error_rate = self.error_count / self.request_count
                avg_response_time = self.total_response_time / self.request_count
                
                self.metrics.set_gauge("api_error_rate", error_rate)
                self.metrics.set_gauge("api_avg_response_time", avg_response_time)
                self.metrics.set_gauge("api_total_cost", self.total_cost)
                
                # æ£€æŸ¥å‘Šè­¦
                self.alerts.check_alerts({
                    "api_response_time": avg_response_time,
                    "api_error_rate": error_rate,
                    "hourly_cost": self.total_cost  # ç®€åŒ–ä¸ºæ€»æˆæœ¬
                })
    
    def get_monitoring_dashboard(self) -> Dict[str, Any]:
        """è·å–ç›‘æ§ä»ªè¡¨æ¿æ•°æ®"""
        dashboard = {
            "overview": {
                "total_requests": self.request_count,
                "error_count": self.error_count,
                "success_rate": (self.request_count - self.error_count) / self.request_count if self.request_count > 0 else 0,
                "total_cost": self.total_cost,
                "avg_response_time": self.total_response_time / self.request_count if self.request_count > 0 else 0
            },
            "metrics": {}
        }
        
        # è·å–å„ç§æŒ‡æ ‡ç»Ÿè®¡
        metric_names = [
            "api_response_time", "api_token_count", "api_cost",
            "api_requests_total", "api_requests_success", "api_requests_error"
        ]
        
        for name in metric_names:
            stats = self.metrics.get_metric_stats(name)
            if stats:
                dashboard["metrics"][name] = stats
        
        return dashboard
    
    def get_recent_logs(self, limit: int = 50, level: LogLevel = None) -> List[Dict[str, Any]]:
        """è·å–æœ€è¿‘çš„æ—¥å¿—"""
        conn = sqlite3.connect(self.logger.db_path)
        cursor = conn.cursor()
        
        where_clause = ""
        params = []
        
        if level:
            where_clause = "WHERE level = ?"
            params.append(level.value)
        
        cursor.execute(f'''
            SELECT timestamp, level, message, module, function, request_id, 
                   model_name, response_time, token_count, cost, error_code
            FROM logs
            {where_clause}
            ORDER BY timestamp DESC
            LIMIT ?
        ''', params + [limit])
        
        logs = []
        for row in cursor.fetchall():
            logs.append({
                "timestamp": row[0],
                "level": row[1],
                "message": row[2],
                "module": row[3],
                "function": row[4],
                "request_id": row[5],
                "model_name": row[6],
                "response_time": row[7],
                "token_count": row[8],
                "cost": row[9],
                "error_code": row[10]
            })
        
        conn.close()
        return logs
    
    def get_recent_alerts(self, limit: int = 20) -> List[Dict[str, Any]]:
        """è·å–æœ€è¿‘çš„å‘Šè­¦"""
        conn = sqlite3.connect(self.alerts.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT timestamp, rule_name, metric_name, current_value, 
                   threshold, message, resolved
            FROM alerts
            ORDER BY timestamp DESC
            LIMIT ?
        ''', [limit])
        
        alerts = []
        for row in cursor.fetchall():
            alerts.append({
                "timestamp": row[0],
                "rule_name": row[1],
                "metric_name": row[2],
                "current_value": row[3],
                "threshold": row[4],
                "message": row[5],
                "resolved": bool(row[6])
            })
        
        conn.close()
        return alerts


async def monitoring_demo():
    """ç›‘æ§æ¼”ç¤º"""
    print("="*60)
    print("ğŸ“Š HarborAI æ—¥å¿—ç›‘æ§ç¤ºä¾‹")
    print("="*60)
    
    # åˆå§‹åŒ–ç›‘æ§å™¨
    monitor = HarborAIMonitor()
    
    print("âœ… ç›‘æ§ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    # æ£€æŸ¥APIå¯†é’¥
    api_key = os.getenv("DEEPSEEK_API_KEY")
    if not api_key:
        print("âŒ éœ€è¦DEEPSEEK_API_KEYç¯å¢ƒå˜é‡")
        return
    
    client = HarborAI(api_key=api_key, base_url="https://api.deepseek.com")
    
    # æµ‹è¯•åœºæ™¯
    test_scenarios = [
        {"prompt": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚", "model": "deepseek-chat"},
        {"prompt": "è¯·å†™ä¸€ä¸ªPythonå‡½æ•°æ¥è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—ã€‚", "model": "deepseek-chat"},
        {"prompt": "è¯·è§£é‡Šä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ã€‚", "model": "deepseek-chat"},
        {"prompt": "è¿™æ˜¯ä¸€ä¸ªæ•…æ„çš„é”™è¯¯æµ‹è¯•", "model": "invalid-model"},  # æ•…æ„çš„é”™è¯¯
        {"prompt": "è¯·åˆ†æå½“å‰AIæŠ€æœ¯çš„å‘å±•è¶‹åŠ¿ã€‚", "model": "deepseek-chat"}
    ]
    
    print(f"\nğŸ”¹ 1. æ‰§è¡Œç›‘æ§æµ‹è¯•")
    print(f"ğŸ“‹ å°†æ‰§è¡Œ {len(test_scenarios)} ä¸ªæµ‹è¯•åœºæ™¯")
    
    # æ‰§è¡Œæµ‹è¯•åœºæ™¯
    for i, scenario in enumerate(test_scenarios, 1):
        print(f"\nğŸ¯ åœºæ™¯ {i}: {scenario['prompt'][:50]}...")
        
        try:
            response = await monitor.monitor_api_call(
                client, scenario["model"], scenario["prompt"],
                max_tokens=200, temperature=0.7
            )
            print(f"   âœ… æˆåŠŸ - å“åº”é•¿åº¦: {len(response.choices[0].message.content)}")
        except Exception as e:
            print(f"   âŒ å¤±è´¥: {e}")
        
        # çŸ­æš‚å»¶è¿Ÿ
        await asyncio.sleep(1)
    
    # æ˜¾ç¤ºç›‘æ§ä»ªè¡¨æ¿
    print(f"\nğŸ”¹ 2. ç›‘æ§ä»ªè¡¨æ¿")
    dashboard = monitor.get_monitoring_dashboard()
    
    overview = dashboard["overview"]
    print(f"ğŸ“Š æ€»ä½“æ¦‚è§ˆ:")
    print(f"   æ€»è¯·æ±‚æ•°: {overview['total_requests']}")
    print(f"   é”™è¯¯æ•°é‡: {overview['error_count']}")
    print(f"   æˆåŠŸç‡: {overview['success_rate']:.1%}")
    print(f"   æ€»æˆæœ¬: Â¥{overview['total_cost']:.4f}")
    print(f"   å¹³å‡å“åº”æ—¶é—´: {overview['avg_response_time']:.2f}ç§’")
    
    print(f"\nğŸ“ˆ æŒ‡æ ‡ç»Ÿè®¡:")
    for metric_name, stats in dashboard["metrics"].items():
        print(f"   {metric_name}:")
        if stats["type"] == "counter":
            print(f"     è®¡æ•°: {stats['value']}")
        elif stats["type"] == "gauge":
            print(f"     å½“å‰å€¼: {stats['value']:.4f}")
        elif stats["type"] in ["histogram", "timer"]:
            if stats.get("count", 0) > 0:
                print(f"     è®¡æ•°: {stats['count']}")
                print(f"     å¹³å‡: {stats['mean']:.4f}")
                print(f"     P95: {stats['p95']:.4f}")
                print(f"     æœ€å¤§: {stats['max']:.4f}")
    
    # æ˜¾ç¤ºæœ€è¿‘æ—¥å¿—
    print(f"\nğŸ”¹ 3. æœ€è¿‘æ—¥å¿—")
    recent_logs = monitor.get_recent_logs(limit=10)
    
    if recent_logs:
        print(f"ğŸ“ æœ€è¿‘ {len(recent_logs)} æ¡æ—¥å¿—:")
        for log in recent_logs:
            timestamp = log["timestamp"][:19]  # åªæ˜¾ç¤ºåˆ°ç§’
            level_emoji = {
                "DEBUG": "ğŸ”", "INFO": "â„¹ï¸", "WARNING": "âš ï¸", 
                "ERROR": "âŒ", "CRITICAL": "ğŸš¨"
            }
            emoji = level_emoji.get(log["level"], "ğŸ“")
            
            print(f"   {emoji} {timestamp} [{log['level']}] {log['message']}")
            if log["request_id"]:
                print(f"      è¯·æ±‚ID: {log['request_id']}")
            if log["response_time"]:
                print(f"      å“åº”æ—¶é—´: {log['response_time']:.2f}s")
            if log["cost"]:
                print(f"      æˆæœ¬: Â¥{log['cost']:.4f}")
    
    # æ˜¾ç¤ºå‘Šè­¦
    print(f"\nğŸ”¹ 4. å‘Šè­¦çŠ¶æ€")
    recent_alerts = monitor.get_recent_alerts(limit=5)
    
    if recent_alerts:
        print(f"ğŸš¨ æœ€è¿‘ {len(recent_alerts)} æ¡å‘Šè­¦:")
        for alert in recent_alerts:
            timestamp = alert["timestamp"][:19]
            status = "âœ…å·²è§£å†³" if alert["resolved"] else "ğŸ”´æ´»è·ƒ"
            print(f"   {timestamp} [{status}] {alert['rule_name']}")
            print(f"      æŒ‡æ ‡: {alert['metric_name']}")
            print(f"      å½“å‰å€¼: {alert['current_value']:.4f}")
            print(f"      é˜ˆå€¼: {alert['threshold']:.4f}")
            print(f"      æè¿°: {alert['message']}")
    else:
        print("âœ… æš‚æ— å‘Šè­¦")
    
    # æ€§èƒ½åˆ†æå»ºè®®
    print(f"\nğŸ”¹ 5. æ€§èƒ½åˆ†æå»ºè®®")
    
    if overview['avg_response_time'] > 3.0:
        print("âš ï¸  å¹³å‡å“åº”æ—¶é—´è¾ƒé«˜ï¼Œå»ºè®®:")
        print("   - æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("   - ä¼˜åŒ–æç¤ºè¯é•¿åº¦")
        print("   - è€ƒè™‘ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹")
    
    if overview['error_count'] > 0:
        print("âš ï¸  å­˜åœ¨é”™è¯¯è¯·æ±‚ï¼Œå»ºè®®:")
        print("   - æ£€æŸ¥æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®")
        print("   - éªŒè¯APIå¯†é’¥é…ç½®")
        print("   - æ·»åŠ é‡è¯•æœºåˆ¶")


# ============================================================================
# ç›‘æ§ä»ªè¡¨æ¿åŠŸèƒ½
# ============================================================================

def show_monitoring_dashboard(monitor: HarborAIMonitor):
    """æ˜¾ç¤ºç›‘æ§ä»ªè¡¨æ¿"""
    print("ğŸ”¸ ç”Ÿæˆç›‘æ§æŠ¥å‘Š...")
    
    # æ˜¾ç¤ºåŸºæœ¬ç»Ÿè®¡
    print(f"ğŸ“Š åŸºæœ¬ç»Ÿè®¡:")
    print(f"   - æ€»è¯·æ±‚æ•°: {monitor.request_count}")
    print(f"   - é”™è¯¯æ•°: {monitor.error_count}")
    print(f"   - æ€»æˆæœ¬: Â¥{monitor.total_cost:.4f}")
    
    if monitor.request_count > 0:
        avg_response_time = monitor.total_response_time / monitor.request_count
        success_rate = ((monitor.request_count - monitor.error_count) / monitor.request_count) * 100
        print(f"   - å¹³å‡å“åº”æ—¶é—´: {avg_response_time:.2f}ms")
        print(f"   - æˆåŠŸç‡: {success_rate:.1f}%")
    
    # æ˜¾ç¤ºæŒ‡æ ‡ç»Ÿè®¡
    print(f"\nğŸ“ˆ æŒ‡æ ‡ç»Ÿè®¡:")
    print(f"   - è®¡æ•°å™¨: {len(monitor.metrics.counters)} ä¸ª")
    print(f"   - ä»ªè¡¨ç›˜: {len(monitor.metrics.gauges)} ä¸ª")
    print(f"   - ç›´æ–¹å›¾: {len(monitor.metrics.histograms)} ä¸ª")
    print(f"   - è®¡æ—¶å™¨: {len(monitor.metrics.timers)} ä¸ª")
    
    # æ˜¾ç¤ºå‘Šè­¦è§„åˆ™
    print(f"\nğŸš¨ å‘Šè­¦è§„åˆ™:")
    print(f"   - å·²é…ç½®è§„åˆ™: {len(monitor.alerts.rules)} ä¸ª")
    enabled_rules = sum(1 for rule in monitor.alerts.rules if rule.enabled)
    print(f"   - å¯ç”¨è§„åˆ™: {enabled_rules} ä¸ª")
    
    print("âœ… ç›‘æ§æŠ¥å‘Šç”Ÿæˆå®Œæˆ")


# ============================================================================
# çœŸå®æ¨¡å‹è°ƒç”¨å’Œå®Œæ•´æ¼”ç¤ºåŠŸèƒ½
# ============================================================================

class RealModelDemo:
    """çœŸå®æ¨¡å‹è°ƒç”¨æ¼”ç¤ºç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ¼”ç¤ºç±»"""
        self.harborai = HarborAI()
        self.logger = StructuredLogger("RealModelDemo")
        self.monitor = HarborAIMonitor()
        
        # å¯ç”¨æ¨¡å‹åˆ—è¡¨ï¼ˆä»é¡¹ç›®é…ç½®è·å–ï¼‰
        self.available_models = [
            {'vendor': 'deepseek', 'model': 'deepseek-chat', 'is_reasoning': False},
            {'vendor': 'deepseek', 'model': 'deepseek-reasoner', 'is_reasoning': True},
            {'vendor': 'ernie', 'model': 'ernie-3.5-8k', 'is_reasoning': False},
            {'vendor': 'ernie', 'model': 'ernie-4.0-turbo-8k', 'is_reasoning': False},
            {'vendor': 'doubao', 'model': 'doubao-1-5-pro-32k-character-250715', 'is_reasoning': False},
        ]
        
        # æµ‹è¯•æ¶ˆæ¯åˆ—è¡¨
        self.test_messages = [
            "ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚",
            "è¯·è§£é‡Šä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
            "å†™ä¸€ä¸ªç®€å•çš„Pythonå‡½æ•°æ¥è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—ã€‚",
            "è¯·æ¨è3æœ¬å€¼å¾—é˜…è¯»çš„æŠ€æœ¯ä¹¦ç±ã€‚",
            "è§£é‡Šä¸€ä¸‹ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ"
        ]
    
    def print_section(self, title: str):
        """æ‰“å°ç« èŠ‚æ ‡é¢˜"""
        print(f"\n{'='*60}")
        print(f"  {title}")
        print(f"{'='*60}")
    
    def print_step(self, step: str):
        """æ‰“å°æ­¥éª¤"""
        print(f"\nğŸ”¸ {step}")
    
    def check_environment(self):
        """æ£€æŸ¥ç¯å¢ƒé…ç½®"""
        self.print_step("æ£€æŸ¥ç¯å¢ƒé…ç½®...")
        
        # æ£€æŸ¥APIå¯†é’¥é…ç½®
        api_keys = {
            'DEEPSEEK_API_KEY': os.getenv('DEEPSEEK_API_KEY'),
            'DOUBAO_API_KEY': os.getenv('DOUBAO_API_KEY'),
            'WENXIN_API_KEY': os.getenv('WENXIN_API_KEY'),
        }
        
        configured_keys = {k: v for k, v in api_keys.items() if v}
        
        if not configured_keys:
            print("âŒ æ²¡æœ‰é…ç½®ä»»ä½•APIå¯†é’¥")
            return False
        
        print(f"âœ… å·²é…ç½®çš„APIå¯†é’¥: {', '.join(configured_keys.keys())}")
        
        # è®°å½•ç¯å¢ƒæ£€æŸ¥æ—¥å¿—
        self.logger.info(
            "ç¯å¢ƒæ£€æŸ¥å®Œæˆ",
            metadata={"configured_keys": list(configured_keys.keys())}
        )
        
        return True
    
    async def test_single_model(self, model_info: Dict[str, Any], message: str, request_id: str) -> Dict[str, Any]:
        """æµ‹è¯•å•ä¸ªæ¨¡å‹"""
        model_name = model_info['model']
        vendor = model_info['vendor']
        
        # è®°å½•è¯·æ±‚å¼€å§‹
        self.logger.info(
            f"å¼€å§‹æµ‹è¯•æ¨¡å‹: {model_name}",
            request_id=request_id,
            model_name=model_name,
            metadata={"vendor": vendor, "message": message[:50]}
        )
        
        try:
            start_time = time.time()
            
            # è°ƒç”¨æ¨¡å‹
            response = await self.harborai.achat(
                model=model_name,
                messages=[{"role": "user", "content": message}],
                max_tokens=100  # é™åˆ¶tokenæ•°ä»¥èŠ‚çœæˆæœ¬
            )
            
            duration = time.time() - start_time
            
            # æ£€æŸ¥å“åº”
            if response and hasattr(response, 'content'):
                # è®°å½•æˆåŠŸæ—¥å¿—
                self.logger.info(
                    f"æ¨¡å‹è°ƒç”¨æˆåŠŸ: {model_name}",
                    request_id=request_id,
                    model_name=model_name,
                    response_time=duration,
                    token_count=len(response.content) if response.content else 0,
                    metadata={
                        "vendor": vendor,
                        "response_length": len(response.content) if response.content else 0,
                        "success": True
                    }
                )
                
                # è®°å½•æ€§èƒ½æŒ‡æ ‡
                self.monitor.record_metric("api_response_time", duration, {"model": model_name, "vendor": vendor})
                self.monitor.record_metric("api_success_count", 1, {"model": model_name, "vendor": vendor})
                
                print(f"âœ… {model_name}: å“åº”æˆåŠŸ ({duration:.2f}s)")
                return {
                    'model': model_name,
                    'vendor': vendor,
                    'success': True,
                    'duration': duration,
                    'response_length': len(response.content) if response.content else 0,
                    'error': None
                }
            else:
                # è®°å½•è­¦å‘Šæ—¥å¿—
                self.logger.warning(
                    f"æ¨¡å‹å“åº”ä¸ºç©º: {model_name}",
                    request_id=request_id,
                    model_name=model_name,
                    response_time=duration,
                    metadata={"vendor": vendor, "error": "å“åº”ä¸ºç©º"}
                )
                
                # è®°å½•é”™è¯¯æŒ‡æ ‡
                self.monitor.record_metric("api_error_count", 1, {"model": model_name, "vendor": vendor, "error_type": "empty_response"})
                
                print(f"âš ï¸  {model_name}: å“åº”ä¸ºç©º")
                return {
                    'model': model_name,
                    'vendor': vendor,
                    'success': False,
                    'duration': duration,
                    'response_length': 0,
                    'error': "å“åº”ä¸ºç©º"
                }
                
        except Exception as e:
            duration = time.time() - start_time
            
            # è®°å½•é”™è¯¯æ—¥å¿—
            self.logger.error(
                f"æ¨¡å‹è°ƒç”¨å¤±è´¥: {model_name}",
                request_id=request_id,
                model_name=model_name,
                response_time=duration,
                error_code="API_ERROR",
                stack_trace=str(e),
                metadata={"vendor": vendor, "error": str(e)}
            )
            
            # è®°å½•é”™è¯¯æŒ‡æ ‡
            self.monitor.record_metric("api_error_count", 1, {"model": model_name, "vendor": vendor, "error_type": "exception"})
            
            print(f"âŒ {model_name}: {str(e)}")
            return {
                'model': model_name,
                'vendor': vendor,
                'success': False,
                'duration': duration,
                'response_length': 0,
                'error': str(e)
            }
    
    async def run_model_tests(self, target_model: Optional[str] = None, test_only: bool = False):
        """è¿è¡Œæ¨¡å‹æµ‹è¯•"""
        self.print_step("å¼€å§‹æ¨¡å‹æµ‹è¯•...")
        
        # è¿‡æ»¤æ¨¡å‹
        if target_model:
            models_to_test = [m for m in self.available_models if m['model'] == target_model]
            if not models_to_test:
                print(f"âŒ æœªæ‰¾åˆ°æ¨¡å‹: {target_model}")
                return []
        else:
            models_to_test = self.available_models
        
        # é€‰æ‹©æµ‹è¯•æ¶ˆæ¯
        messages_to_test = self.test_messages[:1] if test_only else self.test_messages[:3]
        
        results = []
        
        for model_info in models_to_test:
            for i, message in enumerate(messages_to_test):
                request_id = f"test_{model_info['model']}_{i}_{int(time.time())}"
                print(f"æµ‹è¯• {model_info['model']} - æ¶ˆæ¯ {i+1}")
                
                result = await self.test_single_model(model_info, message, request_id)
                results.append(result)
                
                # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                await asyncio.sleep(1)
        
        return results
    
    def show_test_results(self, results: List[Dict[str, Any]]):
        """æ˜¾ç¤ºæµ‹è¯•ç»“æœ"""
        if not results:
            return
        
        successful = [r for r in results if r['success']]
        failed = [r for r in results if not r['success']]
        
        self.print_step("æµ‹è¯•ç»“æœæ‘˜è¦")
        
        print(f"ğŸ“Š æ€»æµ‹è¯•æ•°: {len(results)}")
        print(f"âœ… æˆåŠŸ: {len(successful)}")
        print(f"âŒ å¤±è´¥: {len(failed)}")
        print(f"ğŸ“ˆ æˆåŠŸç‡: {len(successful)/len(results)*100:.1f}%")
        
        if successful:
            avg_duration = sum(r['duration'] for r in successful) / len(successful)
            print(f"â±ï¸  å¹³å‡å“åº”æ—¶é—´: {avg_duration:.2f}s")
        
        # è®°å½•æµ‹è¯•æ‘˜è¦æ—¥å¿—
        self.logger.info(
            "æ¨¡å‹æµ‹è¯•å®Œæˆ",
            metadata={
                "total_tests": len(results),
                "successful": len(successful),
                "failed": len(failed),
                "success_rate": len(successful)/len(results)*100
            }
        )
    
    def demonstrate_log_viewing(self):
        """æ¼”ç¤ºæ—¥å¿—æŸ¥çœ‹åŠŸèƒ½"""
        self.print_step("æ¼”ç¤ºæ—¥å¿—æŸ¥çœ‹åŠŸèƒ½...")
        
        try:
            # å¯¼å…¥æ—¥å¿—æŸ¥çœ‹å·¥å…·
            from harborai.config.settings import get_settings
            from harborai.database.file_log_parser import FileLogParser
            
            settings = get_settings()
            parser = FileLogParser(settings.file_log_directory)
            
            # æŸ¥è¯¢æœ€è¿‘çš„æ—¥å¿—
            result = parser.query_api_logs(days=1, limit=5)
            
            if result.error:
                print(f"âŒ æŸ¥è¯¢å¤±è´¥: {result.error}")
                return
            
            print(f"âœ… æŸ¥è¯¢æˆåŠŸ: æ‰¾åˆ° {result.total_count} æ¡æ—¥å¿—è®°å½•")
            
            if result.data:
                print("\nğŸ“‹ æœ€è¿‘çš„æ—¥å¿—è®°å½•:")
                for i, log in enumerate(result.data[:3], 1):
                    timestamp = log.get('timestamp', 'N/A')
                    model = log.get('model', 'unknown')
                    success = log.get('success', False)
                    tokens = log.get('tokens', {})
                    total_tokens = tokens.get('total_tokens', 0) if isinstance(tokens, dict) else 0
                    
                    status = "âœ… æˆåŠŸ" if success else "âŒ å¤±è´¥"
                    print(f"  [{i}] {timestamp} | {model} | {status} | {total_tokens} tokens")
            
        except Exception as e:
            print(f"âŒ æ—¥å¿—æŸ¥çœ‹æ¼”ç¤ºå¤±è´¥: {e}")
    
    def show_usage_commands(self):
        """æ˜¾ç¤ºä½¿ç”¨å‘½ä»¤"""
        self.print_step("æ—¥å¿—æŸ¥çœ‹å‘½ä»¤å‚è€ƒ...")
        
        commands = [
            ("æŸ¥çœ‹æ‰€æœ‰æ—¥å¿—", "python view_logs.py"),
            ("æŸ¥çœ‹æ–‡ä»¶æ—¥å¿—", "python view_logs.py --source file"),
            ("æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯", "python view_logs.py --stats"),
            ("æŸ¥çœ‹ç‰¹å®šæ¨¡å‹", "python view_logs.py --model deepseek-chat"),
            ("JSONæ ¼å¼è¾“å‡º", "python view_logs.py --format json"),
            ("æŸ¥çœ‹è¯·æ±‚æ—¥å¿—", "python view_logs.py --type request"),
            ("æŸ¥çœ‹å“åº”æ—¥å¿—", "python view_logs.py --type response"),
            ("é…å¯¹æ˜¾ç¤ºè¯·æ±‚-å“åº”", "python view_logs.py --type paired")
        ]
        
        print("\nğŸ’¡ å¸¸ç”¨æ—¥å¿—æŸ¥çœ‹å‘½ä»¤:")
        for desc, cmd in commands:
            print(f"  â€¢ {desc}: {cmd}")
    
    async def run_complete_demo(self, target_model: Optional[str] = None, test_only: bool = False, monitor_only: bool = False):
        """è¿è¡Œå®Œæ•´æ¼”ç¤º"""
        self.print_section("HarborAI å®Œæ•´æ—¥å¿—ç›‘æ§ä¸çœŸå®æ¨¡å‹è°ƒç”¨æ¼”ç¤º")
        
        print("ğŸ“ æœ¬æ¼”ç¤ºå°†å±•ç¤º:")
        print("  1. ç¯å¢ƒé…ç½®æ£€æŸ¥")
        print("  2. çœŸå®æ¨¡å‹è°ƒç”¨å’Œæ—¥å¿—è®°å½•")
        print("  3. æ€§èƒ½ç›‘æ§å’ŒæŒ‡æ ‡æ”¶é›†")
        print("  4. æ—¥å¿—æŸ¥çœ‹å’Œåˆ†æåŠŸèƒ½")
        print("  5. ç›‘æ§æŠ¥å‘Šå’Œå‘Šè­¦æ¼”ç¤º")
        
        # 1. æ£€æŸ¥ç¯å¢ƒ
        self.print_section("1. ç¯å¢ƒé…ç½®æ£€æŸ¥")
        if not self.check_environment():
            return
        
        # å¦‚æœæ˜¯ä»…ç›‘æ§æ¨¡å¼ï¼Œè·³è¿‡æ¨¡å‹æµ‹è¯•
        if not monitor_only:
            # 2. è¿è¡Œæ¨¡å‹æµ‹è¯•
            self.print_section("2. çœŸå®æ¨¡å‹è°ƒç”¨æµ‹è¯•")
            results = await self.run_model_tests(target_model, test_only)
            
            # 3. æ˜¾ç¤ºæµ‹è¯•ç»“æœ
            self.print_section("3. æµ‹è¯•ç»“æœåˆ†æ")
            self.show_test_results(results)
        
        # 4. æ¼”ç¤ºæ—¥å¿—æŸ¥çœ‹
        self.print_section("4. æ—¥å¿—æŸ¥çœ‹åŠŸèƒ½")
        self.demonstrate_log_viewing()
        
        # 5. æ˜¾ç¤ºç›‘æ§æŠ¥å‘Š
        self.print_section("5. ç›‘æ§æŠ¥å‘Š")
        show_monitoring_dashboard(self.monitor)
        
        # 6. æ˜¾ç¤ºä½¿ç”¨å‘½ä»¤
        self.print_section("6. ä½¿ç”¨å‘½ä»¤å‚è€ƒ")
        self.show_usage_commands()
        
        # æ€»ç»“
        self.print_section("æ¼”ç¤ºå®Œæˆ")
        print("âœ… ç¯å¢ƒé…ç½®æ£€æŸ¥å®Œæˆ")
        if not monitor_only:
            print("âœ… çœŸå®æ¨¡å‹è°ƒç”¨æµ‹è¯•å®Œæˆ")
        print("âœ… æ—¥å¿—è®°å½•å’Œç›‘æ§åŠŸèƒ½æ­£å¸¸")
        print("âœ… æ—¥å¿—æŸ¥çœ‹å’Œåˆ†æåŠŸèƒ½æ­£å¸¸")
        print("\nğŸ‰ å®Œæ•´æ—¥å¿—ç›‘æ§æ¼”ç¤ºå®Œæˆï¼")
        print("ğŸ’¡ æç¤º: ä½¿ç”¨ä¸Šè¿°å‘½ä»¤æŸ¥çœ‹å’Œåˆ†ææ—¥å¿—æ•°æ®")


class LayoutModeDemo:
    """å¸ƒå±€æ¨¡å¼æ¼”ç¤ºç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ¼”ç¤ºç±»"""
        self.project_root = Path(__file__).parent.parent.parent
        self.view_logs_script = self.project_root / "view_logs.py"
    
    def run_view_logs_command(self, args: List[str]) -> Tuple[bool, str, str]:
        """è¿è¡Œ view_logs.py å‘½ä»¤"""
        if not self.view_logs_script.exists():
            return False, "", "view_logs.py è„šæœ¬ä¸å­˜åœ¨"
        
        cmd = ["python", str(self.view_logs_script)] + args
        
        try:
            import subprocess
            result = subprocess.run(
                cmd, 
                capture_output=True, 
                text=True, 
                encoding='utf-8', 
                errors='ignore',
                timeout=30,
                cwd=str(self.project_root)
            )
            return result.returncode == 0, result.stdout, result.stderr
        except subprocess.TimeoutExpired:
            return False, "", "å‘½ä»¤æ‰§è¡Œè¶…æ—¶"
        except Exception as e:
            return False, "", f"æ‰§è¡Œå‘½ä»¤æ—¶å‡ºé”™: {e}"
    
    def demo_layout_modes(self):
        """æ¼”ç¤ºå¸ƒå±€æ¨¡å¼"""
        print("\nğŸ¨ å¸ƒå±€æ¨¡å¼æ¼”ç¤º:")
        
        # 1. Classic å¸ƒå±€
        print("   1. Classic å¸ƒå±€ï¼ˆä¼ ç»Ÿè¡¨æ ¼æ˜¾ç¤ºï¼‰:")
        success, stdout, stderr = self.run_view_logs_command([
            "--layout", "classic", "--limit", "5"
        ])
        
        if success:
            print("     âœ… Classic å¸ƒå±€ç¤ºä¾‹:")
            lines = stdout.split('\n')[:10]
            for line in lines:
                if line.strip():
                    print(f"     {line}")
        else:
            print(f"     âŒ Classic å¸ƒå±€æ¼”ç¤ºå¤±è´¥: {stderr}")
        
        print("\n   2. Enhanced å¸ƒå±€ï¼ˆæ™ºèƒ½é…å¯¹æ˜¾ç¤ºï¼‰:")
        success, stdout, stderr = self.run_view_logs_command([
            "--layout", "enhanced", "--limit", "4"
        ])
        
        if success:
            print("     âœ… Enhanced å¸ƒå±€ç¤ºä¾‹:")
            lines = stdout.split('\n')[:10]
            for line in lines:
                if line.strip():
                    print(f"     {line}")
        else:
            print(f"     âŒ Enhanced å¸ƒå±€æ¼”ç¤ºå¤±è´¥: {stderr}")
    
    def demo_trace_id_features(self):
        """æ¼”ç¤º trace_id åŠŸèƒ½"""
        print("\nğŸ†” Trace ID åŠŸèƒ½æ¼”ç¤º:")
        
        # 1. åˆ—å‡ºæœ€è¿‘çš„ trace_id
        print("   1. åˆ—å‡ºæœ€è¿‘çš„ trace_id:")
        success, stdout, stderr = self.run_view_logs_command([
            "--list-recent-trace-ids", "--limit", "10"
        ])
        
        if success:
            print("     âœ… æœ€è¿‘çš„ trace_id:")
            for line in stdout.split('\n')[:8]:
                if line.strip():
                    print(f"     {line}")
        else:
            print(f"     âŒ è·å– trace_id åˆ—è¡¨å¤±è´¥: {stderr}")


async def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="HarborAI ä¸­çº§æ—¥å¿—åŠŸèƒ½æ¼”ç¤º - ç›‘æ§ä¸åˆ†æ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python logging_monitoring.py                    # è¿è¡Œå®Œæ•´æ¼”ç¤º
  python logging_monitoring.py --real-calls       # è¿›è¡ŒçœŸå®æ¨¡å‹è°ƒç”¨
  python logging_monitoring.py --monitoring-only  # ä»…æ¼”ç¤ºç›‘æ§åŠŸèƒ½
  python logging_monitoring.py --layout-demo      # æ¼”ç¤ºå¸ƒå±€æ¨¡å¼
  python logging_monitoring.py --trace-id-demo    # æ¼”ç¤º trace_id åŠŸèƒ½
        """
    )
    
    parser.add_argument("--real-calls", action="store_true", help="è¿›è¡ŒçœŸå®çš„æ¨¡å‹è°ƒç”¨ï¼ˆéœ€è¦ API å¯†é’¥ï¼‰")
    parser.add_argument("--monitoring-only", action="store_true", help="ä»…æ¼”ç¤ºç›‘æ§åŠŸèƒ½ï¼ˆä¸åˆ›å»ºæ–°æ•°æ®ï¼‰")
    parser.add_argument("--layout-demo", action="store_true", help="ä»…æ¼”ç¤ºå¸ƒå±€æ¨¡å¼")
    parser.add_argument("--trace-id-demo", action="store_true", help="ä»…æ¼”ç¤º trace_id åŠŸèƒ½")
    parser.add_argument("--model", help="ä»…æµ‹è¯•æŒ‡å®šæ¨¡å‹")
    
    args = parser.parse_args()
    
    try:
        if args.layout_demo:
            # ä»…æ¼”ç¤ºå¸ƒå±€æ¨¡å¼
            layout_demo = LayoutModeDemo()
            layout_demo.demo_layout_modes()
            
        elif args.trace_id_demo:
            # ä»…æ¼”ç¤º trace_id åŠŸèƒ½
            layout_demo = LayoutModeDemo()
            layout_demo.demo_trace_id_features()
            
        else:
            # è¿è¡ŒåŸæœ‰çš„å®Œæ•´æ¼”ç¤º
            demo = RealModelDemo()
            await demo.run_complete_demo(
                target_model=args.model,
                test_only=not args.real_calls,
                monitor_only=args.monitoring_only
            )
            
    except KeyboardInterrupt:
        print("\n\nâš ï¸ æ¼”ç¤ºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())