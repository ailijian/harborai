#!/usr/bin/env python3
"""
HarborAI æ—¥å¿—ç›‘æ§ç¤ºä¾‹

è¿™ä¸ªç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•åœ¨HarborAIä¸­å®ç°å…¨é¢çš„æ—¥å¿—è®°å½•å’Œç›‘æ§ï¼Œ
åŒ…æ‹¬è¯·æ±‚è¿½è¸ªã€æ€§èƒ½ç›‘æ§ã€é”™è¯¯åˆ†æå’Œå®æ—¶å‘Šè­¦ã€‚

åœºæ™¯æè¿°:
- ç»“æ„åŒ–æ—¥å¿—è®°å½•
- æ€§èƒ½æŒ‡æ ‡ç›‘æ§
- é”™è¯¯è¿½è¸ªåˆ†æ
- å®æ—¶å‘Šè­¦ç³»ç»Ÿ

åº”ç”¨ä»·å€¼:
- æå‡ç³»ç»Ÿå¯è§‚æµ‹æ€§
- å¿«é€Ÿé—®é¢˜å®šä½
- æ€§èƒ½ä¼˜åŒ–æŒ‡å¯¼
- è¿ç»´ç›‘æ§æ”¯æŒ
"""

import os
import json
import time
import asyncio
import logging
import sqlite3
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Callable
from dataclasses import dataclass, asdict
from enum import Enum
from pathlib import Path
import statistics
import threading
from collections import defaultdict, deque
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

try:
    from harborai import HarborAI
except ImportError:
    print("âŒ è¯·å…ˆå®‰è£… HarborAI: pip install harborai")
    exit(1)


class LogLevel(Enum):
    """æ—¥å¿—çº§åˆ«"""
    DEBUG = "DEBUG"
    INFO = "INFO"
    WARNING = "WARNING"
    ERROR = "ERROR"
    CRITICAL = "CRITICAL"


class MetricType(Enum):
    """æŒ‡æ ‡ç±»å‹"""
    COUNTER = "counter"
    GAUGE = "gauge"
    HISTOGRAM = "histogram"
    TIMER = "timer"


@dataclass
class LogEntry:
    """æ—¥å¿—æ¡ç›®"""
    timestamp: str
    level: LogLevel
    message: str
    module: str
    function: str
    request_id: str = None
    user_id: str = None
    session_id: str = None
    model_name: str = None
    response_time: float = None
    token_count: int = None
    cost: float = None
    error_code: str = None
    stack_trace: str = None
    metadata: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}


@dataclass
class MetricEntry:
    """æŒ‡æ ‡æ¡ç›®"""
    timestamp: str
    name: str
    type: MetricType
    value: float
    tags: Dict[str, str] = None
    
    def __post_init__(self):
        if self.tags is None:
            self.tags = {}


@dataclass
class AlertRule:
    """å‘Šè­¦è§„åˆ™"""
    name: str
    metric_name: str
    condition: str  # >, <, >=, <=, ==
    threshold: float
    duration: int  # æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
    enabled: bool = True
    description: str = ""


class StructuredLogger:
    """ç»“æ„åŒ–æ—¥å¿—è®°å½•å™¨"""
    
    def __init__(self, name: str, db_path: str = "monitoring.db"):
        self.name = name
        self.db_path = db_path
        self.init_database()
        
        # è®¾ç½®æ ‡å‡†æ—¥å¿—è®°å½•å™¨
        self.logger = logging.getLogger(name)
        self.logger.setLevel(logging.DEBUG)
        
        # åˆ›å»ºæ–‡ä»¶å¤„ç†å™¨
        log_file = f"{name}.log"
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setLevel(logging.DEBUG)
        
        # åˆ›å»ºæ§åˆ¶å°å¤„ç†å™¨
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        
        # åˆ›å»ºæ ¼å¼å™¨
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        file_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)
        
        # æ·»åŠ å¤„ç†å™¨
        if not self.logger.handlers:
            self.logger.addHandler(file_handler)
            self.logger.addHandler(console_handler)
    
    def init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # åˆ›å»ºæ—¥å¿—è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS logs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT NOT NULL,
                level TEXT NOT NULL,
                message TEXT NOT NULL,
                module TEXT NOT NULL,
                function TEXT NOT NULL,
                request_id TEXT,
                user_id TEXT,
                session_id TEXT,
                model_name TEXT,
                response_time REAL,
                token_count INTEGER,
                cost REAL,
                error_code TEXT,
                stack_trace TEXT,
                metadata TEXT
            )
        ''')
        
        # åˆ›å»ºæŒ‡æ ‡è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS metrics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT NOT NULL,
                name TEXT NOT NULL,
                type TEXT NOT NULL,
                value REAL NOT NULL,
                tags TEXT
            )
        ''')
        
        # åˆ›å»ºå‘Šè­¦è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS alerts (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT NOT NULL,
                rule_name TEXT NOT NULL,
                metric_name TEXT NOT NULL,
                current_value REAL NOT NULL,
                threshold REAL NOT NULL,
                message TEXT NOT NULL,
                resolved BOOLEAN DEFAULT FALSE,
                resolved_at TEXT
            )
        ''')
        
        # åˆ›å»ºç´¢å¼•
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_logs_timestamp ON logs(timestamp)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_logs_level ON logs(level)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_logs_request_id ON logs(request_id)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_metrics_timestamp ON metrics(timestamp)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_metrics_name ON metrics(name)')
        
        conn.commit()
        conn.close()
    
    def log(self, entry: LogEntry):
        """è®°å½•æ—¥å¿—æ¡ç›®"""
        # è®°å½•åˆ°æ ‡å‡†æ—¥å¿—
        log_level = getattr(logging, entry.level.value)
        self.logger.log(log_level, entry.message)
        
        # è®°å½•åˆ°æ•°æ®åº“
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO logs 
            (timestamp, level, message, module, function, request_id, user_id, 
             session_id, model_name, response_time, token_count, cost, 
             error_code, stack_trace, metadata)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            entry.timestamp, entry.level.value, entry.message, entry.module,
            entry.function, entry.request_id, entry.user_id, entry.session_id,
            entry.model_name, entry.response_time, entry.token_count, entry.cost,
            entry.error_code, entry.stack_trace,
            json.dumps(entry.metadata) if entry.metadata else None
        ))
        
        conn.commit()
        conn.close()
    
    def debug(self, message: str, **kwargs):
        """è®°å½•DEBUGçº§åˆ«æ—¥å¿—"""
        entry = LogEntry(
            timestamp=datetime.now().isoformat(),
            level=LogLevel.DEBUG,
            message=message,
            module=self.name,
            function="debug",
            **kwargs
        )
        self.log(entry)
    
    def info(self, message: str, **kwargs):
        """è®°å½•INFOçº§åˆ«æ—¥å¿—"""
        entry = LogEntry(
            timestamp=datetime.now().isoformat(),
            level=LogLevel.INFO,
            message=message,
            module=self.name,
            function="info",
            **kwargs
        )
        self.log(entry)
    
    def warning(self, message: str, **kwargs):
        """è®°å½•WARNINGçº§åˆ«æ—¥å¿—"""
        entry = LogEntry(
            timestamp=datetime.now().isoformat(),
            level=LogLevel.WARNING,
            message=message,
            module=self.name,
            function="warning",
            **kwargs
        )
        self.log(entry)
    
    def error(self, message: str, **kwargs):
        """è®°å½•ERRORçº§åˆ«æ—¥å¿—"""
        entry = LogEntry(
            timestamp=datetime.now().isoformat(),
            level=LogLevel.ERROR,
            message=message,
            module=self.name,
            function="error",
            **kwargs
        )
        self.log(entry)
    
    def critical(self, message: str, **kwargs):
        """è®°å½•CRITICALçº§åˆ«æ—¥å¿—"""
        entry = LogEntry(
            timestamp=datetime.now().isoformat(),
            level=LogLevel.CRITICAL,
            message=message,
            module=self.name,
            function="critical",
            **kwargs
        )
        self.log(entry)


class MetricsCollector:
    """æŒ‡æ ‡æ”¶é›†å™¨"""
    
    def __init__(self, db_path: str = "monitoring.db"):
        self.db_path = db_path
        self.metrics_buffer = deque(maxlen=1000)  # å†…å­˜ç¼“å†²åŒº
        self.counters = defaultdict(float)
        self.gauges = defaultdict(float)
        self.histograms = defaultdict(list)
        self.timers = defaultdict(list)
        
        # å¯åŠ¨åå°çº¿ç¨‹å®šæœŸåˆ·æ–°æŒ‡æ ‡
        self.flush_thread = threading.Thread(target=self._flush_metrics_loop, daemon=True)
        self.flush_thread.start()
    
    def _flush_metrics_loop(self):
        """åå°çº¿ç¨‹å®šæœŸåˆ·æ–°æŒ‡æ ‡åˆ°æ•°æ®åº“"""
        while True:
            time.sleep(10)  # æ¯10ç§’åˆ·æ–°ä¸€æ¬¡
            self._flush_metrics()
    
    def _flush_metrics(self):
        """åˆ·æ–°æŒ‡æ ‡åˆ°æ•°æ®åº“"""
        if not self.metrics_buffer:
            return
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # æ‰¹é‡æ’å…¥æŒ‡æ ‡
        metrics_to_insert = []
        while self.metrics_buffer:
            metric = self.metrics_buffer.popleft()
            metrics_to_insert.append((
                metric.timestamp, metric.name, metric.type.value,
                metric.value, json.dumps(metric.tags) if metric.tags else None
            ))
        
        if metrics_to_insert:
            cursor.executemany('''
                INSERT INTO metrics (timestamp, name, type, value, tags)
                VALUES (?, ?, ?, ?, ?)
            ''', metrics_to_insert)
        
        conn.commit()
        conn.close()
    
    def record_metric(self, metric: MetricEntry):
        """è®°å½•æŒ‡æ ‡"""
        self.metrics_buffer.append(metric)
        
        # æ›´æ–°å†…å­˜ä¸­çš„æŒ‡æ ‡
        if metric.type == MetricType.COUNTER:
            self.counters[metric.name] += metric.value
        elif metric.type == MetricType.GAUGE:
            self.gauges[metric.name] = metric.value
        elif metric.type == MetricType.HISTOGRAM:
            self.histograms[metric.name].append(metric.value)
            # ä¿æŒæœ€è¿‘1000ä¸ªå€¼
            if len(self.histograms[metric.name]) > 1000:
                self.histograms[metric.name] = self.histograms[metric.name][-1000:]
        elif metric.type == MetricType.TIMER:
            self.timers[metric.name].append(metric.value)
            # ä¿æŒæœ€è¿‘1000ä¸ªå€¼
            if len(self.timers[metric.name]) > 1000:
                self.timers[metric.name] = self.timers[metric.name][-1000:]
    
    def increment_counter(self, name: str, value: float = 1.0, tags: Dict[str, str] = None):
        """å¢åŠ è®¡æ•°å™¨"""
        metric = MetricEntry(
            timestamp=datetime.now().isoformat(),
            name=name,
            type=MetricType.COUNTER,
            value=value,
            tags=tags
        )
        self.record_metric(metric)
    
    def set_gauge(self, name: str, value: float, tags: Dict[str, str] = None):
        """è®¾ç½®ä»ªè¡¨ç›˜å€¼"""
        metric = MetricEntry(
            timestamp=datetime.now().isoformat(),
            name=name,
            type=MetricType.GAUGE,
            value=value,
            tags=tags
        )
        self.record_metric(metric)
    
    def record_histogram(self, name: str, value: float, tags: Dict[str, str] = None):
        """è®°å½•ç›´æ–¹å›¾å€¼"""
        metric = MetricEntry(
            timestamp=datetime.now().isoformat(),
            name=name,
            type=MetricType.HISTOGRAM,
            value=value,
            tags=tags
        )
        self.record_metric(metric)
    
    def record_timer(self, name: str, duration: float, tags: Dict[str, str] = None):
        """è®°å½•è®¡æ—¶å™¨å€¼"""
        metric = MetricEntry(
            timestamp=datetime.now().isoformat(),
            name=name,
            type=MetricType.TIMER,
            value=duration,
            tags=tags
        )
        self.record_metric(metric)
    
    def get_metric_stats(self, name: str, metric_type: MetricType = None) -> Dict[str, Any]:
        """è·å–æŒ‡æ ‡ç»Ÿè®¡"""
        if metric_type == MetricType.COUNTER or name in self.counters:
            return {"type": "counter", "value": self.counters[name]}
        
        elif metric_type == MetricType.GAUGE or name in self.gauges:
            return {"type": "gauge", "value": self.gauges[name]}
        
        elif metric_type == MetricType.HISTOGRAM or name in self.histograms:
            values = self.histograms[name]
            if not values:
                return {"type": "histogram", "count": 0}
            
            return {
                "type": "histogram",
                "count": len(values),
                "min": min(values),
                "max": max(values),
                "mean": statistics.mean(values),
                "median": statistics.median(values),
                "p95": statistics.quantiles(values, n=20)[18] if len(values) >= 20 else max(values),
                "p99": statistics.quantiles(values, n=100)[98] if len(values) >= 100 else max(values)
            }
        
        elif metric_type == MetricType.TIMER or name in self.timers:
            values = self.timers[name]
            if not values:
                return {"type": "timer", "count": 0}
            
            return {
                "type": "timer",
                "count": len(values),
                "min": min(values),
                "max": max(values),
                "mean": statistics.mean(values),
                "median": statistics.median(values),
                "p95": statistics.quantiles(values, n=20)[18] if len(values) >= 20 else max(values),
                "p99": statistics.quantiles(values, n=100)[98] if len(values) >= 100 else max(values)
            }
        
        return {}


class AlertManager:
    """å‘Šè­¦ç®¡ç†å™¨"""
    
    def __init__(self, db_path: str = "monitoring.db"):
        self.db_path = db_path
        self.rules = []
        self.alert_handlers = []
        
        # é»˜è®¤å‘Šè­¦è§„åˆ™
        self.add_rule(AlertRule(
            name="high_response_time",
            metric_name="api_response_time",
            condition=">",
            threshold=5.0,
            duration=60,
            description="APIå“åº”æ—¶é—´è¿‡é«˜"
        ))
        
        self.add_rule(AlertRule(
            name="high_error_rate",
            metric_name="api_error_rate",
            condition=">",
            threshold=0.1,
            duration=300,
            description="APIé”™è¯¯ç‡è¿‡é«˜"
        ))
        
        self.add_rule(AlertRule(
            name="high_cost",
            metric_name="hourly_cost",
            condition=">",
            threshold=1.0,
            duration=3600,
            description="å°æ—¶æˆæœ¬è¿‡é«˜"
        ))
    
    def add_rule(self, rule: AlertRule):
        """æ·»åŠ å‘Šè­¦è§„åˆ™"""
        self.rules.append(rule)
    
    def add_alert_handler(self, handler: Callable[[str, Dict[str, Any]], None]):
        """æ·»åŠ å‘Šè­¦å¤„ç†å™¨"""
        self.alert_handlers.append(handler)
    
    def check_alerts(self, metrics: Dict[str, Any]):
        """æ£€æŸ¥å‘Šè­¦æ¡ä»¶"""
        for rule in self.rules:
            if not rule.enabled:
                continue
            
            if rule.metric_name not in metrics:
                continue
            
            current_value = metrics[rule.metric_name]
            
            # æ£€æŸ¥æ¡ä»¶
            triggered = False
            if rule.condition == ">" and current_value > rule.threshold:
                triggered = True
            elif rule.condition == "<" and current_value < rule.threshold:
                triggered = True
            elif rule.condition == ">=" and current_value >= rule.threshold:
                triggered = True
            elif rule.condition == "<=" and current_value <= rule.threshold:
                triggered = True
            elif rule.condition == "==" and current_value == rule.threshold:
                triggered = True
            
            if triggered:
                self._trigger_alert(rule, current_value)
    
    def _trigger_alert(self, rule: AlertRule, current_value: float):
        """è§¦å‘å‘Šè­¦"""
        alert_data = {
            "rule_name": rule.name,
            "metric_name": rule.metric_name,
            "current_value": current_value,
            "threshold": rule.threshold,
            "condition": rule.condition,
            "description": rule.description,
            "timestamp": datetime.now().isoformat()
        }
        
        # è®°å½•åˆ°æ•°æ®åº“
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO alerts 
            (timestamp, rule_name, metric_name, current_value, threshold, message)
            VALUES (?, ?, ?, ?, ?, ?)
        ''', (
            alert_data["timestamp"], rule.name, rule.metric_name,
            current_value, rule.threshold, rule.description
        ))
        
        conn.commit()
        conn.close()
        
        # è°ƒç”¨å‘Šè­¦å¤„ç†å™¨
        for handler in self.alert_handlers:
            try:
                handler(rule.name, alert_data)
            except Exception as e:
                print(f"å‘Šè­¦å¤„ç†å™¨é”™è¯¯: {e}")


class HarborAIMonitor:
    """HarborAIç›‘æ§å™¨"""
    
    def __init__(self, db_path: str = "monitoring.db"):
        self.logger = StructuredLogger("harborai_monitor", db_path)
        self.metrics = MetricsCollector(db_path)
        self.alerts = AlertManager(db_path)
        
        # æ·»åŠ æ§åˆ¶å°å‘Šè­¦å¤„ç†å™¨
        self.alerts.add_alert_handler(self._console_alert_handler)
        
        # æ€§èƒ½ç»Ÿè®¡
        self.request_count = 0
        self.error_count = 0
        self.total_response_time = 0
        self.total_cost = 0
    
    def _console_alert_handler(self, rule_name: str, alert_data: Dict[str, Any]):
        """æ§åˆ¶å°å‘Šè­¦å¤„ç†å™¨"""
        print(f"\nğŸš¨ å‘Šè­¦è§¦å‘: {rule_name}")
        print(f"   æŒ‡æ ‡: {alert_data['metric_name']}")
        print(f"   å½“å‰å€¼: {alert_data['current_value']}")
        print(f"   é˜ˆå€¼: {alert_data['threshold']}")
        print(f"   æè¿°: {alert_data['description']}")
        print(f"   æ—¶é—´: {alert_data['timestamp']}")
    
    async def monitor_api_call(self, client: HarborAI, model_name: str, 
                              prompt: str, **kwargs) -> Any:
        """
        ç›‘æ§APIè°ƒç”¨
        
        Args:
            client: HarborAIå®¢æˆ·ç«¯
            model_name: æ¨¡å‹åç§°
            prompt: æç¤ºè¯
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            APIå“åº”
        """
        request_id = f"req_{int(time.time() * 1000)}_{hash(prompt) % 10000}"
        start_time = time.time()
        
        # è®°å½•è¯·æ±‚å¼€å§‹
        self.logger.info(
            f"APIè¯·æ±‚å¼€å§‹: {model_name}",
            request_id=request_id,
            model_name=model_name,
            metadata={
                "prompt_length": len(prompt),
                "temperature": kwargs.get("temperature", 0.7),
                "max_tokens": kwargs.get("max_tokens", 1000)
            }
        )
        
        # å¢åŠ è¯·æ±‚è®¡æ•°
        self.metrics.increment_counter("api_requests_total", tags={"model": model_name})
        self.request_count += 1
        
        try:
            response = await client.chat.completions.acreate(
                model=model_name,
                messages=[{"role": "user", "content": prompt}],
                **kwargs
            )
            
            response_time = time.time() - start_time
            usage = response.usage
            
            # è®¡ç®—æˆæœ¬ï¼ˆç®€åŒ–ï¼‰
            cost = (usage.total_tokens / 1000) * 0.002
            
            # è®°å½•æˆåŠŸå“åº”
            self.logger.info(
                f"APIè¯·æ±‚æˆåŠŸ: {model_name}",
                request_id=request_id,
                model_name=model_name,
                response_time=response_time,
                token_count=usage.total_tokens,
                cost=cost,
                metadata={
                    "input_tokens": usage.prompt_tokens,
                    "output_tokens": usage.completion_tokens,
                    "response_length": len(response.choices[0].message.content)
                }
            )
            
            # è®°å½•æŒ‡æ ‡
            self.metrics.record_timer("api_response_time", response_time, tags={"model": model_name})
            self.metrics.record_histogram("api_token_count", usage.total_tokens, tags={"model": model_name})
            self.metrics.record_histogram("api_cost", cost, tags={"model": model_name})
            self.metrics.increment_counter("api_requests_success", tags={"model": model_name})
            
            # æ›´æ–°ç»Ÿè®¡
            self.total_response_time += response_time
            self.total_cost += cost
            
            return response
            
        except Exception as e:
            response_time = time.time() - start_time
            
            # è®°å½•é”™è¯¯
            self.logger.error(
                f"APIè¯·æ±‚å¤±è´¥: {model_name}",
                request_id=request_id,
                model_name=model_name,
                response_time=response_time,
                error_code=type(e).__name__,
                stack_trace=str(e),
                metadata={
                    "prompt_length": len(prompt)
                }
            )
            
            # è®°å½•é”™è¯¯æŒ‡æ ‡
            self.metrics.increment_counter("api_requests_error", tags={"model": model_name, "error": type(e).__name__})
            self.error_count += 1
            
            raise e
        
        finally:
            # æ›´æ–°å®æ—¶æŒ‡æ ‡
            if self.request_count > 0:
                error_rate = self.error_count / self.request_count
                avg_response_time = self.total_response_time / self.request_count
                
                self.metrics.set_gauge("api_error_rate", error_rate)
                self.metrics.set_gauge("api_avg_response_time", avg_response_time)
                self.metrics.set_gauge("api_total_cost", self.total_cost)
                
                # æ£€æŸ¥å‘Šè­¦
                self.alerts.check_alerts({
                    "api_response_time": avg_response_time,
                    "api_error_rate": error_rate,
                    "hourly_cost": self.total_cost  # ç®€åŒ–ä¸ºæ€»æˆæœ¬
                })
    
    def get_monitoring_dashboard(self) -> Dict[str, Any]:
        """è·å–ç›‘æ§ä»ªè¡¨æ¿æ•°æ®"""
        dashboard = {
            "overview": {
                "total_requests": self.request_count,
                "error_count": self.error_count,
                "success_rate": (self.request_count - self.error_count) / self.request_count if self.request_count > 0 else 0,
                "total_cost": self.total_cost,
                "avg_response_time": self.total_response_time / self.request_count if self.request_count > 0 else 0
            },
            "metrics": {}
        }
        
        # è·å–å„ç§æŒ‡æ ‡ç»Ÿè®¡
        metric_names = [
            "api_response_time", "api_token_count", "api_cost",
            "api_requests_total", "api_requests_success", "api_requests_error"
        ]
        
        for name in metric_names:
            stats = self.metrics.get_metric_stats(name)
            if stats:
                dashboard["metrics"][name] = stats
        
        return dashboard
    
    def get_recent_logs(self, limit: int = 50, level: LogLevel = None) -> List[Dict[str, Any]]:
        """è·å–æœ€è¿‘çš„æ—¥å¿—"""
        conn = sqlite3.connect(self.logger.db_path)
        cursor = conn.cursor()
        
        where_clause = ""
        params = []
        
        if level:
            where_clause = "WHERE level = ?"
            params.append(level.value)
        
        cursor.execute(f'''
            SELECT timestamp, level, message, module, function, request_id, 
                   model_name, response_time, token_count, cost, error_code
            FROM logs
            {where_clause}
            ORDER BY timestamp DESC
            LIMIT ?
        ''', params + [limit])
        
        logs = []
        for row in cursor.fetchall():
            logs.append({
                "timestamp": row[0],
                "level": row[1],
                "message": row[2],
                "module": row[3],
                "function": row[4],
                "request_id": row[5],
                "model_name": row[6],
                "response_time": row[7],
                "token_count": row[8],
                "cost": row[9],
                "error_code": row[10]
            })
        
        conn.close()
        return logs
    
    def get_recent_alerts(self, limit: int = 20) -> List[Dict[str, Any]]:
        """è·å–æœ€è¿‘çš„å‘Šè­¦"""
        conn = sqlite3.connect(self.alerts.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT timestamp, rule_name, metric_name, current_value, 
                   threshold, message, resolved
            FROM alerts
            ORDER BY timestamp DESC
            LIMIT ?
        ''', [limit])
        
        alerts = []
        for row in cursor.fetchall():
            alerts.append({
                "timestamp": row[0],
                "rule_name": row[1],
                "metric_name": row[2],
                "current_value": row[3],
                "threshold": row[4],
                "message": row[5],
                "resolved": bool(row[6])
            })
        
        conn.close()
        return alerts


async def monitoring_demo():
    """ç›‘æ§æ¼”ç¤º"""
    print("="*60)
    print("ğŸ“Š HarborAI æ—¥å¿—ç›‘æ§ç¤ºä¾‹")
    print("="*60)
    
    # åˆå§‹åŒ–ç›‘æ§å™¨
    monitor = HarborAIMonitor()
    
    print("âœ… ç›‘æ§ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    # æ£€æŸ¥APIå¯†é’¥
    api_key = os.getenv("DEEPSEEK_API_KEY")
    if not api_key:
        print("âŒ éœ€è¦DEEPSEEK_API_KEYç¯å¢ƒå˜é‡")
        return
    
    client = HarborAI(api_key=api_key, base_url="https://api.deepseek.com")
    
    # æµ‹è¯•åœºæ™¯
    test_scenarios = [
        {"prompt": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚", "model": "deepseek-chat"},
        {"prompt": "è¯·å†™ä¸€ä¸ªPythonå‡½æ•°æ¥è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—ã€‚", "model": "deepseek-chat"},
        {"prompt": "è¯·è§£é‡Šä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ã€‚", "model": "deepseek-chat"},
        {"prompt": "è¿™æ˜¯ä¸€ä¸ªæ•…æ„çš„é”™è¯¯æµ‹è¯•", "model": "invalid-model"},  # æ•…æ„çš„é”™è¯¯
        {"prompt": "è¯·åˆ†æå½“å‰AIæŠ€æœ¯çš„å‘å±•è¶‹åŠ¿ã€‚", "model": "deepseek-chat"}
    ]
    
    print(f"\nğŸ”¹ 1. æ‰§è¡Œç›‘æ§æµ‹è¯•")
    print(f"ğŸ“‹ å°†æ‰§è¡Œ {len(test_scenarios)} ä¸ªæµ‹è¯•åœºæ™¯")
    
    # æ‰§è¡Œæµ‹è¯•åœºæ™¯
    for i, scenario in enumerate(test_scenarios, 1):
        print(f"\nğŸ¯ åœºæ™¯ {i}: {scenario['prompt'][:50]}...")
        
        try:
            response = await monitor.monitor_api_call(
                client, scenario["model"], scenario["prompt"],
                max_tokens=200, temperature=0.7
            )
            print(f"   âœ… æˆåŠŸ - å“åº”é•¿åº¦: {len(response.choices[0].message.content)}")
        except Exception as e:
            print(f"   âŒ å¤±è´¥: {e}")
        
        # çŸ­æš‚å»¶è¿Ÿ
        await asyncio.sleep(1)
    
    # æ˜¾ç¤ºç›‘æ§ä»ªè¡¨æ¿
    print(f"\nğŸ”¹ 2. ç›‘æ§ä»ªè¡¨æ¿")
    dashboard = monitor.get_monitoring_dashboard()
    
    overview = dashboard["overview"]
    print(f"ğŸ“Š æ€»ä½“æ¦‚è§ˆ:")
    print(f"   æ€»è¯·æ±‚æ•°: {overview['total_requests']}")
    print(f"   é”™è¯¯æ•°é‡: {overview['error_count']}")
    print(f"   æˆåŠŸç‡: {overview['success_rate']:.1%}")
    print(f"   æ€»æˆæœ¬: ${overview['total_cost']:.4f}")
    print(f"   å¹³å‡å“åº”æ—¶é—´: {overview['avg_response_time']:.2f}ç§’")
    
    print(f"\nğŸ“ˆ æŒ‡æ ‡ç»Ÿè®¡:")
    for metric_name, stats in dashboard["metrics"].items():
        print(f"   {metric_name}:")
        if stats["type"] == "counter":
            print(f"     è®¡æ•°: {stats['value']}")
        elif stats["type"] == "gauge":
            print(f"     å½“å‰å€¼: {stats['value']:.4f}")
        elif stats["type"] in ["histogram", "timer"]:
            if stats.get("count", 0) > 0:
                print(f"     è®¡æ•°: {stats['count']}")
                print(f"     å¹³å‡: {stats['mean']:.4f}")
                print(f"     P95: {stats['p95']:.4f}")
                print(f"     æœ€å¤§: {stats['max']:.4f}")
    
    # æ˜¾ç¤ºæœ€è¿‘æ—¥å¿—
    print(f"\nğŸ”¹ 3. æœ€è¿‘æ—¥å¿—")
    recent_logs = monitor.get_recent_logs(limit=10)
    
    if recent_logs:
        print(f"ğŸ“ æœ€è¿‘ {len(recent_logs)} æ¡æ—¥å¿—:")
        for log in recent_logs:
            timestamp = log["timestamp"][:19]  # åªæ˜¾ç¤ºåˆ°ç§’
            level_emoji = {
                "DEBUG": "ğŸ”", "INFO": "â„¹ï¸", "WARNING": "âš ï¸", 
                "ERROR": "âŒ", "CRITICAL": "ğŸš¨"
            }
            emoji = level_emoji.get(log["level"], "ğŸ“")
            
            print(f"   {emoji} {timestamp} [{log['level']}] {log['message']}")
            if log["request_id"]:
                print(f"      è¯·æ±‚ID: {log['request_id']}")
            if log["response_time"]:
                print(f"      å“åº”æ—¶é—´: {log['response_time']:.2f}s")
            if log["cost"]:
                print(f"      æˆæœ¬: ${log['cost']:.4f}")
    
    # æ˜¾ç¤ºå‘Šè­¦
    print(f"\nğŸ”¹ 4. å‘Šè­¦çŠ¶æ€")
    recent_alerts = monitor.get_recent_alerts(limit=5)
    
    if recent_alerts:
        print(f"ğŸš¨ æœ€è¿‘ {len(recent_alerts)} æ¡å‘Šè­¦:")
        for alert in recent_alerts:
            timestamp = alert["timestamp"][:19]
            status = "âœ…å·²è§£å†³" if alert["resolved"] else "ğŸ”´æ´»è·ƒ"
            print(f"   {timestamp} [{status}] {alert['rule_name']}")
            print(f"      æŒ‡æ ‡: {alert['metric_name']}")
            print(f"      å½“å‰å€¼: {alert['current_value']:.4f}")
            print(f"      é˜ˆå€¼: {alert['threshold']:.4f}")
            print(f"      æè¿°: {alert['message']}")
    else:
        print("âœ… æš‚æ— å‘Šè­¦")
    
    # æ€§èƒ½åˆ†æå»ºè®®
    print(f"\nğŸ”¹ 5. æ€§èƒ½åˆ†æå»ºè®®")
    
    if overview['avg_response_time'] > 3.0:
        print("âš ï¸  å¹³å‡å“åº”æ—¶é—´è¾ƒé«˜ï¼Œå»ºè®®:")
        print("   - æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("   - ä¼˜åŒ–æç¤ºè¯é•¿åº¦")
        print("   - è€ƒè™‘ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹")
    
    if overview['error_count'] > 0:
        print("âš ï¸  å­˜åœ¨é”™è¯¯è¯·æ±‚ï¼Œå»ºè®®:")
        print("   - æ£€æŸ¥æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®")
        print("   - éªŒè¯APIå¯†é’¥é…ç½®")
        print("   - æ·»åŠ é‡è¯•æœºåˆ¶")
    
    if overview['total_cost'] > 0.1:
        print("ğŸ’° æˆæœ¬æé†’:")
        print(f"   - å½“å‰æ€»æˆæœ¬: ${overview['total_cost']:.4f}")
        print("   - å»ºè®®è®¾ç½®æˆæœ¬é¢„ç®—")
        print("   - è€ƒè™‘ä½¿ç”¨æ›´ç»æµçš„æ¨¡å‹")
    
    print(f"\nğŸ‰ ç›‘æ§æ¼”ç¤ºå®Œæˆï¼")
    print(f"ğŸ“ ç›‘æ§æ•°æ®ä¿å­˜åœ¨: monitoring.db")
    print(f"ğŸ“ æ—¥å¿—æ–‡ä»¶: harborai_monitor.log")


if __name__ == "__main__":
    asyncio.run(monitoring_demo())