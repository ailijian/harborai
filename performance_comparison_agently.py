#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸš€ HarborAI æ€§èƒ½æ¨¡å¼å¯¹æ¯”æµ‹è¯•

æœ¬æµ‹è¯•ç”¨äºéªŒè¯å’Œå¯¹æ¯”ï¼š
1. ç›´æ¥ä½¿ç”¨ Agently ç»“æ„åŒ–è¾“å‡ºçš„æ€§èƒ½ï¼ˆåŸºå‡†ï¼‰
2. HarborAI FAST æ¨¡å¼çš„æ€§èƒ½
3. HarborAI BALANCED æ¨¡å¼çš„æ€§èƒ½
4. HarborAI FULL æ¨¡å¼çš„æ€§èƒ½

ç›®æ ‡ï¼šéªŒè¯ä¸åŒæ€§èƒ½æ¨¡å¼çš„çœŸå®æ€§èƒ½å·®å¼‚ï¼Œç¡®è®¤ README.md ä¸­çš„æ€§èƒ½æ•°æ®å‡†ç¡®æ€§
"""

import os
import sys
import time
import json
import statistics
import importlib
from typing import Dict, Any, List, Tuple
from dotenv import load_dotenv
try:
    import psutil
except Exception:
    psutil = None

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

def setup_console_encoding():
    """è®¾ç½®æ§åˆ¶å°ç¼–ç ä¸ºUTF-8ï¼ˆWindowså…¼å®¹ï¼‰"""
    if sys.platform.startswith('win'):
        try:
            import codecs
            sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
            sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')
        except:
            pass

setup_console_encoding()

def set_performance_mode_env(mode: str) -> None:
    """è®¾ç½®æ€§èƒ½æ¨¡å¼çš„ç¯å¢ƒå˜é‡"""
    # æ¸…é™¤ä¹‹å‰çš„è®¾ç½®
    env_vars_to_clear = [
        'HARBORAI_PERFORMANCE_MODE',
        'HARBORAI_ENABLE_FAST_PATH',
        'HARBORAI_ENABLE_COST_TRACKING',
        'HARBORAI_ENABLE_DETAILED_LOGGING'
    ]
    
    for var in env_vars_to_clear:
        if var in os.environ:
            del os.environ[var]
    
    if mode == "FAST":
        os.environ['HARBORAI_PERFORMANCE_MODE'] = 'fast'
        os.environ['HARBORAI_ENABLE_FAST_PATH'] = 'true'
        os.environ['HARBORAI_ENABLE_COST_TRACKING'] = 'false'
        os.environ['HARBORAI_ENABLE_DETAILED_LOGGING'] = 'false'
        print("[CONFIG] è®¾ç½® FAST æ¨¡å¼ç¯å¢ƒå˜é‡")
    elif mode == "BALANCED":
        os.environ['HARBORAI_PERFORMANCE_MODE'] = 'balanced'
        os.environ['HARBORAI_ENABLE_FAST_PATH'] = 'true'
        os.environ['HARBORAI_ENABLE_COST_TRACKING'] = 'true'
        os.environ['HARBORAI_ENABLE_DETAILED_LOGGING'] = 'false'
        print("[CONFIG] è®¾ç½® BALANCED æ¨¡å¼ç¯å¢ƒå˜é‡")
    elif mode == "FULL":
        os.environ['HARBORAI_PERFORMANCE_MODE'] = 'full'
        os.environ['HARBORAI_ENABLE_FAST_PATH'] = 'false'
        os.environ['HARBORAI_ENABLE_COST_TRACKING'] = 'true'
        os.environ['HARBORAI_ENABLE_DETAILED_LOGGING'] = 'true'
        print("[CONFIG] è®¾ç½® FULL æ¨¡å¼ç¯å¢ƒå˜é‡")
    else:
        print(f"[WARNING] æœªçŸ¥çš„æ€§èƒ½æ¨¡å¼: {mode}")

def reload_harborai_module():
    """é‡æ–°åŠ è½½ HarborAI æ¨¡å—ä»¥åº”ç”¨æ–°çš„ç¯å¢ƒå˜é‡"""
    modules_to_reload = []
    for module_name in list(sys.modules.keys()):
        if module_name.startswith('harborai'):
            modules_to_reload.append(module_name)
    
    # åˆ é™¤å·²åŠ è½½çš„æ¨¡å—
    for module_name in modules_to_reload:
        if module_name in sys.modules:
            del sys.modules[module_name]
    
    print("[DEBUG] å·²é‡æ–°åŠ è½½ HarborAI æ¨¡å—")

def get_test_schema() -> Dict[str, Any]:
    """è·å–æµ‹è¯•ç”¨çš„JSON Schema"""
    return {
        "type": "object",
        "properties": {
            "analysis": {
                "type": "string",
                "description": "å¯¹äººå·¥æ™ºèƒ½æŠ€æœ¯å‘å±•è¶‹åŠ¿çš„è¯¦ç»†åˆ†æ"
            },
            "trends": {
                "type": "array",
                "items": {
                    "type": "string"
                },
                "description": "ä¸»è¦å‘å±•è¶‹åŠ¿åˆ—è¡¨",
                "minItems": 3,
                "maxItems": 8
            },
            "confidence": {
                "type": "number",
                "minimum": 0,
                "maximum": 1,
                "description": "åˆ†æç»“æœçš„ç½®ä¿¡åº¦ï¼ˆ0-1ä¹‹é—´ï¼‰"
            },
            "keywords": {
                "type": "array",
                "items": {
                    "type": "string"
                },
                "description": "å…³é”®è¯åˆ—è¡¨",
                "minItems": 3,
                "maxItems": 10
            }
        },
        "required": ["analysis", "trends", "confidence", "keywords"],
        "additionalProperties": False
    }

def test_harborai_with_mode(user_input: str, schema: Dict[str, Any], mode: str) -> Tuple[float, Any, str]:
    """æµ‹è¯•æŒ‡å®šæ€§èƒ½æ¨¡å¼ä¸‹çš„ HarborAI ç»“æ„åŒ–è¾“å‡º"""
    print(f"[INFO] å¼€å§‹æµ‹è¯• HarborAI {mode} æ¨¡å¼ç»“æ„åŒ–è¾“å‡º...")
    
    try:
        # è®¾ç½®æ€§èƒ½æ¨¡å¼ç¯å¢ƒå˜é‡
        set_performance_mode_env(mode)
        
        # é‡æ–°åŠ è½½æ¨¡å—ä»¥åº”ç”¨æ–°çš„ç¯å¢ƒå˜é‡
        reload_harborai_module()
        
        # å¯¼å…¥ HarborAI
        from harborai import HarborAI
        
        # åˆ›å»º HarborAI å®¢æˆ·ç«¯
        client = HarborAI(
            api_key=os.getenv("DEEPSEEK_API_KEY"),
            base_url=os.getenv("DEEPSEEK_BASE_URL")
        )
        
        # æ„å»º response_format
        response_format = {
            "type": "json_schema",
            "json_schema": {
                "name": "ai_trend_analysis",
                "schema": schema,
                "strict": True
            }
        }
        
        print(f"[DEBUG] ä½¿ç”¨æ¨¡å‹: deepseek-chat")
        print(f"[DEBUG] æ€§èƒ½æ¨¡å¼: {mode}")
        print(f"[DEBUG] ç¯å¢ƒå˜é‡æ£€æŸ¥:")
        print(f"  HARBORAI_PERFORMANCE_MODE: {os.getenv('HARBORAI_PERFORMANCE_MODE', 'None')}")
        print(f"  HARBORAI_ENABLE_FAST_PATH: {os.getenv('HARBORAI_ENABLE_FAST_PATH', 'None')}")
        print(f"  HARBORAI_ENABLE_COST_TRACKING: {os.getenv('HARBORAI_ENABLE_COST_TRACKING', 'None')}")
        print(f"  HARBORAI_ENABLE_DETAILED_LOGGING: {os.getenv('HARBORAI_ENABLE_DETAILED_LOGGING', 'None')}")
        
        # è®°å½•å¼€å§‹æ—¶é—´ä¸èµ„æºä½¿ç”¨
        start_time = time.time()
        proc = psutil.Process(os.getpid()) if psutil else None
        cpu_start = proc.cpu_times() if proc else None
        mem_start = proc.memory_info().rss if proc else None
        io_start = proc.io_counters() if (proc and hasattr(proc, "io_counters")) else None
        
        # è°ƒç”¨ HarborAI ç»“æ„åŒ–è¾“å‡º
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "user", "content": user_input}
            ],
            response_format=response_format,
            structured_provider="agently",  # æ˜ç¡®æŒ‡å®šä½¿ç”¨ Agently
            temperature=0.1
        )
        
        # è®°å½•ç»“æŸæ—¶é—´ä¸èµ„æºä½¿ç”¨
        end_time = time.time()
        duration = end_time - start_time
        cpu_end = proc.cpu_times() if proc else None
        mem_end = proc.memory_info().rss if proc else None
        io_end = proc.io_counters() if (proc and hasattr(proc, "io_counters")) else None
        if psutil:
            cpu_user = (cpu_end.user - cpu_start.user) if (cpu_start and cpu_end) else None
            cpu_sys = (cpu_end.system - cpu_start.system) if (cpu_start and cpu_end) else None
            mem_rss_mb = (mem_end / (1024*1024)) if mem_end is not None else None
            io_read = (io_end.read_bytes - io_start.read_bytes) if (io_start and io_end) else None
            io_write = (io_end.write_bytes - io_start.write_bytes) if (io_start and io_end) else None
            print(f"  èµ„æº: CPU(user) {cpu_user}s, CPU(sys) {cpu_sys}s, RSS {mem_rss_mb}MB, è¯» {io_read}B, å†™ {io_write}B")
        
        print(f"[SUCCESS] HarborAI {mode} æ¨¡å¼è°ƒç”¨æˆåŠŸï¼Œè€—æ—¶: {duration:.3f}ç§’")
        
        # è·å–ç»“æ„åŒ–ç»“æœ
        if hasattr(response.choices[0].message, 'parsed') and response.choices[0].message.parsed:
            result = response.choices[0].message.parsed
            return duration, result, None
        else:
            error_msg = "æœªè·å¾—ç»“æ„åŒ–è¾“å‡ºç»“æœ"
            print(f"[ERROR] {error_msg}")
            return duration, None, error_msg
            
    except Exception as e:
        print(f"[ERROR] HarborAI {mode} æ¨¡å¼æµ‹è¯•å¤±è´¥: {e}")
        return 0, None, str(e)

def test_direct_agently_structured_output(user_input: str, schema: Dict[str, Any]) -> Tuple[float, Any, str]:
    """æµ‹è¯•ç›´æ¥ä½¿ç”¨ Agently ç»“æ„åŒ–è¾“å‡ºï¼ˆåŸºå‡†æµ‹è¯•ï¼‰"""
    print("[INFO] å¼€å§‹æµ‹è¯•ç›´æ¥ Agently ç»“æ„åŒ–è¾“å‡ºï¼ˆåŸºå‡†ï¼‰...")
    
    try:
        from Agently.agently import Agently
        
        # é…ç½® Agently
        api_key = os.getenv("DEEPSEEK_API_KEY")
        base_url = os.getenv("DEEPSEEK_BASE_URL")
        model = "deepseek-chat"
        
        print(f"[DEBUG] é…ç½® Agently: base_url={base_url}, model={model}")
        
        # ä½¿ç”¨ OpenAICompatible å…¨å±€é…ç½®
        Agently.set_settings(
            "OpenAICompatible",
            {
                "base_url": base_url,
                "model": model,
                "model_type": "chat",
                "auth": api_key,
            },
        )
        
        print("[DEBUG] Agently å…¨å±€é…ç½®å®Œæˆ")
        
        # åˆ›å»º agent
        agent = Agently.create_agent()
        
        # å°† JSON Schema è½¬æ¢ä¸º Agently output æ ¼å¼
        agently_output = convert_json_schema_to_agently_output(schema)
        
        # è®°å½•å¼€å§‹æ—¶é—´ä¸èµ„æºä½¿ç”¨
        start_time = time.time()
        proc = psutil.Process(os.getpid()) if psutil else None
        cpu_start = proc.cpu_times() if proc else None
        mem_start = proc.memory_info().rss if proc else None
        io_start = proc.io_counters() if (proc and hasattr(proc, "io_counters")) else None
        
        # è°ƒç”¨ Agently ç»“æ„åŒ–è¾“å‡º
        result = (
            agent
            .input(user_input)
            .output(agently_output)
            .start()
        )
        
        # è®°å½•ç»“æŸæ—¶é—´ä¸èµ„æºä½¿ç”¨
        end_time = time.time()
        duration = end_time - start_time
        cpu_end = proc.cpu_times() if proc else None
        mem_end = proc.memory_info().rss if proc else None
        io_end = proc.io_counters() if (proc and hasattr(proc, "io_counters")) else None
        if psutil:
            cpu_user = (cpu_end.user - cpu_start.user) if (cpu_start and cpu_end) else None
            cpu_sys = (cpu_end.system - cpu_start.system) if (cpu_start and cpu_end) else None
            mem_rss_mb = (mem_end / (1024*1024)) if mem_end is not None else None
            io_read = (io_end.read_bytes - io_start.read_bytes) if (io_start and io_end) else None
            io_write = (io_end.write_bytes - io_start.write_bytes) if (io_start and io_end) else None
            print(f"  èµ„æº: CPU(user) {cpu_user}s, CPU(sys) {cpu_sys}s, RSS {mem_rss_mb}MB, è¯» {io_read}B, å†™ {io_write}B")
        
        print(f"[SUCCESS] ç›´æ¥ Agently è°ƒç”¨æˆåŠŸï¼Œè€—æ—¶: {duration:.3f}ç§’")
        
        return duration, result, None
        
    except Exception as e:
        print(f"[ERROR] ç›´æ¥ Agently æµ‹è¯•å¤±è´¥: {e}")
        return 0, None, str(e)

def convert_json_schema_to_agently_output(schema: Dict[str, Any]) -> Dict[str, Any]:
    """å°† JSON Schema è½¬æ¢ä¸º Agently output æ ¼å¼"""
    agently_output = {}
    
    if "properties" in schema:
        for prop_name, prop_def in schema["properties"].items():
            prop_type = prop_def.get("type", "string")
            description = prop_def.get("description", "")
            
            if prop_type == "string":
                agently_output[prop_name] = ("str", description)
            elif prop_type == "number":
                agently_output[prop_name] = ("float", description)
            elif prop_type == "integer":
                agently_output[prop_name] = ("int", description)
            elif prop_type == "boolean":
                agently_output[prop_name] = ("bool", description)
            elif prop_type == "array":
                items_type = prop_def.get("items", {}).get("type", "string")
                if items_type == "string":
                    agently_output[prop_name] = ([("str", "")], description)
                elif items_type == "number":
                    agently_output[prop_name] = ([("float", "")], description)
                elif items_type == "integer":
                    agently_output[prop_name] = ([("int", "")], description)
                else:
                    agently_output[prop_name] = ([("str", "")], description)
            else:
                agently_output[prop_name] = ("str", description)
    
    return agently_output

def run_performance_comparison(iterations: int = 3) -> None:
    """è¿è¡Œæ€§èƒ½æ¨¡å¼å¯¹æ¯”æµ‹è¯•"""
    print("="*80)
    print("ğŸš€ HarborAI æ€§èƒ½æ¨¡å¼å¯¹æ¯”æµ‹è¯•")
    print("="*80)
    
    # æµ‹è¯•å‚æ•°
    user_input = "è¯·åˆ†æäººå·¥æ™ºèƒ½æŠ€æœ¯çš„å‘å±•è¶‹åŠ¿"
    schema = get_test_schema()
    
    print(f"[CONFIG] æµ‹è¯•è½®æ•°: {iterations}")
    print(f"[CONFIG] ç”¨æˆ·è¾“å…¥: {user_input}")
    print(f"[CONFIG] ä½¿ç”¨æ¨¡å‹: deepseek-chat")
    print(f"[CONFIG] æµ‹è¯•æ¨¡å¼: ç›´æ¥ Agentlyï¼ˆåŸºå‡†ï¼‰ã€HarborAI FASTã€HarborAI BALANCEDã€HarborAI FULL")
    print()
    
    # å­˜å‚¨æµ‹è¯•ç»“æœ
    test_modes = ["Agently", "FAST", "BALANCED", "FULL"]
    results = {mode: {"times": [], "results": [], "errors": []} for mode in test_modes}
    
    # è¿›è¡Œå¤šè½®æµ‹è¯•
    for i in range(iterations):
        print(f"ç¬¬ {i+1}/{iterations} è½®æµ‹è¯•")
        print("=" * 60)
        
        # æµ‹è¯•ç›´æ¥ Agentlyï¼ˆåŸºå‡†ï¼‰
        print(f"[ROUND {i+1}] æµ‹è¯•ç›´æ¥ Agentlyï¼ˆåŸºå‡†ï¼‰...")
        agently_time, agently_result, agently_error = test_direct_agently_structured_output(user_input, schema)
        results["Agently"]["times"].append(agently_time)
        results["Agently"]["results"].append(agently_result)
        results["Agently"]["errors"].append(agently_error)
        print(f"  è€—æ—¶: {agently_time:.3f}ç§’")
        print()
        
        # æµ‹è¯• HarborAI FAST æ¨¡å¼
        print(f"[ROUND {i+1}] æµ‹è¯• HarborAI FAST æ¨¡å¼...")
        fast_time, fast_result, fast_error = test_harborai_with_mode(user_input, schema, "FAST")
        results["FAST"]["times"].append(fast_time)
        results["FAST"]["results"].append(fast_result)
        results["FAST"]["errors"].append(fast_error)
        print(f"  è€—æ—¶: {fast_time:.3f}ç§’")
        print()
        
        # æµ‹è¯• HarborAI BALANCED æ¨¡å¼
        print(f"[ROUND {i+1}] æµ‹è¯• HarborAI BALANCED æ¨¡å¼...")
        balanced_time, balanced_result, balanced_error = test_harborai_with_mode(user_input, schema, "BALANCED")
        results["BALANCED"]["times"].append(balanced_time)
        results["BALANCED"]["results"].append(balanced_result)
        results["BALANCED"]["errors"].append(balanced_error)
        print(f"  è€—æ—¶: {balanced_time:.3f}ç§’")
        print()
        
        # æµ‹è¯• HarborAI FULL æ¨¡å¼
        print(f"[ROUND {i+1}] æµ‹è¯• HarborAI FULL æ¨¡å¼...")
        full_time, full_result, full_error = test_harborai_with_mode(user_input, schema, "FULL")
        results["FULL"]["times"].append(full_time)
        results["FULL"]["results"].append(full_result)
        results["FULL"]["errors"].append(full_error)
        print(f"  è€—æ—¶: {full_time:.3f}ç§’")
        print()
        
        # æœ¬è½®å¯¹æ¯”
        print(f"[ROUND {i+1}] æœ¬è½®æ€§èƒ½å¯¹æ¯”:")
        print(f"  ç›´æ¥ Agentlyï¼ˆåŸºå‡†ï¼‰: {agently_time:.3f}ç§’")
        print(f"  HarborAI FAST:       {fast_time:.3f}ç§’")
        print(f"  HarborAI BALANCED:   {balanced_time:.3f}ç§’")
        print(f"  HarborAI FULL:       {full_time:.3f}ç§’")
        
        if agently_time > 0:
            print(f"  ç›¸å¯¹æ€§èƒ½æ¯”ç‡:")
            if fast_time > 0:
                fast_ratio = fast_time / agently_time
                print(f"    FAST vs Agently:     {fast_ratio:.2f}x ({(fast_ratio-1)*100:+.1f}%)")
            if balanced_time > 0:
                balanced_ratio = balanced_time / agently_time
                print(f"    BALANCED vs Agently: {balanced_ratio:.2f}x ({(balanced_ratio-1)*100:+.1f}%)")
            if full_time > 0:
                full_ratio = full_time / agently_time
                print(f"    FULL vs Agently:     {full_ratio:.2f}x ({(full_ratio-1)*100:+.1f}%)")
        print()
    
    # è®¡ç®—ç»Ÿè®¡æ•°æ®
    print("="*80)
    print("ğŸ“Š æ€§èƒ½æ¨¡å¼å¯¹æ¯”ç»Ÿè®¡ç»“æœ")
    print("="*80)
    
    stats = {}
    for mode in test_modes:
        valid_times = [t for t in results[mode]["times"] if t > 0]
        if valid_times:
            stats[mode] = {
                "avg": statistics.mean(valid_times),
                "min": min(valid_times),
                "max": max(valid_times),
                "success_rate": len(valid_times) / iterations * 100
            }
        else:
            stats[mode] = None
    
    # è¾“å‡ºè¯¦ç»†ç»Ÿè®¡
    for mode in test_modes:
        if stats[mode]:
            print(f"{mode} æ¨¡å¼:")
            print(f"  å¹³å‡è€—æ—¶: {stats[mode]['avg']:.3f}ç§’")
            print(f"  æœ€å°è€—æ—¶: {stats[mode]['min']:.3f}ç§’")
            print(f"  æœ€å¤§è€—æ—¶: {stats[mode]['max']:.3f}ç§’")
            print(f"  æˆåŠŸç‡:   {stats[mode]['success_rate']:.1f}%")
            # ååé‡æŒ‰ 1/å¹³å‡è€—æ—¶ ä¼°ç®—
            throughput = (1.0 / stats[mode]['avg']) if stats[mode]['avg'] > 0 else 0.0
            print(f"  ååé‡:   {throughput:.3f} æ¬¡/ç§’")
        else:
            print(f"{mode} æ¨¡å¼: æ‰€æœ‰æµ‹è¯•å‡å¤±è´¥")
        print()
    
    # æ€§èƒ½å¯¹æ¯”åˆ†æ
    if stats["Agently"]:
        baseline_avg = stats["Agently"]["avg"]
        print("ğŸ” æ€§èƒ½å¯¹æ¯”åˆ†æï¼ˆç›¸å¯¹äº Agently åŸºå‡†ï¼‰:")
        print(f"  Agently åŸºå‡†å¹³å‡è€—æ—¶: {baseline_avg:.3f}ç§’")
        print()
        
        for mode in ["FAST", "BALANCED", "FULL"]:
            if stats[mode]:
                mode_avg = stats[mode]["avg"]
                ratio = mode_avg / baseline_avg
                improvement = (1 - ratio) * 100
                
                print(f"  HarborAI {mode} æ¨¡å¼:")
                print(f"    å¹³å‡è€—æ—¶: {mode_avg:.3f}ç§’")
                print(f"    ç›¸å¯¹æ€§èƒ½: {ratio:.2f}x")
                if improvement > 0:
                    print(f"    æ€§èƒ½æå‡: +{improvement:.1f}%")
                else:
                    print(f"    æ€§èƒ½ä¸‹é™: {improvement:.1f}%")
                print()
        
        # éªŒè¯ README.md æ•°æ®
        print("ğŸ“‹ README.md æ•°æ®éªŒè¯:")
        readme_data = {
            "Agently": {"expected": 4.37, "ratio": 1.00},
            "FAST": {"expected": 3.87, "ratio": 0.88},
            "BALANCED": {"expected": 4.47, "ratio": 1.02},
            "FULL": {"expected": 3.92, "ratio": 0.90}
        }
        
        for mode in test_modes:
            if stats[mode]:
                actual_time = stats[mode]["avg"]
                expected_time = readme_data[mode]["expected"]
                expected_ratio = readme_data[mode]["ratio"]
                actual_ratio = actual_time / baseline_avg if mode != "Agently" else 1.0
                
                print(f"  {mode} æ¨¡å¼:")
                print(f"    README é¢„æœŸ: {expected_time:.2f}ç§’ ({expected_ratio:.2f}x)")
                print(f"    å®é™…æµ‹è¯•:   {actual_time:.3f}ç§’ ({actual_ratio:.2f}x)")
                
                time_diff = abs(actual_time - expected_time)
                ratio_diff = abs(actual_ratio - expected_ratio)
                
                if time_diff < 1.0 and ratio_diff < 0.1:
                    print(f"    éªŒè¯ç»“æœ: âœ… æ•°æ®åŸºæœ¬ä¸€è‡´")
                else:
                    print(f"    éªŒè¯ç»“æœ: âŒ æ•°æ®å­˜åœ¨å·®å¼‚")
                    print(f"    æ—¶é—´å·®å¼‚: {time_diff:.3f}ç§’")
                    print(f"    æ¯”ç‡å·®å¼‚: {ratio_diff:.3f}")
                print()
    
    # é”™è¯¯åˆ†æ
    print("âŒ é”™è¯¯ç»Ÿè®¡:")
    for mode in test_modes:
        error_count = sum(1 for e in results[mode]["errors"] if e is not None)
        if error_count > 0:
            print(f"  {mode} æ¨¡å¼é”™è¯¯: {error_count}/{iterations}")
            for i, error in enumerate(results[mode]["errors"]):
                if error:
                    print(f"    ç¬¬{i+1}è½®: {error}")
        else:
            print(f"  {mode} æ¨¡å¼: æ— é”™è¯¯")
    
    print()
    print("="*80)
    print("âœ… HarborAI æ€§èƒ½æ¨¡å¼å¯¹æ¯”æµ‹è¯•å®Œæˆ")
    print("="*80)

if __name__ == "__main__":
    print("ğŸ¯ å¼€å§‹ HarborAI æ€§èƒ½æ¨¡å¼å¯¹æ¯”æµ‹è¯•")
    print("ğŸ“‹ æœ¬æµ‹è¯•å°†å¯¹æ¯”ä»¥ä¸‹å››ç§æƒ…å†µï¼š")
    print("   1. ç›´æ¥ Agentlyï¼ˆåŸºå‡†ï¼‰")
    print("   2. HarborAI FAST æ¨¡å¼")
    print("   3. HarborAI BALANCED æ¨¡å¼")
    print("   4. HarborAI FULL æ¨¡å¼")
    print()
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    if not os.getenv("DEEPSEEK_API_KEY") or not os.getenv("DEEPSEEK_BASE_URL"):
        print("[ERROR] è¯·ç¡®ä¿ .env æ–‡ä»¶ä¸­é…ç½®äº† DEEPSEEK_API_KEY å’Œ DEEPSEEK_BASE_URL")
        exit(1)
    
    # è¿è¡Œæ€§èƒ½æ¨¡å¼å¯¹æ¯”æµ‹è¯•
    run_performance_comparison(iterations=3)