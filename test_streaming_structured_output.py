#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•agentlyæµå¼ç»“æ„åŒ–è¾“å‡ºåŠŸèƒ½
éªŒè¯HarborAIçš„æµå¼ç»“æ„åŒ–è¾“å‡ºæ˜¯å¦æ­£ç¡®å®ç°
"""

import json
import sys
import os
import time
import asyncio

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__)))
sys.path.insert(0, project_root)

# åŠ è½½ç¯å¢ƒå˜é‡
try:
    from dotenv import load_dotenv
    env_path = os.path.join(project_root, '.env')
    if os.path.exists(env_path):
        load_dotenv(env_path)
        print(f"âœ“ å·²åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶: {env_path}")
    else:
        print(f"âš  ç¯å¢ƒå˜é‡æ–‡ä»¶ä¸å­˜åœ¨: {env_path}")
except ImportError:
    print("âš  python-dotenvæœªå®‰è£…ï¼Œç›´æ¥ä½¿ç”¨ç¯å¢ƒå˜é‡")

from harborai import HarborAI

def test_sync_streaming_structured_output():
    """æµ‹è¯•åŒæ­¥æµå¼ç»“æ„åŒ–è¾“å‡º"""
    print("ğŸ”„ æµ‹è¯•åŒæ­¥æµå¼ç»“æ„åŒ–è¾“å‡º")
    
    client = HarborAI()
    
    # åˆ›å»ºæµ‹è¯•schema
    schema = {
        "type": "object",
        "properties": {
            "analysis": {
                "type": "string",
                "description": "è¯¦ç»†çš„æ–‡æœ¬åˆ†æ"
            },
            "sentiment": {
                "type": "string",
                "enum": ["positive", "negative", "neutral"],
                "description": "æƒ…æ„Ÿå€¾å‘åˆ†æ"
            },
            "confidence": {
                "type": "number",
                "minimum": 0,
                "maximum": 100,
                "description": "ç½®ä¿¡åº¦åˆ†æ•°"
            },
            "keywords": {
                "type": "array",
                "items": {"type": "string"},
                "description": "å…³é”®è¯åˆ—è¡¨"
            }
        },
        "required": ["analysis", "sentiment", "confidence", "keywords"]
    }
    
    response_format = {
        "type": "json_schema",
        "json_schema": {
            "name": "text_analysis",
            "schema": schema,
            "strict": True
        }
    }
    
    start_time = time.time()
    
    # ä½¿ç”¨æµå¼è°ƒç”¨
    stream = client.chat.completions.create(
        model="deepseek-chat",
        messages=[
            {
                "role": "user",
                "content": "è¯·è¯¦ç»†åˆ†æè¿™æ®µæ–‡æœ¬ï¼š'ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œå¿ƒæƒ…ä¸é”™ï¼Œå‡†å¤‡å‡ºå»æ•£æ­¥ï¼Œäº«å—ç¾å¥½çš„é˜³å…‰ã€‚'"
            }
        ],
        response_format=response_format,
        structured_provider="agently",  # ä½¿ç”¨agentlyè¿›è¡Œæµå¼ç»“æ„åŒ–è¾“å‡º
        stream=True,
        temperature=0.1,
        max_tokens=1000
    )
    
    print("ğŸ” æµå¼å“åº”æ•°æ®:")
    chunks_received = 0
    final_result = None
    
    for chunk in stream:
        chunks_received += 1
        print(f"   Chunk {chunks_received}: {chunk}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰parsedå­—æ®µ
        if hasattr(chunk.choices[0], 'delta') and hasattr(chunk.choices[0].delta, 'parsed'):
            parsed_data = chunk.choices[0].delta.parsed
            if parsed_data:
                print(f"   ğŸ“Š è§£ææ•°æ®: {parsed_data}")
                final_result = parsed_data
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å®Œæ•´çš„message.parsed
        if hasattr(chunk.choices[0], 'message') and hasattr(chunk.choices[0].message, 'parsed'):
            parsed_data = chunk.choices[0].message.parsed
            if parsed_data:
                print(f"   ğŸ“Š å®Œæ•´è§£ææ•°æ®: {parsed_data}")
                final_result = parsed_data
    
    end_time = time.time()
    
    print(f"âœ… åŒæ­¥æµå¼è°ƒç”¨å®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.2f}ç§’")
    print(f"   æ¥æ”¶åˆ° {chunks_received} ä¸ªæ•°æ®å—")
    print(f"   æœ€ç»ˆç»“æœ: {final_result}")
    
    # éªŒè¯ç»“æœ
    assert final_result is not None, "æµå¼è°ƒç”¨æ²¡æœ‰è¿”å›è§£æç»“æœ"
    assert "analysis" in final_result, "ç¼ºå°‘analysiså­—æ®µ"
    assert "sentiment" in final_result, "ç¼ºå°‘sentimentå­—æ®µ"
    assert "confidence" in final_result, "ç¼ºå°‘confidenceå­—æ®µ"
    assert "keywords" in final_result, "ç¼ºå°‘keywordså­—æ®µ"
    
    return final_result

async def test_async_streaming_structured_output():
    """æµ‹è¯•å¼‚æ­¥æµå¼ç»“æ„åŒ–è¾“å‡º"""
    print("ğŸ”„ æµ‹è¯•å¼‚æ­¥æµå¼ç»“æ„åŒ–è¾“å‡º")
    
    client = HarborAI()
    
    # åˆ›å»ºæµ‹è¯•schema
    schema = {
        "type": "object",
        "properties": {
            "analysis": {
                "type": "string",
                "description": "è¯¦ç»†çš„æ–‡æœ¬åˆ†æ"
            },
            "sentiment": {
                "type": "string",
                "enum": ["positive", "negative", "neutral"],
                "description": "æƒ…æ„Ÿå€¾å‘åˆ†æ"
            },
            "confidence": {
                "type": "number",
                "minimum": 0,
                "maximum": 100,
                "description": "ç½®ä¿¡åº¦åˆ†æ•°"
            },
            "keywords": {
                "type": "array",
                "items": {"type": "string"},
                "description": "å…³é”®è¯åˆ—è¡¨"
            }
        },
        "required": ["analysis", "sentiment", "confidence", "keywords"]
    }
    
    response_format = {
        "type": "json_schema",
        "json_schema": {
            "name": "text_analysis",
            "schema": schema,
            "strict": True
        }
    }
    
    start_time = time.time()
    
    # ä½¿ç”¨å¼‚æ­¥æµå¼è°ƒç”¨
    stream = await client.chat.completions.acreate(
        model="deepseek-chat",
        messages=[
            {
                "role": "user",
                "content": "è¯·è¯¦ç»†åˆ†æè¿™æ®µæ–‡æœ¬ï¼š'ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œå¿ƒæƒ…ä¸é”™ï¼Œå‡†å¤‡å‡ºå»æ•£æ­¥ï¼Œäº«å—ç¾å¥½çš„é˜³å…‰ã€‚'"
            }
        ],
        response_format=response_format,
        structured_provider="agently",  # ä½¿ç”¨agentlyè¿›è¡Œæµå¼ç»“æ„åŒ–è¾“å‡º
        stream=True,
        temperature=0.1,
        max_tokens=1000
    )
    
    print("ğŸ” å¼‚æ­¥æµå¼å“åº”æ•°æ®:")
    chunks_received = 0
    final_result = None
    
    async for chunk in stream:
        chunks_received += 1
        print(f"   Async Chunk {chunks_received}: {chunk}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰parsedå­—æ®µ
        if hasattr(chunk.choices[0], 'delta') and hasattr(chunk.choices[0].delta, 'parsed'):
            parsed_data = chunk.choices[0].delta.parsed
            if parsed_data:
                print(f"   ğŸ“Š å¼‚æ­¥è§£ææ•°æ®: {parsed_data}")
                final_result = parsed_data
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å®Œæ•´çš„message.parsed
        if hasattr(chunk.choices[0], 'message') and hasattr(chunk.choices[0].message, 'parsed'):
            parsed_data = chunk.choices[0].message.parsed
            if parsed_data:
                print(f"   ğŸ“Š å¼‚æ­¥å®Œæ•´è§£ææ•°æ®: {parsed_data}")
                final_result = parsed_data
    
    end_time = time.time()
    
    print(f"âœ… å¼‚æ­¥æµå¼è°ƒç”¨å®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.2f}ç§’")
    print(f"   æ¥æ”¶åˆ° {chunks_received} ä¸ªæ•°æ®å—")
    print(f"   æœ€ç»ˆç»“æœ: {final_result}")
    
    # éªŒè¯ç»“æœ
    assert final_result is not None, "å¼‚æ­¥æµå¼è°ƒç”¨æ²¡æœ‰è¿”å›è§£æç»“æœ"
    assert "analysis" in final_result, "ç¼ºå°‘analysiså­—æ®µ"
    assert "sentiment" in final_result, "ç¼ºå°‘sentimentå­—æ®µ"
    assert "confidence" in final_result, "ç¼ºå°‘confidenceå­—æ®µ"
    assert "keywords" in final_result, "ç¼ºå°‘keywordså­—æ®µ"
    
    return final_result

def test_streaming_vs_non_streaming():
    """æ¯”è¾ƒæµå¼å’Œéæµå¼ç»“æ„åŒ–è¾“å‡ºçš„ç»“æœ"""
    print("ğŸ”„ æµ‹è¯•æµå¼vséæµå¼ç»“æ„åŒ–è¾“å‡º")
    
    client = HarborAI()
    
    # åˆ›å»ºæµ‹è¯•schema
    schema = {
        "type": "object",
        "properties": {
            "sentiment": {
                "type": "string",
                "enum": ["positive", "negative", "neutral"],
                "description": "æƒ…æ„Ÿå€¾å‘åˆ†æ"
            },
            "confidence": {
                "type": "number",
                "minimum": 0,
                "maximum": 100,
                "description": "ç½®ä¿¡åº¦åˆ†æ•°"
            }
        },
        "required": ["sentiment", "confidence"]
    }
    
    response_format = {
        "type": "json_schema",
        "json_schema": {
            "name": "sentiment_analysis",
            "schema": schema,
            "strict": True
        }
    }
    
    test_message = "ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œå¿ƒæƒ…ä¸é”™"
    
    # éæµå¼è°ƒç”¨
    print("   ğŸ“ éæµå¼è°ƒç”¨...")
    start_time = time.time()
    non_stream_response = client.chat.completions.create(
        model="deepseek-chat",
        messages=[{"role": "user", "content": f"è¯·åˆ†æè¿™æ®µæ–‡æœ¬çš„æƒ…æ„Ÿï¼š'{test_message}'"}],
        response_format=response_format,
        structured_provider="agently",
        stream=False,
        temperature=0.1,
        max_tokens=500
    )
    non_stream_time = time.time() - start_time
    non_stream_result = non_stream_response.choices[0].message.parsed
    
    # æµå¼è°ƒç”¨
    print("   ğŸŒŠ æµå¼è°ƒç”¨...")
    start_time = time.time()
    stream_response = client.chat.completions.create(
        model="deepseek-chat",
        messages=[{"role": "user", "content": f"è¯·åˆ†æè¿™æ®µæ–‡æœ¬çš„æƒ…æ„Ÿï¼š'{test_message}'"}],
        response_format=response_format,
        structured_provider="agently",
        stream=True,
        temperature=0.1,
        max_tokens=500
    )
    
    stream_result = None
    for chunk in stream_response:
        if hasattr(chunk.choices[0], 'delta') and hasattr(chunk.choices[0].delta, 'parsed'):
            parsed_data = chunk.choices[0].delta.parsed
            if parsed_data:
                stream_result = parsed_data
        if hasattr(chunk.choices[0], 'message') and hasattr(chunk.choices[0].message, 'parsed'):
            parsed_data = chunk.choices[0].message.parsed
            if parsed_data:
                stream_result = parsed_data
    
    stream_time = time.time() - start_time
    
    print(f"ğŸ“Š ç»“æœæ¯”è¾ƒ:")
    print(f"   éæµå¼ç»“æœ: {non_stream_result} (è€—æ—¶: {non_stream_time:.2f}ç§’)")
    print(f"   æµå¼ç»“æœ: {stream_result} (è€—æ—¶: {stream_time:.2f}ç§’)")
    
    # éªŒè¯ç»“æœç»“æ„ä¸€è‡´æ€§
    assert type(non_stream_result) == type(stream_result), "ç»“æœç±»å‹ä¸ä¸€è‡´"
    assert set(non_stream_result.keys()) == set(stream_result.keys()), "ç»“æœå­—æ®µä¸ä¸€è‡´"
    
    return non_stream_result, stream_result

def test_sync_streaming_only():
    """ä»…æµ‹è¯•åŒæ­¥æµå¼ç»“æ„åŒ–è¾“å‡º"""
    print("ğŸ§ª æµ‹è¯•åŒæ­¥æµå¼ç»“æ„åŒ–è¾“å‡ºåŠŸèƒ½")
    print("=" * 60)
    
    try:
        # æµ‹è¯•åŒæ­¥æµå¼
        print("\n1ï¸âƒ£ æµ‹è¯•åŒæ­¥æµå¼ç»“æ„åŒ–è¾“å‡º")
        sync_result = test_sync_streaming_structured_output()
        
        # æµ‹è¯•æµå¼vséæµå¼
        print("\n2ï¸âƒ£ æµ‹è¯•æµå¼vséæµå¼ç»“æ„åŒ–è¾“å‡º")
        non_stream_result, stream_result = test_streaming_vs_non_streaming()
        
        print("\nğŸ“Š åŒæ­¥æµ‹è¯•ç»“æœ:")
        print(f"åŒæ­¥æµå¼ç»“æœ: {sync_result}")
        print(f"éæµå¼ç»“æœ: {non_stream_result}")
        print(f"æµå¼ç»“æœ: {stream_result}")
        
        print("âœ… åŒæ­¥æµå¼ç»“æ„åŒ–è¾“å‡ºæµ‹è¯•é€šè¿‡")
        print("âœ… æµå¼å’Œéæµå¼ç»“æœç»“æ„ä¸€è‡´")
        
        return True
        
    except Exception as e:
        print(f"âŒ åŒæ­¥æµå¼ç»“æ„åŒ–è¾“å‡ºæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

async def test_async_streaming_only():
    """ä»…æµ‹è¯•å¼‚æ­¥æµå¼ç»“æ„åŒ–è¾“å‡º"""
    print("ğŸ§ª æµ‹è¯•å¼‚æ­¥æµå¼ç»“æ„åŒ–è¾“å‡ºåŠŸèƒ½")
    print("=" * 60)
    
    try:
        # æµ‹è¯•å¼‚æ­¥æµå¼
        print("\n1ï¸âƒ£ æµ‹è¯•å¼‚æ­¥æµå¼ç»“æ„åŒ–è¾“å‡º")
        async_result = await test_async_streaming_structured_output()
        
        print("\nğŸ“Š å¼‚æ­¥æµ‹è¯•ç»“æœ:")
        print(f"å¼‚æ­¥æµå¼ç»“æœ: {async_result}")
        
        print("âœ… å¼‚æ­¥æµå¼ç»“æ„åŒ–è¾“å‡ºæµ‹è¯•é€šè¿‡")
        
        return True
        
    except Exception as e:
        print(f"âŒ å¼‚æ­¥æµå¼ç»“æ„åŒ–è¾“å‡ºæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    # å…ˆæµ‹è¯•åŒæ­¥åŠŸèƒ½
    print("ğŸ”„ å¼€å§‹åŒæ­¥æµå¼æµ‹è¯•...")
    sync_success = test_sync_streaming_only()
    
    # å†æµ‹è¯•å¼‚æ­¥åŠŸèƒ½
    print("\nğŸ”„ å¼€å§‹å¼‚æ­¥æµå¼æµ‹è¯•...")
    async_success = asyncio.run(test_async_streaming_only())
    
    if sync_success and async_success:
        print("\nğŸ‰ agentlyæµå¼ç»“æ„åŒ–è¾“å‡ºåŠŸèƒ½éªŒè¯é€šè¿‡")
        print("âœ… æ”¯æŒåŒæ­¥å’Œå¼‚æ­¥æµå¼ç»“æ„åŒ–è¾“å‡º")
        print("âœ… æµå¼è¾“å‡ºä¸éæµå¼è¾“å‡ºç»“æœä¸€è‡´")
        sys.exit(0)
    else:
        print("\nğŸš¨ agentlyæµå¼ç»“æ„åŒ–è¾“å‡ºåŠŸèƒ½æµ‹è¯•å¤±è´¥")
        sys.exit(1)