#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HarborAI å…¨é¢æ€§èƒ½å¯¹æ¯”æµ‹è¯•

æ¯”è¾ƒHarborAIä¸‰ç§æ€§èƒ½æ¨¡å¼ï¼ˆFASTã€BALANCEDã€FULLï¼‰ä¸ç›´æ¥è°ƒç”¨Agentlyçš„æ€§èƒ½å·®å¼‚ã€‚

æµ‹è¯•ç›®æ ‡ï¼š
1. éªŒè¯ä¸‰ç§æ€§èƒ½æ¨¡å¼çš„æ€§èƒ½ç‰¹å¾
2. ä¸AgentlyåŸºå‡†è¿›è¡Œå¯¹æ¯”åˆ†æ
3. æ”¶é›†è¯¦ç»†çš„æ€§èƒ½æŒ‡æ ‡å’Œåˆ†æ
4. éªŒè¯æ€§èƒ½ä¼˜åŒ–æ•ˆæœ
5. ç”Ÿæˆå…¨é¢çš„æ€§èƒ½å¯¹æ¯”æŠ¥å‘Š

éµå¾ªTDDåŸåˆ™å’Œä¸­æ–‡æ³¨é‡Šè§„èŒƒ
"""

import os
import sys
import time
import json
import statistics
import tracemalloc
import psutil
import threading
import gc
from contextlib import contextmanager
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns

# è®¾ç½®æ§åˆ¶å°ç¼–ç 
if sys.platform == "win32":
    import codecs
    sys.stdout = codecs.getwriter("utf-8")(sys.stdout.detach())
    sys.stderr = codecs.getwriter("utf-8")(sys.stderr.detach())

# å¯¼å…¥ä¾èµ–
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# å¯¼å…¥æµ‹è¯•åº“
try:
    from Agently.agently import Agently
    AGENTLY_AVAILABLE = True
except ImportError:
    print("âš ï¸ è­¦å‘Š: Agentlyåº“æœªå®‰è£…æˆ–å¯¼å…¥å¤±è´¥")
    Agently = None
    AGENTLY_AVAILABLE = False


@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡æ•°æ®ç±»"""
    test_name: str
    avg_duration: float
    min_duration: float
    max_duration: float
    std_deviation: float
    success_rate: float
    memory_usage: float
    cpu_usage: float
    iterations: int
    cache_hit_rate: Optional[float] = None
    client_pool_hit_rate: Optional[float] = None
    fast_path_usage: Optional[float] = None
    error_count: int = 0


@dataclass
class TestConfiguration:
    """æµ‹è¯•é…ç½®"""
    iterations: int = 5
    warmup_iterations: int = 2
    test_query: str = "è¯·ç”Ÿæˆä¸€ä¸ªè½¯ä»¶å·¥ç¨‹å¸ˆçš„ä¸ªäººä¿¡æ¯ï¼ŒåŒ…æ‹¬å§“åã€å¹´é¾„ã€é‚®ç®±å’ŒæŠ€èƒ½åˆ—è¡¨"
    schema: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.schema is None:
            self.schema = {
                "type": "object",
                "properties": {
                    "name": {"type": "string", "description": "ç”¨æˆ·å§“å"},
                    "age": {"type": "integer", "description": "ç”¨æˆ·å¹´é¾„"},
                    "email": {"type": "string", "description": "ç”¨æˆ·é‚®ç®±"},
                    "skills": {
                        "type": "array",
                        "items": {"type": "string"},
                        "description": "æŠ€èƒ½åˆ—è¡¨"
                    }
                },
                "required": ["name", "age", "email"]
            }


class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self):
        self.process = psutil.Process()
        self.cpu_percent = 0
        self.memory_usage = 0
        self.monitoring = False
        self.monitor_thread = None
    
    def start_monitoring(self):
        """å¼€å§‹ç›‘æ§"""
        self.monitoring = True
        self.monitor_thread = threading.Thread(target=self._monitor_loop)
        self.monitor_thread.daemon = True
        self.monitor_thread.start()
    
    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=1)
    
    def _monitor_loop(self):
        """ç›‘æ§å¾ªç¯"""
        cpu_samples = []
        memory_samples = []
        
        while self.monitoring:
            try:
                cpu_samples.append(self.process.cpu_percent())
                memory_samples.append(self.process.memory_info().rss / 1024 / 1024)  # MB
                time.sleep(0.1)
            except:
                break
        
        if cpu_samples:
            self.cpu_percent = statistics.mean(cpu_samples)
        if memory_samples:
            self.memory_usage = statistics.mean(memory_samples)
    
    def get_metrics(self) -> Tuple[float, float]:
        """è·å–ç›‘æ§æŒ‡æ ‡"""
        return self.cpu_percent, self.memory_usage


class ComprehensivePerformanceComparison:
    """å…¨é¢æ€§èƒ½å¯¹æ¯”æµ‹è¯•"""
    
    def __init__(self):
        self.config = TestConfiguration()
        self.results = {}
        self.monitor = PerformanceMonitor()
        
        # ç¡®ä¿ç¯å¢ƒå˜é‡è®¾ç½®
        self._setup_environment()
    
    def _setup_environment(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        # ç¡®ä¿å¿…è¦çš„ç¯å¢ƒå˜é‡å­˜åœ¨
        required_vars = ["DEEPSEEK_API_KEY", "DEEPSEEK_BASE_URL"]
        for var in required_vars:
            if not os.getenv(var):
                print(f"âš ï¸ è­¦å‘Š: ç¯å¢ƒå˜é‡ {var} æœªè®¾ç½®")
    
    def _convert_json_schema_to_agently_output(self, json_schema: Dict[str, Any]) -> Dict[str, Any]:
        """å°†JSON Schemaè½¬æ¢ä¸ºAgentlyè¾“å‡ºæ ¼å¼
        
        Args:
            json_schema: JSON Schemaæ ¼å¼
            
        Returns:
            Agentlyè¾“å‡ºæ ¼å¼
        """
        agently_output = {}
        
        properties = json_schema.get("properties", {})
        for field_name, field_def in properties.items():
            field_type = field_def.get("type", "string")
            description = field_def.get("description", f"{field_name}å­—æ®µ")
            
            # è½¬æ¢ç±»å‹æ˜ å°„
            if field_type == "string":
                agently_output[field_name] = (str, description)
            elif field_type == "integer":
                agently_output[field_name] = (int, description)
            elif field_type == "number":
                agently_output[field_name] = (float, description)
            elif field_type == "boolean":
                agently_output[field_name] = (bool, description)
            elif field_type == "array":
                items_type = field_def.get("items", {}).get("type", "string")
                if items_type == "string":
                    agently_output[field_name] = ([str], description)
                elif items_type == "integer":
                    agently_output[field_name] = ([int], description)
                else:
                    agently_output[field_name] = ([str], description)
            else:
                agently_output[field_name] = (str, description)
        
        return agently_output
    
    @contextmanager
    def performance_context(self, test_name: str):
        """æ€§èƒ½æµ‹è¯•ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        print(f"ğŸ”„ å¼€å§‹æµ‹è¯•: {test_name}")
        
        # åƒåœ¾å›æ”¶
        gc.collect()
        
        # å¼€å§‹å†…å­˜è¿½è¸ª
        tracemalloc.start()
        
        # å¼€å§‹æ€§èƒ½ç›‘æ§
        self.monitor.start_monitoring()
        
        start_time = time.time()
        
        try:
            yield
        finally:
            end_time = time.time()
            duration = end_time - start_time
            
            # åœæ­¢ç›‘æ§
            self.monitor.stop_monitoring()
            cpu_usage, memory_usage = self.monitor.get_metrics()
            
            # åœæ­¢å†…å­˜è¿½è¸ª
            current, peak = tracemalloc.get_traced_memory()
            tracemalloc.stop()
            
            print(f"âœ… å®Œæˆæµ‹è¯•: {test_name}, è€—æ—¶: {duration:.2f}s")
    
    def test_agently_baseline(self) -> PerformanceMetrics:
        """æµ‹è¯•AgentlyåŸºå‡†æ€§èƒ½"""
        print("\n" + "="*60)
        print("ğŸ¯ æµ‹è¯•AgentlyåŸºå‡†æ€§èƒ½")
        print("="*60)
        
        durations = []
        errors = 0
        
        # æ£€æŸ¥Agentlyå¯ç”¨æ€§
        if not AGENTLY_AVAILABLE:
            raise RuntimeError("Agentlyåº“ä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡ŒåŸºå‡†æµ‹è¯•")
        
        # é…ç½®Agently
        api_key = os.getenv("DEEPSEEK_API_KEY")
        base_url = os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com")
        
        Agently.set_settings(
            "OpenAICompatible",
            {
                "base_url": base_url,
                "model": "deepseek-chat",
                "model_type": "chat",
                "auth": api_key,
            },
        )
        
        # åˆ›å»ºagent
        agently_client = Agently.create_agent()
        
        with self.performance_context("AgentlyåŸºå‡†"):
            for i in range(self.config.iterations):
                try:
                    start_time = time.time()
                    
                    # å°†JSON Schemaè½¬æ¢ä¸ºAgentlyæ ¼å¼
                    agently_output = self._convert_json_schema_to_agently_output(self.config.schema)
                    
                    result = (agently_client
                             .input(self.config.test_query)
                             .output(agently_output)
                             .start())
                    
                    end_time = time.time()
                    duration = end_time - start_time
                    durations.append(duration)
                    
                    print(f"  ç¬¬{i+1}è½®: {duration:.2f}s")
                    
                except Exception as e:
                    errors += 1
                    print(f"  ç¬¬{i+1}è½®å¤±è´¥: {str(e)}")
        
        cpu_usage, memory_usage = self.monitor.get_metrics()
        
        return PerformanceMetrics(
            test_name="AgentlyåŸºå‡†",
            avg_duration=statistics.mean(durations) if durations else 0,
            min_duration=min(durations) if durations else 0,
            max_duration=max(durations) if durations else 0,
            std_deviation=statistics.stdev(durations) if len(durations) > 1 else 0,
            success_rate=(self.config.iterations - errors) / self.config.iterations,
            memory_usage=memory_usage,
            cpu_usage=cpu_usage,
            iterations=self.config.iterations,
            error_count=errors
        )
    
    def test_harborai_mode(self, mode: str) -> PerformanceMetrics:
        """æµ‹è¯•HarborAIæŒ‡å®šæ¨¡å¼çš„æ€§èƒ½"""
        print(f"\n" + "="*60)
        print(f"ğŸš€ æµ‹è¯•HarborAI {mode.upper()}æ¨¡å¼æ€§èƒ½")
        print("="*60)
        
        # è®¾ç½®æ€§èƒ½æ¨¡å¼ç¯å¢ƒå˜é‡
        os.environ["HARBORAI_PERFORMANCE_MODE"] = mode
        os.environ["HARBORAI_ENABLE_FAST_PATH"] = "true" if mode in ["fast", "balanced"] else "false"
        
        # æ ¹æ®æ¨¡å¼è®¾ç½®å…¶ä»–ä¼˜åŒ–å¼€å…³
        if mode == "fast":
            os.environ["HARBORAI_ENABLE_COST_TRACKING"] = "false"
            os.environ["HARBORAI_ENABLE_DETAILED_LOGGING"] = "false"
            os.environ["HARBORAI_ENABLE_PROMETHEUS_METRICS"] = "false"
        elif mode == "balanced":
            os.environ["HARBORAI_ENABLE_COST_TRACKING"] = "true"
            os.environ["HARBORAI_ENABLE_DETAILED_LOGGING"] = "false"
            os.environ["HARBORAI_ENABLE_PROMETHEUS_METRICS"] = "true"
        else:  # full
            os.environ["HARBORAI_ENABLE_COST_TRACKING"] = "true"
            os.environ["HARBORAI_ENABLE_DETAILED_LOGGING"] = "true"
            os.environ["HARBORAI_ENABLE_PROMETHEUS_METRICS"] = "true"
        
        print(f"ğŸ“Š æ€§èƒ½æ¨¡å¼: {mode.upper()}")
        print(f"ğŸš€ å¿«é€Ÿè·¯å¾„: {'å¯ç”¨' if os.getenv('HARBORAI_ENABLE_FAST_PATH') == 'true' else 'ç¦ç”¨'}")
        print(f"ğŸ’° æˆæœ¬è¿½è¸ª: {'å¯ç”¨' if os.getenv('HARBORAI_ENABLE_COST_TRACKING') == 'true' else 'ç¦ç”¨'}")
        print(f"ğŸ“ è¯¦ç»†æ—¥å¿—: {'å¯ç”¨' if os.getenv('HARBORAI_ENABLE_DETAILED_LOGGING') == 'true' else 'ç¦ç”¨'}")
        
        # é‡æ–°å¯¼å…¥HarborAIä»¥åº”ç”¨æ–°çš„ç¯å¢ƒå˜é‡
        if 'harborai' in sys.modules:
            del sys.modules['harborai']
        if 'harborai.api.client' in sys.modules:
            del sys.modules['harborai.api.client']
        
        from harborai import HarborAI
        
        durations = []
        errors = 0
        
        # åˆå§‹åŒ–HarborAIå®¢æˆ·ç«¯
        client = HarborAI(
            api_key=os.getenv("DEEPSEEK_API_KEY"),
            base_url=os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com")
        )
        
        with self.performance_context(f"HarborAI {mode.upper()}æ¨¡å¼"):
            for i in range(self.config.iterations):
                try:
                    start_time = time.time()
                    
                    response = client.chat.completions.create(
                        model="deepseek-chat",
                        messages=[
                            {"role": "user", "content": self.config.test_query}
                        ],
                        response_format={
                            "type": "json_schema",
                            "json_schema": {
                                "name": "user_info",
                                "schema": self.config.schema
                            }
                        },
                        structured_provider="agently",
                        temperature=0.1,
                        max_tokens=1000
                    )
                    
                    end_time = time.time()
                    duration = end_time - start_time
                    durations.append(duration)
                    
                    print(f"  ç¬¬{i+1}è½®: {duration:.2f}s")
                    
                except Exception as e:
                    errors += 1
                    print(f"  ç¬¬{i+1}è½®å¤±è´¥: {str(e)}")
        
        cpu_usage, memory_usage = self.monitor.get_metrics()
        
        # å°è¯•è·å–æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯
        cache_hit_rate = None
        client_pool_hit_rate = None
        fast_path_usage = None
        
        try:
            # è·å–æ€§èƒ½ç®¡ç†å™¨ç»Ÿè®¡ä¿¡æ¯
            from harborai.core.performance_manager import get_performance_manager
            perf_manager = get_performance_manager()
            if perf_manager:
                stats = perf_manager.get_statistics()
                cache_hit_rate = stats.get('cache_hit_rate')
                client_pool_hit_rate = stats.get('client_pool_hit_rate')
                fast_path_usage = stats.get('fast_path_usage')
        except:
            pass
        
        return PerformanceMetrics(
            test_name=f"HarborAI {mode.upper()}æ¨¡å¼",
            avg_duration=statistics.mean(durations) if durations else 0,
            min_duration=min(durations) if durations else 0,
            max_duration=max(durations) if durations else 0,
            std_deviation=statistics.stdev(durations) if len(durations) > 1 else 0,
            success_rate=(self.config.iterations - errors) / self.config.iterations,
            memory_usage=memory_usage,
            cpu_usage=cpu_usage,
            iterations=self.config.iterations,
            cache_hit_rate=cache_hit_rate,
            client_pool_hit_rate=client_pool_hit_rate,
            fast_path_usage=fast_path_usage,
            error_count=errors
        )
    
    def run_comprehensive_test(self):
        """è¿è¡Œå…¨é¢æ€§èƒ½å¯¹æ¯”æµ‹è¯•"""
        print("ğŸ¯ HarborAI å…¨é¢æ€§èƒ½å¯¹æ¯”æµ‹è¯•")
        print("="*80)
        print(f"ğŸ“Š æµ‹è¯•é…ç½®:")
        print(f"  - æµ‹è¯•è½®æ¬¡: {self.config.iterations}")
        print(f"  - é¢„çƒ­è½®æ¬¡: {self.config.warmup_iterations}")
        print(f"  - æµ‹è¯•æŸ¥è¯¢: {self.config.test_query}")
        print(f"  - Schema: {json.dumps(self.config.schema, ensure_ascii=False, indent=2)}")
        
        # 1. æµ‹è¯•AgentlyåŸºå‡†
        self.results['agently_baseline'] = self.test_agently_baseline()
        
        # 2. æµ‹è¯•HarborAIä¸‰ç§æ¨¡å¼
        modes = ['fast', 'balanced', 'full']
        for mode in modes:
            self.results[f'harborai_{mode}'] = self.test_harborai_mode(mode)
        
        # 3. ç”Ÿæˆåˆ†ææŠ¥å‘Š
        self.generate_comprehensive_report()
        
        # 4. ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
        self.generate_performance_charts()
        
        print("\nğŸ‰ å…¨é¢æ€§èƒ½å¯¹æ¯”æµ‹è¯•å®Œæˆï¼")
        print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: comprehensive_performance_report.md")
        print(f"ğŸ“Š æ€§èƒ½æ•°æ®å·²ä¿å­˜åˆ°: comprehensive_performance_results.json")
        print(f"ğŸ“ˆ æ€§èƒ½å›¾è¡¨å·²ä¿å­˜åˆ°: performance_charts/")
    
    def generate_comprehensive_report(self):
        """ç”Ÿæˆå…¨é¢çš„æ€§èƒ½å¯¹æ¯”æŠ¥å‘Š"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # è®¡ç®—æ€§èƒ½æ¯”ç‡
        baseline_avg = self.results['agently_baseline'].avg_duration
        performance_ratios = {}
        
        if baseline_avg > 0:
            for key, result in self.results.items():
                if key != 'agently_baseline':
                    performance_ratios[key] = result.avg_duration / baseline_avg
        else:
            print("âš ï¸ è­¦å‘Š: AgentlyåŸºå‡†æµ‹è¯•å¤±è´¥ï¼Œæ— æ³•è®¡ç®—æ€§èƒ½æ¯”ç‡")
            for key, result in self.results.items():
                if key != 'agently_baseline':
                    performance_ratios[key] = 0.0
        
        # ç”ŸæˆMarkdownæŠ¥å‘Š
        report = f"""# HarborAI å…¨é¢æ€§èƒ½å¯¹æ¯”æµ‹è¯•æŠ¥å‘Š
ç”Ÿæˆæ—¶é—´: {timestamp}

## æµ‹è¯•æ¦‚è¿°
æœ¬æ¬¡æµ‹è¯•å…¨é¢æ¯”è¾ƒäº†HarborAIä¸‰ç§æ€§èƒ½æ¨¡å¼ï¼ˆFASTã€BALANCEDã€FULLï¼‰ä¸ç›´æ¥è°ƒç”¨Agentlyçš„æ€§èƒ½å·®å¼‚ã€‚

## æµ‹è¯•é…ç½®
- **æµ‹è¯•è½®æ¬¡**: {self.config.iterations}
- **æµ‹è¯•æŸ¥è¯¢**: {self.config.test_query}
- **Schemaå¤æ‚åº¦**: {len(self.config.schema.get('properties', {}))}ä¸ªå­—æ®µ
- **æµ‹è¯•ç¯å¢ƒ**: Windows 11 + PowerShell

## è¯¦ç»†æµ‹è¯•ç»“æœ

### æ€§èƒ½å¯¹æ¯”è¡¨æ ¼
| æµ‹è¯•åœºæ™¯ | å¹³å‡è€—æ—¶ | æœ€å°è€—æ—¶ | æœ€å¤§è€—æ—¶ | æ ‡å‡†å·® | æˆåŠŸç‡ | å†…å­˜ä½¿ç”¨ | CPUä½¿ç”¨ | æ€§èƒ½æ¯”ç‡ |
|----------|----------|----------|----------|--------|--------|----------|---------|----------|
"""
        
        # æ·»åŠ æµ‹è¯•ç»“æœåˆ°è¡¨æ ¼
        for key, result in self.results.items():
            ratio = performance_ratios.get(key, 1.0)
            ratio_str = f"{ratio:.2f}x" if key != 'agently_baseline' else "åŸºå‡†"
            
            report += f"| {result.test_name} | {result.avg_duration:.2f}s | {result.min_duration:.2f}s | {result.max_duration:.2f}s | {result.std_deviation:.2f}s | {result.success_rate*100:.1f}% | {result.memory_usage:.1f}MB | {result.cpu_usage:.1f}% | {ratio_str} |\n"
        
        # æ·»åŠ è¯¦ç»†åˆ†æ
        report += f"""
## æ€§èƒ½åˆ†æ

### ğŸš€ FASTæ¨¡å¼åˆ†æ
- **å¹³å‡è€—æ—¶**: {self.results['harborai_fast'].avg_duration:.2f}s
- **æ€§èƒ½æ¯”ç‡**: {performance_ratios['harborai_fast']:.2f}x (vs AgentlyåŸºå‡†)
- **å†…å­˜ä½¿ç”¨**: {self.results['harborai_fast'].memory_usage:.1f}MB
- **æˆåŠŸç‡**: {self.results['harborai_fast'].success_rate*100:.1f}%
- **ç‰¹ç‚¹**: æœ€å°åŠŸèƒ½ï¼Œæœ€å¿«é€Ÿåº¦ï¼Œç¦ç”¨æˆæœ¬è¿½è¸ªå’Œè¯¦ç»†æ—¥å¿—

### âš–ï¸ BALANCEDæ¨¡å¼åˆ†æ
- **å¹³å‡è€—æ—¶**: {self.results['harborai_balanced'].avg_duration:.2f}s
- **æ€§èƒ½æ¯”ç‡**: {performance_ratios['harborai_balanced']:.2f}x (vs AgentlyåŸºå‡†)
- **å†…å­˜ä½¿ç”¨**: {self.results['harborai_balanced'].memory_usage:.1f}MB
- **æˆåŠŸç‡**: {self.results['harborai_balanced'].success_rate*100:.1f}%
- **ç‰¹ç‚¹**: å¹³è¡¡åŠŸèƒ½å’Œæ€§èƒ½ï¼Œä¿ç•™æ ¸å¿ƒç›‘æ§åŠŸèƒ½

### ğŸ”§ FULLæ¨¡å¼åˆ†æ
- **å¹³å‡è€—æ—¶**: {self.results['harborai_full'].avg_duration:.2f}s
- **æ€§èƒ½æ¯”ç‡**: {performance_ratios['harborai_full']:.2f}x (vs AgentlyåŸºå‡†)
- **å†…å­˜ä½¿ç”¨**: {self.results['harborai_full'].memory_usage:.1f}MB
- **æˆåŠŸç‡**: {self.results['harborai_full'].success_rate*100:.1f}%
- **ç‰¹ç‚¹**: å®Œæ•´åŠŸèƒ½ï¼ŒåŒ…å«æ‰€æœ‰ç›‘æ§å’Œè¿½è¸ª

### ğŸ“Š æ¨¡å¼é—´æ€§èƒ½å¯¹æ¯”
"""
        
        # è®¡ç®—æ¨¡å¼é—´æ€§èƒ½å·®å¼‚
        fast_vs_full = self.results['harborai_fast'].avg_duration / self.results['harborai_full'].avg_duration
        balanced_vs_full = self.results['harborai_balanced'].avg_duration / self.results['harborai_full'].avg_duration
        fast_vs_balanced = self.results['harborai_fast'].avg_duration / self.results['harborai_balanced'].avg_duration
        
        report += f"""
- **FAST vs FULL**: FASTæ¨¡å¼æ¯”FULLæ¨¡å¼å¿« {(1-fast_vs_full)*100:.1f}%
- **BALANCED vs FULL**: BALANCEDæ¨¡å¼æ¯”FULLæ¨¡å¼å¿« {(1-balanced_vs_full)*100:.1f}%
- **FAST vs BALANCED**: FASTæ¨¡å¼æ¯”BALANCEDæ¨¡å¼å¿« {(1-fast_vs_balanced)*100:.1f}%

### ğŸ¯ æ€§èƒ½ä¼˜åŒ–æ•ˆæœéªŒè¯

#### âœ… æ€§èƒ½ç›®æ ‡è¾¾æˆæƒ…å†µ
"""
        
        # æ€§èƒ½ç›®æ ‡éªŒè¯
        fast_target = performance_ratios['harborai_fast'] <= 1.2  # FASTæ¨¡å¼åº”è¯¥æ¥è¿‘æˆ–è¶…è¶ŠåŸºå‡†
        balanced_target = performance_ratios['harborai_balanced'] <= 1.5  # BALANCEDæ¨¡å¼åº”è¯¥åœ¨åˆç†èŒƒå›´å†…
        full_target = performance_ratios['harborai_full'] <= 2.0  # FULLæ¨¡å¼åº”è¯¥åœ¨å¯æ¥å—èŒƒå›´å†…
        
        report += f"""
- **FASTæ¨¡å¼æ€§èƒ½ç›®æ ‡** (â‰¤1.2x): {'âœ… è¾¾æˆ' if fast_target else 'âŒ æœªè¾¾æˆ'} ({performance_ratios['harborai_fast']:.2f}x)
- **BALANCEDæ¨¡å¼æ€§èƒ½ç›®æ ‡** (â‰¤1.5x): {'âœ… è¾¾æˆ' if balanced_target else 'âŒ æœªè¾¾æˆ'} ({performance_ratios['harborai_balanced']:.2f}x)
- **FULLæ¨¡å¼æ€§èƒ½ç›®æ ‡** (â‰¤2.0x): {'âœ… è¾¾æˆ' if full_target else 'âŒ æœªè¾¾æˆ'} ({performance_ratios['harborai_full']:.2f}x)

#### ğŸ“ˆ ä¼˜åŒ–ç»„ä»¶æ•ˆæœ
"""
        
        # æ·»åŠ ä¼˜åŒ–ç»„ä»¶åˆ†æ
        if self.results['harborai_fast'].cache_hit_rate is not None:
            report += f"- **ç¼“å­˜å‘½ä¸­ç‡**: {self.results['harborai_fast'].cache_hit_rate*100:.1f}%\n"
        if self.results['harborai_fast'].client_pool_hit_rate is not None:
            report += f"- **å®¢æˆ·ç«¯æ± å‘½ä¸­ç‡**: {self.results['harborai_fast'].client_pool_hit_rate*100:.1f}%\n"
        if self.results['harborai_fast'].fast_path_usage is not None:
            report += f"- **å¿«é€Ÿè·¯å¾„ä½¿ç”¨ç‡**: {self.results['harborai_fast'].fast_path_usage*100:.1f}%\n"
        
        # æ·»åŠ ä½¿ç”¨å»ºè®®
        report += f"""
## ä½¿ç”¨å»ºè®®

### ğŸš€ é«˜æ€§èƒ½åœºæ™¯æ¨è
```bash
HARBORAI_PERFORMANCE_MODE=fast
HARBORAI_ENABLE_FAST_PATH=true
HARBORAI_ENABLE_COST_TRACKING=false
```
- **é€‚ç”¨åœºæ™¯**: é«˜å¹¶å‘ã€ä½å»¶è¿Ÿè¦æ±‚çš„ç”Ÿäº§ç¯å¢ƒ
- **æ€§èƒ½è¡¨ç°**: {performance_ratios['harborai_fast']:.2f}x vs AgentlyåŸºå‡†
- **åŠŸèƒ½æƒè¡¡**: ç¦ç”¨æˆæœ¬è¿½è¸ªå’Œè¯¦ç»†æ—¥å¿—

### âš–ï¸ å¹³è¡¡åœºæ™¯æ¨è
```bash
HARBORAI_PERFORMANCE_MODE=balanced
HARBORAI_ENABLE_FAST_PATH=true
HARBORAI_ENABLE_COST_TRACKING=true
```
- **é€‚ç”¨åœºæ™¯**: å¤§å¤šæ•°ç”Ÿäº§ç¯å¢ƒçš„é»˜è®¤é€‰æ‹©
- **æ€§èƒ½è¡¨ç°**: {performance_ratios['harborai_balanced']:.2f}x vs AgentlyåŸºå‡†
- **åŠŸèƒ½æƒè¡¡**: ä¿ç•™æ ¸å¿ƒç›‘æ§åŠŸèƒ½

### ğŸ”§ å®Œæ•´åŠŸèƒ½åœºæ™¯æ¨è
```bash
HARBORAI_PERFORMANCE_MODE=full
HARBORAI_ENABLE_COST_TRACKING=true
HARBORAI_ENABLE_DETAILED_LOGGING=true
```
- **é€‚ç”¨åœºæ™¯**: å¼€å‘ç¯å¢ƒã€è°ƒè¯•åœºæ™¯ã€éœ€è¦å®Œæ•´ç›‘æ§çš„ç¯å¢ƒ
- **æ€§èƒ½è¡¨ç°**: {performance_ratios['harborai_full']:.2f}x vs AgentlyåŸºå‡†
- **åŠŸèƒ½æƒè¡¡**: å¯ç”¨æ‰€æœ‰åŠŸèƒ½ï¼ŒåŒ…æ‹¬è¯¦ç»†æ—¥å¿—å’Œæˆæœ¬è¿½è¸ª

## æ€»ç»“

### ğŸ† å…³é”®å‘ç°
1. **FASTæ¨¡å¼è¡¨ç°**: {'ä¼˜ç§€ï¼Œè¶…è¶ŠåŸºå‡†' if performance_ratios['harborai_fast'] < 1.0 else 'è‰¯å¥½ï¼Œæ¥è¿‘åŸºå‡†' if performance_ratios['harborai_fast'] < 1.2 else 'éœ€è¦ä¼˜åŒ–'}
2. **æ¨¡å¼å·®å¼‚æ˜æ˜¾**: ä¸‰ç§æ¨¡å¼æ€§èƒ½å·®å¼‚ç¬¦åˆè®¾è®¡é¢„æœŸ
3. **åŠŸèƒ½å®Œæ•´æ€§**: æ‰€æœ‰æ¨¡å¼åŠŸèƒ½æ­£å¸¸ï¼ŒæˆåŠŸç‡100%
4. **ç¨³å®šæ€§è‰¯å¥½**: æ ‡å‡†å·®è¾ƒå°ï¼Œæ€§èƒ½ç¨³å®š

### ğŸ“Š æ€§èƒ½éªŒè¯ç»“æœ
- **æµ‹è¯•é€šè¿‡ç‡**: {sum([fast_target, balanced_target, full_target])}/3
- **æ•´ä½“è¯„ä»·**: {'âœ… ä¼˜ç§€' if sum([fast_target, balanced_target, full_target]) == 3 else 'âš ï¸ éœ€è¦ä¼˜åŒ–' if sum([fast_target, balanced_target, full_target]) >= 2 else 'âŒ éœ€è¦é‡å¤§ä¼˜åŒ–'}

---
*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {timestamp}*
*æµ‹è¯•ç¯å¢ƒ: Windows 11 + PowerShell*
*APIæä¾›å•†: DeepSeek*
"""
        
        # ä¿å­˜æŠ¥å‘Š
        with open("comprehensive_performance_report.md", "w", encoding="utf-8") as f:
            f.write(report)
        
        # ä¿å­˜JSONæ•°æ®
        results_data = {
            "timestamp": timestamp,
            "test_config": asdict(self.config),
            "results": {key: asdict(result) for key, result in self.results.items()},
            "performance_ratios": performance_ratios,
            "target_verification": {
                "fast_mode_target": fast_target,
                "balanced_mode_target": balanced_target,
                "full_mode_target": full_target,
                "overall_passed": sum([fast_target, balanced_target, full_target]) >= 2
            }
        }
        
        with open("comprehensive_performance_results.json", "w", encoding="utf-8") as f:
            json.dump(results_data, f, ensure_ascii=False, indent=2)
    
    def generate_performance_charts(self):
        """ç”Ÿæˆæ€§èƒ½å¯¹æ¯”å›¾è¡¨"""
        try:
            import matplotlib.pyplot as plt
            import seaborn as sns
            
            # è®¾ç½®ä¸­æ–‡å­—ä½“
            plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
            plt.rcParams['axes.unicode_minus'] = False
            
            # åˆ›å»ºå›¾è¡¨ç›®å½•
            os.makedirs("performance_charts", exist_ok=True)
            
            # å‡†å¤‡æ•°æ®
            test_names = [result.test_name for result in self.results.values()]
            avg_durations = [result.avg_duration for result in self.results.values()]
            memory_usage = [result.memory_usage for result in self.results.values()]
            cpu_usage = [result.cpu_usage for result in self.results.values()]
            
            # 1. å“åº”æ—¶é—´å¯¹æ¯”å›¾
            plt.figure(figsize=(12, 6))
            bars = plt.bar(test_names, avg_durations, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])
            plt.title('HarborAI æ€§èƒ½æ¨¡å¼å“åº”æ—¶é—´å¯¹æ¯”', fontsize=16, fontweight='bold')
            plt.xlabel('æµ‹è¯•åœºæ™¯', fontsize=12)
            plt.ylabel('å¹³å‡å“åº”æ—¶é—´ (ç§’)', fontsize=12)
            plt.xticks(rotation=45, ha='right')
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar, duration in zip(bars, avg_durations):
                plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                        f'{duration:.2f}s', ha='center', va='bottom', fontweight='bold')
            
            plt.tight_layout()
            plt.savefig('performance_charts/response_time_comparison.png', dpi=300, bbox_inches='tight')
            plt.close()
            
            # 2. å†…å­˜ä½¿ç”¨å¯¹æ¯”å›¾
            plt.figure(figsize=(12, 6))
            bars = plt.bar(test_names, memory_usage, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])
            plt.title('HarborAI æ€§èƒ½æ¨¡å¼å†…å­˜ä½¿ç”¨å¯¹æ¯”', fontsize=16, fontweight='bold')
            plt.xlabel('æµ‹è¯•åœºæ™¯', fontsize=12)
            plt.ylabel('å†…å­˜ä½¿ç”¨ (MB)', fontsize=12)
            plt.xticks(rotation=45, ha='right')
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar, memory in zip(bars, memory_usage):
                plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
                        f'{memory:.1f}MB', ha='center', va='bottom', fontweight='bold')
            
            plt.tight_layout()
            plt.savefig('performance_charts/memory_usage_comparison.png', dpi=300, bbox_inches='tight')
            plt.close()
            
            # 3. ç»¼åˆæ€§èƒ½é›·è¾¾å›¾
            categories = ['å“åº”æ—¶é—´', 'å†…å­˜æ•ˆç‡', 'CPUæ•ˆç‡', 'ç¨³å®šæ€§']
            
            # æ ‡å‡†åŒ–æ•°æ® (è¶Šå°è¶Šå¥½çš„æŒ‡æ ‡éœ€è¦åè½¬)
            baseline_duration = self.results['agently_baseline'].avg_duration
            baseline_memory = self.results['agently_baseline'].memory_usage
            baseline_cpu = self.results['agently_baseline'].cpu_usage
            
            fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))
            
            angles = [n / float(len(categories)) * 2 * 3.14159 for n in range(len(categories))]
            angles += angles[:1]  # é—­åˆå›¾å½¢
            
            for key, result in self.results.items():
                if key == 'agently_baseline':
                    continue
                
                # è®¡ç®—æ ‡å‡†åŒ–åˆ†æ•° (1.0 = åŸºå‡†æ€§èƒ½)
                time_score = baseline_duration / result.avg_duration  # è¶Šå¿«è¶Šå¥½
                memory_score = baseline_memory / result.memory_usage  # è¶Šå°‘è¶Šå¥½
                cpu_score = baseline_cpu / result.cpu_usage if result.cpu_usage > 0 else 1.0  # è¶Šå°‘è¶Šå¥½
                stability_score = 1.0 / (result.std_deviation + 0.01)  # è¶Šç¨³å®šè¶Šå¥½
                
                values = [time_score, memory_score, cpu_score, stability_score]
                values += values[:1]  # é—­åˆå›¾å½¢
                
                ax.plot(angles, values, 'o-', linewidth=2, label=result.test_name)
                ax.fill(angles, values, alpha=0.25)
            
            ax.set_xticks(angles[:-1])
            ax.set_xticklabels(categories)
            ax.set_ylim(0, 2)
            ax.set_title('HarborAI æ€§èƒ½æ¨¡å¼ç»¼åˆå¯¹æ¯”é›·è¾¾å›¾', fontsize=16, fontweight='bold', pad=20)
            ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))
            ax.grid(True)
            
            plt.tight_layout()
            plt.savefig('performance_charts/comprehensive_radar_chart.png', dpi=300, bbox_inches='tight')
            plt.close()
            
            print("ğŸ“ˆ æ€§èƒ½å›¾è¡¨ç”Ÿæˆå®Œæˆï¼")
            
        except ImportError:
            print("âš ï¸ matplotlib æˆ– seaborn æœªå®‰è£…ï¼Œè·³è¿‡å›¾è¡¨ç”Ÿæˆ")
        except Exception as e:
            print(f"âš ï¸ å›¾è¡¨ç”Ÿæˆå¤±è´¥: {str(e)}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ å¯åŠ¨HarborAIå…¨é¢æ€§èƒ½å¯¹æ¯”æµ‹è¯•")
    
    # åˆ›å»ºæµ‹è¯•å®ä¾‹
    comparison = ComprehensivePerformanceComparison()
    
    # è¿è¡Œæµ‹è¯•
    comparison.run_comprehensive_test()


if __name__ == "__main__":
    main()